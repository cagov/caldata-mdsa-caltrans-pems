{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/run-results/v6.json", "dbt_version": "1.10.6", "generated_at": "2025-08-19T19:33:52.357251Z", "invocation_id": "5302189a-2f4e-4576-9b78-7385be303d8d", "invocation_started_at": "2025-08-19T19:33:37.940532Z", "env": {}}, "results": [{"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.769601Z", "completed_at": "2025-08-19T19:33:49.773352Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.773885Z", "completed_at": "2025-08-19T19:33:49.773906Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.023301362991333008, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.stg_db96__controller_config", "compiled": true, "compiled_code": "select\n    controller_id,\n    controller_type,\n    district_id as district,\n    county_id as county,\n    city_id as city,\n    freeway_id as freeway,\n    freeway_dir as direction\nfrom RAW_PRD.db96.controller_config", "relation_name": "ANALYTICS_PRD.db96.stg_db96__controller_config", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.760015Z", "completed_at": "2025-08-19T19:33:49.779069Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.779596Z", "completed_at": "2025-08-19T19:33:49.779605Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.03171348571777344, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.stg_clearinghouse__station_raw", "compiled": true, "compiled_code": "\n\nselect\n    substr(filename, 14, 2)::int as district,\n    sample_timestamp,\n    sample_date,\n    id,\n    flow_1 as volume_1,\n    occupancy_1,\n    speed_1,\n    flow_2 as volume_2,\n    occupancy_2,\n    speed_2,\n    flow_3 as volume_3,\n    occupancy_3,\n    speed_3,\n    flow_4 as volume_4,\n    occupancy_4,\n    speed_4,\n    flow_5 as volume_5,\n    occupancy_5,\n    speed_5,\n    flow_6 as volume_6,\n    occupancy_6,\n    speed_6,\n    flow_7 as volume_7,\n    occupancy_7,\n    speed_7,\n    flow_8 as volume_8,\n    occupancy_8,\n    speed_8\nfrom RAW_PRD.clearinghouse.station_raw\nwhere sample_date >= '2023-01-01'", "relation_name": "ANALYTICS_PRD.clearinghouse.stg_clearinghouse__station_raw", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.765495Z", "completed_at": "2025-08-19T19:33:49.785323Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.785831Z", "completed_at": "2025-08-19T19:33:49.785838Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.03622603416442871, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.stg_clearinghouse__station_status", "compiled": true, "compiled_code": "\n\n/*\nHelpful article for flattening XML:\nhttps://community.snowflake.com/s/article/HOW-TO-QUERY-NESTED-XML-DATA-IN-SNOWFLAKE\n*/\nSELECT\n    STATUS.FILENAME,\n    DATE_FROM_PARTS(\n        REGEXP_SUBSTR(STATUS.FILENAME, 'clhouse/status/d\\\\d{2}/\\\\d{4}/\\\\d{2}/d(\\\\d{2})_tmdd_meta_(\\\\d{4})_(\\\\d{2})_(\\\\d{2}).xml', 1, 1, '', 2)::INT,\n        REGEXP_SUBSTR(STATUS.FILENAME, 'clhouse/status/d\\\\d{2}/\\\\d{4}/\\\\d{2}/d(\\\\d{2})_tmdd_meta_(\\\\d{4})_(\\\\d{2})_(\\\\d{2}).xml', 1, 1, '', 3)::INT,\n        REGEXP_SUBSTR(STATUS.FILENAME, 'clhouse/status/d\\\\d{2}/\\\\d{4}/\\\\d{2}/d(\\\\d{2})_tmdd_meta_(\\\\d{4})_(\\\\d{2})_(\\\\d{2}).xml', 1, 1, '', 4)::INT\n    ) AS META_DATE,\n    REGEXP_SUBSTR(STATUS.FILENAME, 'clhouse/status/d\\\\d{2}/\\\\d{4}/\\\\d{2}/d(\\\\d{2})_tmdd_meta_(\\\\d{4})_(\\\\d{2})_(\\\\d{2}).xml', 1, 1, '', 1)::INT AS DISTRICT,\n    XMLGET(STATUS.CONTENT, 'station-id'):\"$\"::VARCHAR AS STATION_ID,\n    XMLGET(XMLGET(DETECTOR.VALUE, 'detector'), 'detector-id'):\"$\"::VARCHAR AS DETECTOR_ID,\n    XMLGET(XMLGET(DETECTOR.VALUE, 'detector'), 'detector-name'):\"$\"::VARCHAR AS DETECTOR_NAME,\n    XMLGET(XMLGET(DETECTOR.VALUE, 'detector'), 'detector-status'):\"$\"::VARCHAR AS DETECTOR_STATUS,\n    XMLGET(XMLGET(DETECTOR.VALUE, 'detector'), 'tmdd:last-update-time'):\"$\"::VARCHAR AS LAST_UPDATE_TIME,\n    XMLGET(XMLGET(LANE.VALUE, 'detection-lane-item'), 'lane-number'):\"$\"::INT AS LANE_NUMBER\nFROM\n    RAW_PRD.clearinghouse.station_status AS STATUS,\n    /*\n    It's not 100% clear that these flattening operations are necessary. The structure of\n    the XML documents suggest that there can be multiple detectors in a 'detector-list',\n    and multiple lanes in a 'detection-lane'. However, there seem to be few (if any) instances\n    of entries where that is the case. So these flattenings are defensive.\n    */\n    LATERAL FLATTEN(STATUS.CONTENT:\"$\") AS DETECTOR,\n    LATERAL FLATTEN(XMLGET(DETECTOR.VALUE, 'detector'):\"$\") AS LANE\nWHERE\n    GET(DETECTOR.VALUE, '@') = 'detector-list'\n    AND GET(LANE.VALUE, '@') = 'detection-lane'", "relation_name": "ANALYTICS_PRD.clearinghouse.stg_clearinghouse__station_status", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.776213Z", "completed_at": "2025-08-19T19:33:49.790856Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.791378Z", "completed_at": "2025-08-19T19:33:49.791386Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.01623988151550293, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.stg_db96__controller_config_log", "compiled": true, "compiled_code": "select\n    controller_id,\n    time_id,\n    status,\n    name,\n    state_postmile,\n    abs_postmile as absolute_postmile,\n    latitude,\n    longitude,\n    angle,\n    line_num,\n    stn_address\nfrom RAW_PRD.db96.controller_config_log", "relation_name": "ANALYTICS_PRD.db96.stg_db96__controller_config_log", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.751234Z", "completed_at": "2025-08-19T19:33:49.792639Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.794275Z", "completed_at": "2025-08-19T19:33:49.794284Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.04747152328491211, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.stg_clearinghouse__station_meta", "compiled": true, "compiled_code": "\n\nSELECT\n    FILENAME,\n    DATE_FROM_PARTS(\n        REGEXP_SUBSTR(FILENAME, 'clhouse/meta/d\\\\d{2}/\\\\d{4}/\\\\d{2}/d\\\\d{2}_text_meta_(\\\\d{4})_(\\\\d{2})_(\\\\d{2}).txt', 1, 1, '', 1)::INT,\n        REGEXP_SUBSTR(FILENAME, 'clhouse/meta/d\\\\d{2}/\\\\d{4}/\\\\d{2}/d\\\\d{2}_text_meta_(\\\\d{4})_(\\\\d{2})_(\\\\d{2}).txt', 1, 1, '', 2)::INT,\n        REGEXP_SUBSTR(FILENAME, 'clhouse/meta/d\\\\d{2}/\\\\d{4}/\\\\d{2}/d\\\\d{2}_text_meta_(\\\\d{4})_(\\\\d{2})_(\\\\d{2}).txt', 1, 1, '', 3)::INT\n    ) AS META_DATE,\n    ID,\n    FWY AS FREEWAY,\n    DIR AS DIRECTION,\n    DISTRICT,\n    COUNTY,\n    CITY,\n    STATE_PM AS STATE_POSTMILE,\n    ABS_PM AS ABSOLUTE_POSTMILE,\n    LATITUDE,\n    LONGITUDE,\n    LENGTH,\n    TYPE,\n    LANES,\n    NAME\nFROM RAW_PRD.clearinghouse.station_meta", "relation_name": "ANALYTICS_PRD.clearinghouse.stg_clearinghouse__station_meta", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.788072Z", "completed_at": "2025-08-19T19:33:49.793758Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.796222Z", "completed_at": "2025-08-19T19:33:49.796230Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.009217023849487305, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.stg_db96__detector_config_log", "compiled": true, "compiled_code": "select\n    detector_id,\n    time_id,\n    station_id,\n    status,\n    lane::int as lane,\n    slot,\n    volume_flag,\n    logical_position\nfrom RAW_PRD.db96.detector_config_log", "relation_name": "ANALYTICS_PRD.db96.stg_db96__detector_config_log", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.781947Z", "completed_at": "2025-08-19T19:33:49.795019Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.797600Z", "completed_at": "2025-08-19T19:33:49.797611Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.016770124435424805, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.stg_db96__detector_config", "compiled": true, "compiled_code": "select\n    detector_id,\n    detector_type\nfrom RAW_PRD.db96.detector_config", "relation_name": "ANALYTICS_PRD.db96.stg_db96__detector_config", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.798449Z", "completed_at": "2025-08-19T19:33:49.804570Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.809095Z", "completed_at": "2025-08-19T19:33:49.809109Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.01603388786315918, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.stg_db96__station_config", "compiled": true, "compiled_code": "select\n    station_id,\n    station_type,\n    district_id as district,\n    county_id as county,\n    city_id as city,\n    freeway_id as freeway,\n    freeway_dir as direction\nfrom RAW_PRD.db96.station_config", "relation_name": "ANALYTICS_PRD.db96.stg_db96__station_config", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.806151Z", "completed_at": "2025-08-19T19:33:49.820038Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.821545Z", "completed_at": "2025-08-19T19:33:49.821554Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.019522905349731445, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.stg_db96__station_config_log", "compiled": true, "compiled_code": "select\n    station_id,\n    time_id,\n    status,\n    name,\n    physical_lanes,\n    use_speed,\n    dt_set_id,\n    state_postmile,\n    abs_postmile as absolute_postmile,\n    latitude,\n    longitude,\n    angle,\n    seg_start as segment_start,\n    seg_end as segment_end,\n    segment_end - segment_start as length,\n    controller_id\nfrom RAW_PRD.db96.station_config_log", "relation_name": "ANALYTICS_PRD.db96.stg_db96__station_config_log", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.810474Z", "completed_at": "2025-08-19T19:33:49.822335Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.824404Z", "completed_at": "2025-08-19T19:33:49.824415Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.02112126350402832, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.stg_db96__vds30sec", "compiled": true, "compiled_code": "\nselect\n    split_part(split_part(filename, '/', 4), '=D', 2)::int as district,\n    vds_id::varchar as id,\n    sample_date,\n    sample_time as sample_timestamp,\n    volume_1,\n    volume_2,\n    volume_3,\n    volume_4,\n    volume_5,\n    volume_6,\n    volume_7,\n    volume_8,\n    volume_9,\n    volume_10,\n    volume_11,\n    volume_12,\n    volume_13,\n    volume_14,\n    occupancy_1,\n    occupancy_2,\n    occupancy_3,\n    occupancy_4,\n    occupancy_5,\n    occupancy_6,\n    occupancy_7,\n    occupancy_8,\n    occupancy_9,\n    occupancy_10,\n    occupancy_11,\n    occupancy_12,\n    occupancy_13,\n    occupancy_14,\n    speed_1,\n    speed_2,\n    speed_3,\n    speed_4,\n    speed_5,\n    speed_6,\n    speed_7,\n    speed_8,\n    speed_9,\n    speed_10,\n    speed_11,\n    speed_12,\n    speed_13,\n    speed_14\nfrom RAW_PRD.db96.vds30sec\nwhere \n    1=1\n    \nqualify row_number() over (partition by vds_id, sample_date, sample_time order by vds_id) = 1", "relation_name": "ANALYTICS_PRD.db96.stg_db96__vds30sec", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.817259Z", "completed_at": "2025-08-19T19:33:49.823367Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.828044Z", "completed_at": "2025-08-19T19:33:49.828053Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.02302718162536621, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.stg_geo_reference__county_boundaries", "compiled": true, "compiled_code": "select\n\n    COUNTYFP10 as COUNTY_FIPS,\n    GEOID10 as GEO_ID,\n    NAME10 as NAME,\n    ALAND10 as LAND,\n    AWATER10 as WATER,\n    INTPTLAT10 as LATITUDE,\n    INTPTLON10 as LONGITUDE,\n    CO_CODE as COUNTY_CODE,\n    DISTRICT,\n    \"Shape__Area\" as AREA,\n    \"Shape__Length\" as LENGTH,\n    \"geometry\" as GEOMETRY\n\nfrom RAW_PRD.geo_reference.county_boundaries", "relation_name": "ANALYTICS_PRD.analytics.stg_geo_reference__county_boundaries", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.825222Z", "completed_at": "2025-08-19T19:33:49.831822Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.836509Z", "completed_at": "2025-08-19T19:33:49.836517Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.015865802764892578, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.stg_geo_reference__districts", "compiled": true, "compiled_code": "select\n\n    DISTRICT,\n    \"Region\" as REGION,\n    \"Shape__Area\" as AREA,\n    \"Shape__Length\" as LENGTH,\n    \"geometry\" as GEOMETRY\n\nfrom RAW_PRD.geo_reference.districts", "relation_name": "ANALYTICS_PRD.analytics.stg_geo_reference__districts", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.832866Z", "completed_at": "2025-08-19T19:33:49.840911Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.844225Z", "completed_at": "2025-08-19T19:33:49.844237Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.015474557876586914, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.stg_geo_reference__shn_lines", "compiled": true, "compiled_code": "select\n\n    /* RteSuffix was dropped because less than 1% of it\n    was filled and as such it didn't seem very useful.\n    Route is very similar to RouteS and was therefore dropped\n    as well. */\n\n    \"RouteS\" as ROUTE_WITH_SUFFIX,\n    \"PMRouteID\" as PM_ROUTE_ID,\n    \"County\" as COUNTY,\n    \"District\" as DISTRICT,\n    \"PMPrefix\" as PM_PREFIX,\n    \"bPM\" as BPM,\n    \"ePM\" as EPM,\n    \"PMSuffix\" as PM_SUFFIX,\n    \"bPMc\" as BPMC,\n    \"ePMc\" as EPMC,\n    \"bOdometer\" as B_ODOMETER,\n    \"eOdometer\" as E_ODOMETER,\n    \"AlignCode\" as ALIGN_CODE,\n    \"RouteType\" as ROUTE_TYPE,\n    \"Direction\" as DIRECTION,\n    \"Shape__Length\" as LENGTH,\n    \"geometry\" as GEOMETRY\n\nfrom RAW_PRD.geo_reference.shn_lines", "relation_name": "ANALYTICS_PRD.analytics.stg_geo_reference__shn_lines", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.841497Z", "completed_at": "2025-08-19T19:33:49.843017Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.845040Z", "completed_at": "2025-08-19T19:33:49.845049Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.012789249420166016, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.caldata_mdsa_caltrans_pems.cities", "compiled": null, "compiled_code": null, "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.837872Z", "completed_at": "2025-08-19T19:33:49.846335Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.850028Z", "completed_at": "2025-08-19T19:33:49.850036Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.018793821334838867, "adapter_response": {}, "message": null, "failures": null, "unique_id": "operation.caldata_mdsa_caltrans_pems.caldata_mdsa_caltrans_pems-on-run-start-0", "compiled": true, "compiled_code": "\n\n    \n\nCREATE OR REPLACE FUNCTION ANALYTICS_PRD.public.exponential_smooth(\"VALUE\" FLOAT, \"FACTOR\" FLOAT)\nRETURNS TABLE (\"VALUE_SMOOTHED\" FLOAT)\nLANGUAGE PYTHON\nRUNTIME_VERSION = '3.11'\nHANDLER = 'Smoother'\nAS $$\nclass Smoother:\n    def __init__(self):\n        self.previous_value = None\n\n    def process(self, value, factor):\n        if value is None or factor is None:\n            yield_value = None\n        else:\n            # If previous value was null, substitute current value.\n            previous_value = self.previous_value if self.previous_value is not None else value\n            yield_value = value * factor + (1-factor) * previous_value\n\n        self.previous_value = yield_value\n        yield (yield_value,)\n$$\n\n;\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.848016Z", "completed_at": "2025-08-19T19:33:49.849513Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.851859Z", "completed_at": "2025-08-19T19:33:49.851869Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.00828409194946289, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.caldata_mdsa_caltrans_pems.counties", "compiled": null, "compiled_code": null, "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.855406Z", "completed_at": "2025-08-19T19:33:49.856883Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.860467Z", "completed_at": "2025-08-19T19:33:49.860479Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.00974273681640625, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.caldata_mdsa_caltrans_pems.detector_station_types", "compiled": null, "compiled_code": null, "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.857415Z", "completed_at": "2025-08-19T19:33:49.858932Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.861253Z", "completed_at": "2025-08-19T19:33:49.861261Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.010007619857788086, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.caldata_mdsa_caltrans_pems.diagnostic_threshold_values", "compiled": null, "compiled_code": null, "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.862622Z", "completed_at": "2025-08-19T19:33:49.864125Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.869629Z", "completed_at": "2025-08-19T19:33:49.869639Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.014919757843017578, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.caldata_mdsa_caltrans_pems.districts", "compiled": null, "compiled_code": null, "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.865988Z", "completed_at": "2025-08-19T19:33:49.869097Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.871679Z", "completed_at": "2025-08-19T19:33:49.871687Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.012308597564697266, "adapter_response": {}, "message": null, "failures": null, "unique_id": "seed.caldata_mdsa_caltrans_pems.states", "compiled": null, "compiled_code": null, "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.879463Z", "completed_at": "2025-08-19T19:33:49.893737Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.895113Z", "completed_at": "2025-08-19T19:33:49.895124Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.024082422256469727, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.dbt_utils_source_unique_combination_of_columns_db96_detector_config_log_detector_id__time_id.3dc584c5d3", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        detector_id, time_id\n    from RAW_PRD.db96.detector_config_log\n    group by detector_id, time_id\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.875119Z", "completed_at": "2025-08-19T19:33:49.894413Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.895995Z", "completed_at": "2025-08-19T19:33:49.896006Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.02550053596496582, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.dbt_utils_source_unique_combination_of_columns_db96_controller_config_log_controller_id__time_id.8e887df6cf", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        controller_id, time_id\n    from RAW_PRD.db96.controller_config_log\n    group by controller_id, time_id\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.889933Z", "completed_at": "2025-08-19T19:33:49.896759Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.898997Z", "completed_at": "2025-08-19T19:33:49.899006Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.015327930450439453, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.source_not_empty_db96_controller_config_.0d08a5e84f", "compiled": true, "compiled_code": "\n\nwith validation as (\n   select count(0) as num_rows\n   from RAW_PRD.db96.controller_config\n),\n\nvalidation_errors as (\n   select num_rows\n   from validation\n   where num_rows = 0\n)\n\nselect * from validation_errors\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.885670Z", "completed_at": "2025-08-19T19:33:49.897930Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.900335Z", "completed_at": "2025-08-19T19:33:49.900346Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.025861740112304688, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.dbt_utils_source_unique_combination_of_columns_db96_station_config_log_station_id__time_id.6157a011ae", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        station_id, time_id\n    from RAW_PRD.db96.station_config_log\n    group by station_id, time_id\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.904678Z", "completed_at": "2025-08-19T19:33:49.914208Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.922961Z", "completed_at": "2025-08-19T19:33:49.922970Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.023255109786987305, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.source_not_empty_db96_controller_config_log_.9a685f5015", "compiled": true, "compiled_code": "\n\nwith validation as (\n   select count(0) as num_rows\n   from RAW_PRD.db96.controller_config_log\n),\n\nvalidation_errors as (\n   select num_rows\n   from validation\n   where num_rows = 0\n)\n\nselect * from validation_errors\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.909297Z", "completed_at": "2025-08-19T19:33:49.918491Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.923866Z", "completed_at": "2025-08-19T19:33:49.923877Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.02276301383972168, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.source_not_empty_db96_detector_config_.37c2ba5fb6", "compiled": true, "compiled_code": "\n\nwith validation as (\n   select count(0) as num_rows\n   from RAW_PRD.db96.detector_config\n),\n\nvalidation_errors as (\n   select num_rows\n   from validation\n   where num_rows = 0\n)\n\nselect * from validation_errors\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.914760Z", "completed_at": "2025-08-19T19:33:49.924612Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.926896Z", "completed_at": "2025-08-19T19:33:49.926907Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.022861480712890625, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.source_not_empty_db96_detector_config_log_.2de5555832", "compiled": true, "compiled_code": "\n\nwith validation as (\n   select count(0) as num_rows\n   from RAW_PRD.db96.detector_config_log\n),\n\nvalidation_errors as (\n   select num_rows\n   from validation\n   where num_rows = 0\n)\n\nselect * from validation_errors\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.919123Z", "completed_at": "2025-08-19T19:33:49.926382Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.928791Z", "completed_at": "2025-08-19T19:33:49.928802Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.020343542098999023, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.source_not_empty_db96_station_config_.31b0f54c1e", "compiled": true, "compiled_code": "\n\nwith validation as (\n   select count(0) as num_rows\n   from RAW_PRD.db96.station_config\n),\n\nvalidation_errors as (\n   select num_rows\n   from validation\n   where num_rows = 0\n)\n\nselect * from validation_errors\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.932234Z", "completed_at": "2025-08-19T19:33:49.949805Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.954938Z", "completed_at": "2025-08-19T19:33:49.954951Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.027323484420776367, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.source_not_empty_db96_station_config_log_.4844ae5c4e", "compiled": true, "compiled_code": "\n\nwith validation as (\n   select count(0) as num_rows\n   from RAW_PRD.db96.station_config_log\n),\n\nvalidation_errors as (\n   select num_rows\n   from validation\n   where num_rows = 0\n)\n\nselect * from validation_errors\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.937397Z", "completed_at": "2025-08-19T19:33:49.950336Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.956419Z", "completed_at": "2025-08-19T19:33:49.956430Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.02827906608581543, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.source_unique_db96_controller_config_controller_id.cd75d813b7", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    controller_id as unique_field,\n    count(*) as n_records\n\nfrom RAW_PRD.db96.controller_config\nwhere controller_id is not null\ngroup by controller_id\nhaving count(*) > 1\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.946027Z", "completed_at": "2025-08-19T19:33:49.955919Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.957923Z", "completed_at": "2025-08-19T19:33:49.957931Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.026333332061767578, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.source_unique_db96_detector_config_detector_id.c1a0cde27d", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    detector_id as unique_field,\n    count(*) as n_records\n\nfrom RAW_PRD.db96.detector_config\nwhere detector_id is not null\ngroup by detector_id\nhaving count(*) > 1\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.950890Z", "completed_at": "2025-08-19T19:33:49.958674Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.960885Z", "completed_at": "2025-08-19T19:33:49.960893Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.0168609619140625, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.source_unique_db96_station_config_station_id.f6ea518fb5", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    station_id as unique_field,\n    count(*) as n_records\n\nfrom RAW_PRD.db96.station_config\nwhere station_id is not null\ngroup by station_id\nhaving count(*) > 1\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.964337Z", "completed_at": "2025-08-19T19:33:49.983057Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.987919Z", "completed_at": "2025-08-19T19:33:49.987932Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.028214454650878906, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_stg_clearinghouse__station_raw_ID.8fdaf0ebd1", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect ID\nfrom ANALYTICS_PRD.clearinghouse.stg_clearinghouse__station_raw\nwhere ID is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.974050Z", "completed_at": "2025-08-19T19:33:49.983581Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.988761Z", "completed_at": "2025-08-19T19:33:49.988769Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.027134418487548828, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_stg_clearinghouse__station_raw_SAMPLE_TIMESTAMP.ab5501c249", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect SAMPLE_TIMESTAMP\nfrom ANALYTICS_PRD.clearinghouse.stg_clearinghouse__station_raw\nwhere SAMPLE_TIMESTAMP is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.978232Z", "completed_at": "2025-08-19T19:33:49.989503Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.991840Z", "completed_at": "2025-08-19T19:33:49.991852Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.029190540313720703, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_stg_db96__controller_config_controller_id.305a718762", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect controller_id\nfrom ANALYTICS_PRD.db96.stg_db96__controller_config\nwhere controller_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.984100Z", "completed_at": "2025-08-19T19:33:49.991241Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:49.993693Z", "completed_at": "2025-08-19T19:33:49.993701Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.020355224609375, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.unique_stg_db96__controller_config_controller_id.e076f51952", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    controller_id as unique_field,\n    count(*) as n_records\n\nfrom ANALYTICS_PRD.db96.stg_db96__controller_config\nwhere controller_id is not null\ngroup by controller_id\nhaving count(*) > 1\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.000117Z", "completed_at": "2025-08-19T19:33:50.014049Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.015918Z", "completed_at": "2025-08-19T19:33:50.015928Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.02288198471069336, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_vds__controller_config", "compiled": true, "compiled_code": "\n\nwith config_log as (\n    select * from ANALYTICS_PRD.db96.stg_db96__controller_config_log\n),\n\nconfig as (\n    select * from ANALYTICS_PRD.db96.stg_db96__controller_config\n),\n\nconfig_log_with_validity as (\n    select\n        * exclude (time_id),\n        time_id as _valid_from,\n        lead(time_id) over (partition by controller_id order by time_id asc) as _valid_to\n    from config_log\n),\n\nconfig_scd as (\n    select\n        config_log_with_validity.*,\n        config.controller_type,\n        config.district,\n        config.county,\n        config.city,\n        config.freeway,\n        config.direction\n    from config_log_with_validity\n    left join config\n        on config_log_with_validity.controller_id = config.controller_id\n    where config_log_with_validity.status = 1\n)\n\nselect * from config_scd", "relation_name": "ANALYTICS_PRD.vds.int_vds__controller_config", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.007088Z", "completed_at": "2025-08-19T19:33:50.014883Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.016777Z", "completed_at": "2025-08-19T19:33:50.016789Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.020197153091430664, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_stg_db96__controller_config_log_controller_id.fd4291b6dc", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect controller_id\nfrom ANALYTICS_PRD.db96.stg_db96__controller_config_log\nwhere controller_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:49.997214Z", "completed_at": "2025-08-19T19:33:50.015399Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.018051Z", "completed_at": "2025-08-19T19:33:50.018060Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.025514602661132812, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_clearinghouse__station_status", "compiled": true, "compiled_code": "with station_status as (\n    select * from ANALYTICS_PRD.clearinghouse.stg_clearinghouse__station_status\n),\n\nstatus_dates as (\n    select distinct\n        district,\n        meta_date\n    from station_status\n),\n\nvalidity_dates as (\n    select\n        district,\n        meta_date,\n        meta_date as _valid_from,\n        lead(meta_date) over (partition by district order by meta_date asc) as _valid_to\n    from status_dates\n),\n\nstation_status_scd as (\n    select\n        station_status.*,\n        validity_dates._valid_from,\n        validity_dates._valid_to\n    from station_status\n    inner join validity_dates\n        on\n            station_status.meta_date = validity_dates.meta_date\n            and station_status.district = validity_dates.district\n)\n\nselect * from station_status_scd", "relation_name": "ANALYTICS_PRD.clearinghouse.int_clearinghouse__station_status", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.010983Z", "completed_at": "2025-08-19T19:33:50.017546Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.020036Z", "completed_at": "2025-08-19T19:33:50.020044Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.014896392822265625, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_clearinghouse__station_meta", "compiled": true, "compiled_code": "with station_meta as (\n    select * from ANALYTICS_PRD.clearinghouse.stg_clearinghouse__station_meta\n),\n\nmeta_dates as (\n    select distinct\n        district,\n        meta_date\n    from station_meta\n),\n\nvalidity_dates as (\n    select\n        district,\n        meta_date,\n        meta_date as _valid_from,\n        lead(meta_date) over (partition by district order by meta_date asc) as _valid_to\n    from meta_dates\n),\n\nstation_meta_scd as (\n    select\n        station_meta.*,\n        validity_dates._valid_from,\n        validity_dates._valid_to\n    from station_meta\n    inner join validity_dates\n        on\n            station_meta.meta_date = validity_dates.meta_date\n            and station_meta.district = validity_dates.district\n)\n\nselect * from station_meta_scd", "relation_name": "ANALYTICS_PRD.clearinghouse.int_clearinghouse__station_meta", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.029922Z", "completed_at": "2025-08-19T19:33:50.042899Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.044180Z", "completed_at": "2025-08-19T19:33:50.044188Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.022016286849975586, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_stg_db96__detector_config_log_detector_id.c96cf05de1", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect detector_id\nfrom ANALYTICS_PRD.db96.stg_db96__detector_config_log\nwhere detector_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.026147Z", "completed_at": "2025-08-19T19:33:50.043539Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.045520Z", "completed_at": "2025-08-19T19:33:50.045528Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.024117469787597656, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_stg_clearinghouse__station_meta_ID.8bb6e726cd", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect ID\nfrom ANALYTICS_PRD.clearinghouse.stg_clearinghouse__station_meta\nwhere ID is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.034602Z", "completed_at": "2025-08-19T19:33:50.044987Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.047397Z", "completed_at": "2025-08-19T19:33:50.047405Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.02393651008605957, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_stg_db96__detector_config_detector_id.4b1b87d07c", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect detector_id\nfrom ANALYTICS_PRD.db96.stg_db96__detector_config\nwhere detector_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.038752Z", "completed_at": "2025-08-19T19:33:50.046835Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.049250Z", "completed_at": "2025-08-19T19:33:50.049258Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.024219989776611328, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.unique_stg_db96__detector_config_detector_id.94c6915b93", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    detector_id as unique_field,\n    count(*) as n_records\n\nfrom ANALYTICS_PRD.db96.stg_db96__detector_config\nwhere detector_id is not null\ngroup by detector_id\nhaving count(*) > 1\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.053250Z", "completed_at": "2025-08-19T19:33:50.067847Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.072559Z", "completed_at": "2025-08-19T19:33:50.072570Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.023943662643432617, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_stg_db96__station_config_station_id.4cf48b71ea", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect station_id\nfrom ANALYTICS_PRD.db96.stg_db96__station_config\nwhere station_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.058261Z", "completed_at": "2025-08-19T19:33:50.073472Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.075136Z", "completed_at": "2025-08-19T19:33:50.075145Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.024618864059448242, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.unique_stg_db96__station_config_station_id.d0d27cec9b", "compiled": true, "compiled_code": "\n    \n    \n\nselect\n    station_id as unique_field,\n    count(*) as n_records\n\nfrom ANALYTICS_PRD.db96.stg_db96__station_config\nwhere station_id is not null\ngroup by station_id\nhaving count(*) > 1\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.062834Z", "completed_at": "2025-08-19T19:33:50.074627Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.077054Z", "completed_at": "2025-08-19T19:33:50.077063Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.02494668960571289, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_vds__station_config", "compiled": true, "compiled_code": "\n\nwith config_log as (\n    select * from ANALYTICS_PRD.db96.stg_db96__station_config_log\n),\n\nconfig as (\n    select * from ANALYTICS_PRD.db96.stg_db96__station_config\n),\n\nconfig_log_with_validity as (\n    select\n        * exclude (time_id),\n        time_id as _valid_from,\n        lead(time_id) over (partition by station_id order by time_id asc) as _valid_to\n    from config_log\n),\n\nconfig_scd as (\n    select\n        config_log_with_validity.*,\n        config.station_type,\n        config.district,\n        config.county,\n        config.city,\n        config.freeway,\n        config.direction\n    from config_log_with_validity\n    left join config\n        on config_log_with_validity.station_id = config.station_id\n    where config_log_with_validity.status = 1\n)\n\nselect * from config_scd", "relation_name": "ANALYTICS_PRD.vds.int_vds__station_config", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.068481Z", "completed_at": "2025-08-19T19:33:50.076550Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.078914Z", "completed_at": "2025-08-19T19:33:50.078923Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.021898984909057617, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_stg_db96__station_config_log_station_id.97d2183445", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect station_id\nfrom ANALYTICS_PRD.db96.stg_db96__station_config_log\nwhere station_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.081156Z", "completed_at": "2025-08-19T19:33:50.101347Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.105909Z", "completed_at": "2025-08-19T19:33:50.105920Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.030000925064086914, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_db96__detector_agg_five_minutes", "compiled": true, "compiled_code": "\n\n\nwith raw as (\n    select\n        *,\n        /* Create a timestamp truncated down to the nearest five\n         minute bucket. This will be the the timestamp on which\n         we aggregate. If a 30-second interval straddles two different\n         buckets, it will be assigned to the one latter one due to\n         the floor() call.\n        */\n        dateadd(\n            'minute',\n            floor(minute(sample_timestamp) / 5) * 5,\n            trunc(sample_timestamp, 'hour')\n        ) as sample_timestamp_trunc\n    from ANALYTICS_PRD.db96.stg_db96__vds30sec\n    where \n    1=1\n    \n),\n\nagg as (\n    select\n        id,\n        sample_date,\n        sample_timestamp_trunc as sample_timestamp,\n        district,\n        \n            sum(volume_1) as volume_1,\n        \n            sum(volume_2) as volume_2,\n        \n            sum(volume_3) as volume_3,\n        \n            sum(volume_4) as volume_4,\n        \n            sum(volume_5) as volume_5,\n        \n            sum(volume_6) as volume_6,\n        \n            sum(volume_7) as volume_7,\n        \n            sum(volume_8) as volume_8,\n        \n            sum(volume_9) as volume_9,\n        \n            sum(volume_10) as volume_10,\n        \n            sum(volume_11) as volume_11,\n        \n            sum(volume_12) as volume_12,\n        \n            sum(volume_13) as volume_13,\n        \n            sum(volume_14) as volume_14,\n        \n        \n            avg(occupancy_1) as occupancy_1,\n        \n            avg(occupancy_2) as occupancy_2,\n        \n            avg(occupancy_3) as occupancy_3,\n        \n            avg(occupancy_4) as occupancy_4,\n        \n            avg(occupancy_5) as occupancy_5,\n        \n            avg(occupancy_6) as occupancy_6,\n        \n            avg(occupancy_7) as occupancy_7,\n        \n            avg(occupancy_8) as occupancy_8,\n        \n            avg(occupancy_9) as occupancy_9,\n        \n            avg(occupancy_10) as occupancy_10,\n        \n            avg(occupancy_11) as occupancy_11,\n        \n            avg(occupancy_12) as occupancy_12,\n        \n            avg(occupancy_13) as occupancy_13,\n        \n            avg(occupancy_14) as occupancy_14,\n        \n        \n            avg(speed_1) as speed_1\n            \n                ,\n            \n        \n            avg(speed_2) as speed_2\n            \n                ,\n            \n        \n            avg(speed_3) as speed_3\n            \n                ,\n            \n        \n            avg(speed_4) as speed_4\n            \n                ,\n            \n        \n            avg(speed_5) as speed_5\n            \n                ,\n            \n        \n            avg(speed_6) as speed_6\n            \n                ,\n            \n        \n            avg(speed_7) as speed_7\n            \n                ,\n            \n        \n            avg(speed_8) as speed_8\n            \n                ,\n            \n        \n            avg(speed_9) as speed_9\n            \n                ,\n            \n        \n            avg(speed_10) as speed_10\n            \n                ,\n            \n        \n            avg(speed_11) as speed_11\n            \n                ,\n            \n        \n            avg(speed_12) as speed_12\n            \n                ,\n            \n        \n            avg(speed_13) as speed_13\n            \n                ,\n            \n        \n            avg(speed_14) as speed_14\n            \n        \n    from raw\n    group by id, sample_date, sample_timestamp_trunc, district\n),\n\n\n    agg_1 as (\n        select\n            id,\n            sample_date,\n            sample_timestamp,\n            district,\n            1 as lane,\n            volume_1 as flow,\n            occupancy_1 as occupancy,\n            speed_1 as speed\n        from agg\n    ),\n\n    agg_2 as (\n        select\n            id,\n            sample_date,\n            sample_timestamp,\n            district,\n            2 as lane,\n            volume_2 as flow,\n            occupancy_2 as occupancy,\n            speed_2 as speed\n        from agg\n    ),\n\n    agg_3 as (\n        select\n            id,\n            sample_date,\n            sample_timestamp,\n            district,\n            3 as lane,\n            volume_3 as flow,\n            occupancy_3 as occupancy,\n            speed_3 as speed\n        from agg\n    ),\n\n    agg_4 as (\n        select\n            id,\n            sample_date,\n            sample_timestamp,\n            district,\n            4 as lane,\n            volume_4 as flow,\n            occupancy_4 as occupancy,\n            speed_4 as speed\n        from agg\n    ),\n\n    agg_5 as (\n        select\n            id,\n            sample_date,\n            sample_timestamp,\n            district,\n            5 as lane,\n            volume_5 as flow,\n            occupancy_5 as occupancy,\n            speed_5 as speed\n        from agg\n    ),\n\n    agg_6 as (\n        select\n            id,\n            sample_date,\n            sample_timestamp,\n            district,\n            6 as lane,\n            volume_6 as flow,\n            occupancy_6 as occupancy,\n            speed_6 as speed\n        from agg\n    ),\n\n    agg_7 as (\n        select\n            id,\n            sample_date,\n            sample_timestamp,\n            district,\n            7 as lane,\n            volume_7 as flow,\n            occupancy_7 as occupancy,\n            speed_7 as speed\n        from agg\n    ),\n\n    agg_8 as (\n        select\n            id,\n            sample_date,\n            sample_timestamp,\n            district,\n            8 as lane,\n            volume_8 as flow,\n            occupancy_8 as occupancy,\n            speed_8 as speed\n        from agg\n    ),\n\n    agg_9 as (\n        select\n            id,\n            sample_date,\n            sample_timestamp,\n            district,\n            9 as lane,\n            volume_9 as flow,\n            occupancy_9 as occupancy,\n            speed_9 as speed\n        from agg\n    ),\n\n    agg_10 as (\n        select\n            id,\n            sample_date,\n            sample_timestamp,\n            district,\n            10 as lane,\n            volume_10 as flow,\n            occupancy_10 as occupancy,\n            speed_10 as speed\n        from agg\n    ),\n\n    agg_11 as (\n        select\n            id,\n            sample_date,\n            sample_timestamp,\n            district,\n            11 as lane,\n            volume_11 as flow,\n            occupancy_11 as occupancy,\n            speed_11 as speed\n        from agg\n    ),\n\n    agg_12 as (\n        select\n            id,\n            sample_date,\n            sample_timestamp,\n            district,\n            12 as lane,\n            volume_12 as flow,\n            occupancy_12 as occupancy,\n            speed_12 as speed\n        from agg\n    ),\n\n    agg_13 as (\n        select\n            id,\n            sample_date,\n            sample_timestamp,\n            district,\n            13 as lane,\n            volume_13 as flow,\n            occupancy_13 as occupancy,\n            speed_13 as speed\n        from agg\n    ),\n\n    agg_14 as (\n        select\n            id,\n            sample_date,\n            sample_timestamp,\n            district,\n            14 as lane,\n            volume_14 as flow,\n            occupancy_14 as occupancy,\n            speed_14 as speed\n        from agg\n    ),\n\n\nagg_unioned as (\n    \n        select * from agg_1\n        union all\n    \n        select * from agg_2\n        union all\n    \n        select * from agg_3\n        union all\n    \n        select * from agg_4\n        union all\n    \n        select * from agg_5\n        union all\n    \n        select * from agg_6\n        union all\n    \n        select * from agg_7\n        union all\n    \n        select * from agg_8\n        union all\n    \n        select * from agg_9\n        union all\n    \n        select * from agg_10\n        union all\n    \n        select * from agg_11\n        union all\n    \n        select * from agg_12\n        union all\n    \n        select * from agg_13\n        union all\n    \n        select * from agg_14\n        \n    \n)\n\nselect * from agg_unioned", "relation_name": "ANALYTICS_PRD.db96.int_db96__detector_agg_five_minutes", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.097322Z", "completed_at": "2025-08-19T19:33:50.107038Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.108221Z", "completed_at": "2025-08-19T19:33:50.108233Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.017955303192138672, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_vds__controller_config__valid_from.c3d32ffb6e", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect _valid_from\nfrom ANALYTICS_PRD.vds.int_vds__controller_config\nwhere _valid_from is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.102008Z", "completed_at": "2025-08-19T19:33:50.109034Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.111244Z", "completed_at": "2025-08-19T19:33:50.111253Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.019899368286132812, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_vds__controller_config_controller_id.b389c43d70", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect controller_id\nfrom ANALYTICS_PRD.vds.int_vds__controller_config\nwhere controller_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.092621Z", "completed_at": "2025-08-19T19:33:50.110127Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.112549Z", "completed_at": "2025-08-19T19:33:50.112557Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.03213810920715332, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.dbt_utils_unique_combination_of_columns_int_vds__controller_config_CONTROLLER_ID___VALID_TO.891389041c", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        CONTROLLER_ID, _VALID_TO\n    from ANALYTICS_PRD.vds.int_vds__controller_config\n    group by CONTROLLER_ID, _VALID_TO\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.114392Z", "completed_at": "2025-08-19T19:33:50.127179Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.137016Z", "completed_at": "2025-08-19T19:33:50.137026Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.027496337890625, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.accepted_values_int_clearinghouse__station_status_DISTRICT___var_districts_.cc346c7114", "compiled": true, "compiled_code": "\n    \n    \n\nwith all_values as (\n\n    select\n        DISTRICT as value_field,\n        count(*) as n_records\n\n    from ANALYTICS_PRD.clearinghouse.int_clearinghouse__station_status\n    group by DISTRICT\n\n)\n\nselect *\nfrom all_values\nwhere value_field not in (\n    '1','2','3','4','5','6','7','8','9','10','11','12'\n)\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.121634Z", "completed_at": "2025-08-19T19:33:50.137833Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.139181Z", "completed_at": "2025-08-19T19:33:50.139192Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.025986433029174805, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.dbt_utils_unique_combination_of_columns_int_clearinghouse__station_status_META_DATE__DETECTOR_ID.18b89f5a20", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        META_DATE, DETECTOR_ID\n    from ANALYTICS_PRD.clearinghouse.int_clearinghouse__station_status\n    group by META_DATE, DETECTOR_ID\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.131575Z", "completed_at": "2025-08-19T19:33:50.139945Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.142229Z", "completed_at": "2025-08-19T19:33:50.142238Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.021283626556396484, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__station_status_META_DATE.4f088cd5af", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect META_DATE\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__station_status\nwhere META_DATE is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.127717Z", "completed_at": "2025-08-19T19:33:50.141156Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.143594Z", "completed_at": "2025-08-19T19:33:50.143602Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.023212194442749023, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__station_status_DETECTOR_ID.532974a9c9", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect DETECTOR_ID\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__station_status\nwhere DETECTOR_ID is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.145608Z", "completed_at": "2025-08-19T19:33:50.155781Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.157570Z", "completed_at": "2025-08-19T19:33:50.157579Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.01703810691833496, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__station_status_STATION_ID.374fb2576e", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect STATION_ID\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__station_status\nwhere STATION_ID is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.151757Z", "completed_at": "2025-08-19T19:33:50.163166Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.168767Z", "completed_at": "2025-08-19T19:33:50.168778Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.024529218673706055, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.accepted_values_int_clearinghouse__station_meta_DIRECTION__N__E__S__W__n__e__s__w.e55615f4f4", "compiled": true, "compiled_code": "\n    \n    \n\nwith all_values as (\n\n    select\n        DIRECTION as value_field,\n        count(*) as n_records\n\n    from ANALYTICS_PRD.clearinghouse.int_clearinghouse__station_meta\n    group by DIRECTION\n\n)\n\nselect *\nfrom all_values\nwhere value_field not in (\n    'N','E','S','W','n','e','s','w'\n)\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.158420Z", "completed_at": "2025-08-19T19:33:50.170360Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.172514Z", "completed_at": "2025-08-19T19:33:50.172525Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.02203202247619629, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.accepted_values_int_clearinghouse__station_meta_DISTRICT___var_districts_.2eb8658b67", "compiled": true, "compiled_code": "\n    \n    \n\nwith all_values as (\n\n    select\n        DISTRICT as value_field,\n        count(*) as n_records\n\n    from ANALYTICS_PRD.clearinghouse.int_clearinghouse__station_meta\n    group by DISTRICT\n\n)\n\nselect *\nfrom all_values\nwhere value_field not in (\n    '1','2','3','4','5','6','7','8','9','10','11','12'\n)\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.163806Z", "completed_at": "2025-08-19T19:33:50.170878Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.173292Z", "completed_at": "2025-08-19T19:33:50.173299Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.022233247756958008, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__station_meta_ID.24794e5a3f", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect ID\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__station_meta\nwhere ID is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.174618Z", "completed_at": "2025-08-19T19:33:50.181451Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.186723Z", "completed_at": "2025-08-19T19:33:50.186736Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.017046689987182617, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__station_meta_META_DATE.a86396f7b0", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect META_DATE\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__station_meta\nwhere META_DATE is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.181970Z", "completed_at": "2025-08-19T19:33:50.202083Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.204408Z", "completed_at": "2025-08-19T19:33:50.204420Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.03044891357421875, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.geo__current_stations", "compiled": true, "compiled_code": "with station_config as (\n    select * from ANALYTICS_PRD.vds.int_vds__station_config\n),\n\ncurrent_stations as (\n    select\n        * exclude (_valid_from, _valid_to),\n        st_makepoint(longitude, latitude) as geometry\n    from station_config\n    where _valid_to is null\n),\n\ncurrent_stationsc as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            current_stations.*,\n            c.county_name,\n            c.county_abb\n        from current_stations\n        inner join county as c\n        on current_stations.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\ncurrent_stationscc as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from current_stationsc as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n)\n\nselect * from current_stationscc", "relation_name": "ANALYTICS_PRD.geo.geo__current_stations", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.194583Z", "completed_at": "2025-08-19T19:33:50.205155Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.209840Z", "completed_at": "2025-08-19T19:33:50.209849Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.02898883819580078, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_vds__detector_config", "compiled": true, "compiled_code": "\n\nwith config_log as (\n    select * from ANALYTICS_PRD.db96.stg_db96__detector_config_log\n),\n\nconfig as (\n    select * from ANALYTICS_PRD.db96.stg_db96__detector_config\n),\n\nstation_config as (\n    select * from ANALYTICS_PRD.vds.int_vds__station_config\n),\n\nconfig_log_with_validity as (\n    select\n        *,\n        time_id as _valid_from,\n        lead(time_id) over (partition by detector_id order by time_id asc) as _valid_to\n    from config_log\n),\n\nconfig_scd as (\n    select\n        config_log_with_validity.detector_id,\n        config_log_with_validity.station_id,\n        config_log_with_validity.status,\n        config_log_with_validity.lane,\n        config.detector_type,\n        station_config.station_type,\n        station_config.district,\n        station_config.county,\n        station_config.city,\n        station_config.freeway,\n        station_config.direction,\n        station_config.length,\n        station_config.state_postmile,\n        station_config.absolute_postmile,\n        station_config.latitude,\n        station_config.longitude,\n        station_config.physical_lanes,\n        config_log_with_validity._valid_from,\n        config_log_with_validity._valid_to\n    from config_log_with_validity\n    left join config\n        on config_log_with_validity.detector_id = config.detector_id\n    left join station_config\n        on\n            config_log_with_validity.station_id = station_config.station_id\n            and\n            \n\n    config_log_with_validity._valid_from >= station_config._valid_from\n    and ( config_log_with_validity._valid_from < station_config._valid_to or station_config._valid_to is null)\n\n\n    where config_log_with_validity.status = 1\n)\n\nselect * from config_scd", "relation_name": "ANALYTICS_PRD.vds.int_vds__detector_config", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.205762Z", "completed_at": "2025-08-19T19:33:50.211823Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.213739Z", "completed_at": "2025-08-19T19:33:50.213750Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.012691020965576172, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_vds__nearby_stations", "compiled": true, "compiled_code": "\n\nwith station_meta as (\n    select * from ANALYTICS_PRD.vds.int_vds__station_config\n),\n\nstation_pairs as (\n    select\n        a.station_id,\n        b.station_id as other_station_id,\n        a.district,\n        a.freeway,\n        a.direction,\n        a.station_type,\n        b.absolute_postmile - a.absolute_postmile as delta_postmile,\n        a._valid_from,\n        a._valid_to\n    from station_meta as a\n    inner join station_meta as b\n        on\n            a.freeway = b.freeway and a.direction = b.direction and a.station_type = b.station_type\n            and a._valid_from = b._valid_from\n    -- Most performance metrics are restricted to mainline and HV lanes.\n    -- Furthermore, when looking at upstream and downstream stations, it\n    -- does not make sense to include, e.g., ramps. So for the time being\n    -- we restrict this table to HV and ML.\n    where a.station_type in ('HV', 'ML')\n),\n\nnearest_downstream_station_pairs as (\n    select\n        station_id,\n        other_station_id,\n        district,\n        freeway,\n        direction,\n        station_type,\n        delta_postmile,\n        _valid_from,\n        _valid_to,\n        row_number() over (partition by station_id, _valid_from order by abs(delta_postmile) asc)\n            as distance_ranking\n    from station_pairs\n    where\n        delta_postmile > 0\n        and delta_postmile <= 5.0\n        and station_id != other_station_id\n),\n\nnearest_upstream_station_pairs as (\n    select\n        station_id,\n        other_station_id,\n        district,\n        freeway,\n        direction,\n        station_type,\n        delta_postmile,\n        _valid_from,\n        _valid_to,\n        row_number() over (partition by station_id, _valid_from order by abs(delta_postmile) asc)\n            as distance_ranking\n    from station_pairs\n    where\n        delta_postmile < 0\n        and delta_postmile >= -5.0\n        and station_id != other_station_id\n),\n\nself_pairs as (\n    select\n        *,\n        0 as distance_ranking\n    from station_pairs\n    where station_id = other_station_id\n),\n\nnearest_station_pairs as (\n    select\n        station_id,\n        other_station_id,\n        district,\n        freeway,\n        direction,\n        station_type,\n        delta_postmile,\n        _valid_from,\n        _valid_to,\n        distance_ranking\n    from self_pairs\n    union all\n    select\n        station_id,\n        other_station_id,\n        district,\n        freeway,\n        direction,\n        station_type,\n        delta_postmile,\n        _valid_from,\n        _valid_to,\n        distance_ranking\n    from nearest_downstream_station_pairs\n    union all\n    select\n        station_id,\n        other_station_id,\n        district,\n        freeway,\n        direction,\n        station_type,\n        delta_postmile,\n        _valid_from,\n        _valid_to,\n        distance_ranking\n    from nearest_upstream_station_pairs\n    order by district asc, freeway asc, station_id asc\n),\n\n-- assign the tag that is qulified for local and regional regression\nnearest_station_pairs_with_tag as (\n    select\n        *,\n        distance_ranking <= 1 as other_station_is_local\n    from nearest_station_pairs\n)\n\nselect * from nearest_station_pairs_with_tag", "relation_name": "ANALYTICS_PRD.vds.int_vds__nearby_stations", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.214524Z", "completed_at": "2025-08-19T19:33:50.224496Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.226150Z", "completed_at": "2025-08-19T19:33:50.226161Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.015502691268920898, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.dbt_utils_unique_combination_of_columns_int_vds__station_config_STATION_ID___VALID_TO.6a789d00e0", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        STATION_ID, _VALID_TO\n    from ANALYTICS_PRD.vds.int_vds__station_config\n    group by STATION_ID, _VALID_TO\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.219856Z", "completed_at": "2025-08-19T19:33:50.225643Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.230871Z", "completed_at": "2025-08-19T19:33:50.230881Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.017940998077392578, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_vds__station_config__valid_from.367ed1e9b5", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect _valid_from\nfrom ANALYTICS_PRD.vds.int_vds__station_config\nwhere _valid_from is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.226950Z", "completed_at": "2025-08-19T19:33:50.233603Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.235201Z", "completed_at": "2025-08-19T19:33:50.235209Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.01139068603515625, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_vds__station_config_station_id.d834fe2c05", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect station_id\nfrom ANALYTICS_PRD.vds.int_vds__station_config\nwhere station_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.236496Z", "completed_at": "2025-08-19T19:33:50.261247Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.261790Z", "completed_at": "2025-08-19T19:33:50.261799Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.0288238525390625, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.geo__current_detectors", "compiled": true, "compiled_code": "with detector_config as (\n    select * from ANALYTICS_PRD.vds.int_vds__detector_config\n),\n\ncurrent_detectors as (\n    select\n        * exclude (_valid_from, _valid_to),\n        st_makepoint(longitude, latitude) as geometry\n    from detector_config\n    where _valid_to is null\n),\n\ncurrent_detectorsc as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            current_detectors.*,\n            c.county_name,\n            c.county_abb\n        from current_detectors\n        inner join county as c\n        on current_detectors.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\ncurrent_detectorscc as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from current_detectorsc as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n)\n\nselect * from current_detectorscc", "relation_name": "ANALYTICS_PRD.geo.geo__current_detectors", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.252096Z", "completed_at": "2025-08-19T19:33:50.263674Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.265206Z", "completed_at": "2025-08-19T19:33:50.265214Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.01953744888305664, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_performance__max_capacity", "compiled": true, "compiled_code": "/*\nThis model currently uses a maximum capacity of 2076 vehicles/lane/hour for all detectors.\nUsing this value provides a consistent metric for determining the capcacity and\ncalculating the lost productivity.\n\nThe current methodology in PeMS uses the max of either the 15 minute historical highest\nflow or 2076 v/l/h as the capacity at each location per PeMS website:\nhttps://pems.dot.ca.gov/?dnode=Help&content=help_calc#perf\n\nThe issue with the current methodology is that there is no documentation for how the historical\nmeasured maximum capacity has been developed and we have observed inconsistencies in high flow\nvalues in PeMS. We also do not have any documention on why a 15-minute timeframe was selected\nand how that value is used to compute the 5-minute aggregation level of the lost productivity\nperformance metric.\n*/\n\nwith\n\nsource as (\n    select *\n    from ANALYTICS_PRD.vds.int_vds__detector_config\n),\n\nmax_capacity_detector as (\n    select distinct\n        detector_id,\n        /*\n        2076 v/l/h / 12 = 173 v/l/5-min\n        */\n        173 as max_capacity_5min\n    from source\n)\n\nselect * from max_capacity_detector", "relation_name": "ANALYTICS_PRD.performance.int_performance__max_capacity", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.240457Z", "completed_at": "2025-08-19T19:33:50.264180Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.265962Z", "completed_at": "2025-08-19T19:33:50.265970Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.0319521427154541, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_clearinghouse__detector_agg_five_minutes", "compiled": true, "compiled_code": "\n\n\nwith raw as (\n    select\n        *,\n        /* Create a timestamp truncated down to the nearest five\n         minute bucket. This will be the the timestamp on which\n         we aggregate. If a 30-second interval straddles two different\n         buckets, it will be assigned to the one latter one due to\n         the floor() call.\n        */\n        dateadd(\n            'minute',\n            floor(minute(sample_timestamp) / 5) * 5,\n            trunc(sample_timestamp, 'hour')\n        ) as sample_timestamp_trunc\n    from ANALYTICS_PRD.clearinghouse.stg_clearinghouse__station_raw\n\n    where \n    1=1\n    \n),\n\ndmeta as (\n    select * from ANALYTICS_PRD.vds.int_vds__detector_config\n),\n\nagg as (\n    select\n        id as station_id,\n        sample_date,\n        sample_timestamp_trunc as sample_timestamp,\n        district,\n        \n            sum(volume_1) as volume_1,\n        \n            sum(volume_2) as volume_2,\n        \n            sum(volume_3) as volume_3,\n        \n            sum(volume_4) as volume_4,\n        \n            sum(volume_5) as volume_5,\n        \n            sum(volume_6) as volume_6,\n        \n            sum(volume_7) as volume_7,\n        \n            sum(volume_8) as volume_8,\n        \n        \n            count_if(volume_1 = 0) as zero_vol_ct_1,\n        \n            count_if(volume_2 = 0) as zero_vol_ct_2,\n        \n            count_if(volume_3 = 0) as zero_vol_ct_3,\n        \n            count_if(volume_4 = 0) as zero_vol_ct_4,\n        \n            count_if(volume_5 = 0) as zero_vol_ct_5,\n        \n            count_if(volume_6 = 0) as zero_vol_ct_6,\n        \n            count_if(volume_7 = 0) as zero_vol_ct_7,\n        \n            count_if(volume_8 = 0) as zero_vol_ct_8,\n        \n        \n            avg(occupancy_1) as occupancy_1,\n        \n            avg(occupancy_2) as occupancy_2,\n        \n            avg(occupancy_3) as occupancy_3,\n        \n            avg(occupancy_4) as occupancy_4,\n        \n            avg(occupancy_5) as occupancy_5,\n        \n            avg(occupancy_6) as occupancy_6,\n        \n            avg(occupancy_7) as occupancy_7,\n        \n            avg(occupancy_8) as occupancy_8,\n        \n        \n            count_if(occupancy_1 = 0) as zero_occ_ct_1,\n        \n            count_if(occupancy_2 = 0) as zero_occ_ct_2,\n        \n            count_if(occupancy_3 = 0) as zero_occ_ct_3,\n        \n            count_if(occupancy_4 = 0) as zero_occ_ct_4,\n        \n            count_if(occupancy_5 = 0) as zero_occ_ct_5,\n        \n            count_if(occupancy_6 = 0) as zero_occ_ct_6,\n        \n            count_if(occupancy_7 = 0) as zero_occ_ct_7,\n        \n            count_if(occupancy_8 = 0) as zero_occ_ct_8,\n        \n        \n            count_if(volume_1 = 0 and occupancy_1 > 0) as zero_vol_pos_occ_ct_1,\n        \n            count_if(volume_2 = 0 and occupancy_2 > 0) as zero_vol_pos_occ_ct_2,\n        \n            count_if(volume_3 = 0 and occupancy_3 > 0) as zero_vol_pos_occ_ct_3,\n        \n            count_if(volume_4 = 0 and occupancy_4 > 0) as zero_vol_pos_occ_ct_4,\n        \n            count_if(volume_5 = 0 and occupancy_5 > 0) as zero_vol_pos_occ_ct_5,\n        \n            count_if(volume_6 = 0 and occupancy_6 > 0) as zero_vol_pos_occ_ct_6,\n        \n            count_if(volume_7 = 0 and occupancy_7 > 0) as zero_vol_pos_occ_ct_7,\n        \n            count_if(volume_8 = 0 and occupancy_8 > 0) as zero_vol_pos_occ_ct_8,\n        \n        \n            count_if(volume_1 > 0 and occupancy_1 = 0) as zero_occ_pos_vol_ct_1,\n        \n            count_if(volume_2 > 0 and occupancy_2 = 0) as zero_occ_pos_vol_ct_2,\n        \n            count_if(volume_3 > 0 and occupancy_3 = 0) as zero_occ_pos_vol_ct_3,\n        \n            count_if(volume_4 > 0 and occupancy_4 = 0) as zero_occ_pos_vol_ct_4,\n        \n            count_if(volume_5 > 0 and occupancy_5 = 0) as zero_occ_pos_vol_ct_5,\n        \n            count_if(volume_6 > 0 and occupancy_6 = 0) as zero_occ_pos_vol_ct_6,\n        \n            count_if(volume_7 > 0 and occupancy_7 = 0) as zero_occ_pos_vol_ct_7,\n        \n            count_if(volume_8 > 0 and occupancy_8 = 0) as zero_occ_pos_vol_ct_8,\n        \n        \n            count_if(volume_1 > 20) as high_volume_ct_1,\n        \n            count_if(volume_2 > 20) as high_volume_ct_2,\n        \n            count_if(volume_3 > 20) as high_volume_ct_3,\n        \n            count_if(volume_4 > 20) as high_volume_ct_4,\n        \n            count_if(volume_5 > 20) as high_volume_ct_5,\n        \n            count_if(volume_6 > 20) as high_volume_ct_6,\n        \n            count_if(volume_7 > 20) as high_volume_ct_7,\n        \n            count_if(volume_8 > 20) as high_volume_ct_8,\n        \n        \n            count_if(occupancy_1 > 0.7) as high_occupancy_ct_1,\n        \n            count_if(occupancy_2 > 0.7) as high_occupancy_ct_2,\n        \n            count_if(occupancy_3 > 0.7) as high_occupancy_ct_3,\n        \n            count_if(occupancy_4 > 0.7) as high_occupancy_ct_4,\n        \n            count_if(occupancy_5 > 0.7) as high_occupancy_ct_5,\n        \n            count_if(occupancy_6 > 0.7) as high_occupancy_ct_6,\n        \n            count_if(occupancy_7 > 0.7) as high_occupancy_ct_7,\n        \n            count_if(occupancy_8 > 0.7) as high_occupancy_ct_8,\n        \n        \n            count_if(volume_1 is not null and occupancy_1 is not null) as sample_ct_1,\n        \n            count_if(volume_2 is not null and occupancy_2 is not null) as sample_ct_2,\n        \n            count_if(volume_3 is not null and occupancy_3 is not null) as sample_ct_3,\n        \n            count_if(volume_4 is not null and occupancy_4 is not null) as sample_ct_4,\n        \n            count_if(volume_5 is not null and occupancy_5 is not null) as sample_ct_5,\n        \n            count_if(volume_6 is not null and occupancy_6 is not null) as sample_ct_6,\n        \n            count_if(volume_7 is not null and occupancy_7 is not null) as sample_ct_7,\n        \n            count_if(volume_8 is not null and occupancy_8 is not null) as sample_ct_8,\n        \n        \n            sum(volume_1 * speed_1)\n            / nullifzero(sum(volume_1)) as speed_weighted_1        \n                ,\n            \n        \n            sum(volume_2 * speed_2)\n            / nullifzero(sum(volume_2)) as speed_weighted_2        \n                ,\n            \n        \n            sum(volume_3 * speed_3)\n            / nullifzero(sum(volume_3)) as speed_weighted_3        \n                ,\n            \n        \n            sum(volume_4 * speed_4)\n            / nullifzero(sum(volume_4)) as speed_weighted_4        \n                ,\n            \n        \n            sum(volume_5 * speed_5)\n            / nullifzero(sum(volume_5)) as speed_weighted_5        \n                ,\n            \n        \n            sum(volume_6 * speed_6)\n            / nullifzero(sum(volume_6)) as speed_weighted_6        \n                ,\n            \n        \n            sum(volume_7 * speed_7)\n            / nullifzero(sum(volume_7)) as speed_weighted_7        \n                ,\n            \n        \n            sum(volume_8 * speed_8)\n            / nullifzero(sum(volume_8)) as speed_weighted_8        \n        \n    from raw\n    group by station_id, sample_date, sample_timestamp_trunc, district\n),\n\n\n    agg_1 as (\n        select\n            station_id,\n            sample_date,\n            sample_timestamp,\n            district,\n            sample_ct_1 as sample_ct,\n            1 as lane,\n            volume_1 as volume_observed,\n            round(iff(\n                sample_ct_1 >= 10, volume_1,\n                10 / nullifzero(sample_ct_1) * volume_1\n            ))\n                as volume_sum,\n                --Represents the observed or normalized flow value based on the\n                --number of samples recieved by the device\n            zero_vol_ct_1 as zero_vol_ct,\n            occupancy_1 as occupancy_avg,\n            zero_occ_ct_1 as zero_occ_ct,\n            zero_vol_pos_occ_ct_1 as zero_vol_pos_occ_ct,\n            zero_occ_pos_vol_ct_1 as zero_occ_pos_vol_ct,\n            high_volume_ct_1 as high_volume_ct,\n            high_occupancy_ct_1 as high_occupancy_ct,\n            speed_weighted_1 as speed_weighted\n        from agg\n    ),\n\n    agg_2 as (\n        select\n            station_id,\n            sample_date,\n            sample_timestamp,\n            district,\n            sample_ct_2 as sample_ct,\n            2 as lane,\n            volume_2 as volume_observed,\n            round(iff(\n                sample_ct_2 >= 10, volume_2,\n                10 / nullifzero(sample_ct_2) * volume_2\n            ))\n                as volume_sum,\n                --Represents the observed or normalized flow value based on the\n                --number of samples recieved by the device\n            zero_vol_ct_2 as zero_vol_ct,\n            occupancy_2 as occupancy_avg,\n            zero_occ_ct_2 as zero_occ_ct,\n            zero_vol_pos_occ_ct_2 as zero_vol_pos_occ_ct,\n            zero_occ_pos_vol_ct_2 as zero_occ_pos_vol_ct,\n            high_volume_ct_2 as high_volume_ct,\n            high_occupancy_ct_2 as high_occupancy_ct,\n            speed_weighted_2 as speed_weighted\n        from agg\n    ),\n\n    agg_3 as (\n        select\n            station_id,\n            sample_date,\n            sample_timestamp,\n            district,\n            sample_ct_3 as sample_ct,\n            3 as lane,\n            volume_3 as volume_observed,\n            round(iff(\n                sample_ct_3 >= 10, volume_3,\n                10 / nullifzero(sample_ct_3) * volume_3\n            ))\n                as volume_sum,\n                --Represents the observed or normalized flow value based on the\n                --number of samples recieved by the device\n            zero_vol_ct_3 as zero_vol_ct,\n            occupancy_3 as occupancy_avg,\n            zero_occ_ct_3 as zero_occ_ct,\n            zero_vol_pos_occ_ct_3 as zero_vol_pos_occ_ct,\n            zero_occ_pos_vol_ct_3 as zero_occ_pos_vol_ct,\n            high_volume_ct_3 as high_volume_ct,\n            high_occupancy_ct_3 as high_occupancy_ct,\n            speed_weighted_3 as speed_weighted\n        from agg\n    ),\n\n    agg_4 as (\n        select\n            station_id,\n            sample_date,\n            sample_timestamp,\n            district,\n            sample_ct_4 as sample_ct,\n            4 as lane,\n            volume_4 as volume_observed,\n            round(iff(\n                sample_ct_4 >= 10, volume_4,\n                10 / nullifzero(sample_ct_4) * volume_4\n            ))\n                as volume_sum,\n                --Represents the observed or normalized flow value based on the\n                --number of samples recieved by the device\n            zero_vol_ct_4 as zero_vol_ct,\n            occupancy_4 as occupancy_avg,\n            zero_occ_ct_4 as zero_occ_ct,\n            zero_vol_pos_occ_ct_4 as zero_vol_pos_occ_ct,\n            zero_occ_pos_vol_ct_4 as zero_occ_pos_vol_ct,\n            high_volume_ct_4 as high_volume_ct,\n            high_occupancy_ct_4 as high_occupancy_ct,\n            speed_weighted_4 as speed_weighted\n        from agg\n    ),\n\n    agg_5 as (\n        select\n            station_id,\n            sample_date,\n            sample_timestamp,\n            district,\n            sample_ct_5 as sample_ct,\n            5 as lane,\n            volume_5 as volume_observed,\n            round(iff(\n                sample_ct_5 >= 10, volume_5,\n                10 / nullifzero(sample_ct_5) * volume_5\n            ))\n                as volume_sum,\n                --Represents the observed or normalized flow value based on the\n                --number of samples recieved by the device\n            zero_vol_ct_5 as zero_vol_ct,\n            occupancy_5 as occupancy_avg,\n            zero_occ_ct_5 as zero_occ_ct,\n            zero_vol_pos_occ_ct_5 as zero_vol_pos_occ_ct,\n            zero_occ_pos_vol_ct_5 as zero_occ_pos_vol_ct,\n            high_volume_ct_5 as high_volume_ct,\n            high_occupancy_ct_5 as high_occupancy_ct,\n            speed_weighted_5 as speed_weighted\n        from agg\n    ),\n\n    agg_6 as (\n        select\n            station_id,\n            sample_date,\n            sample_timestamp,\n            district,\n            sample_ct_6 as sample_ct,\n            6 as lane,\n            volume_6 as volume_observed,\n            round(iff(\n                sample_ct_6 >= 10, volume_6,\n                10 / nullifzero(sample_ct_6) * volume_6\n            ))\n                as volume_sum,\n                --Represents the observed or normalized flow value based on the\n                --number of samples recieved by the device\n            zero_vol_ct_6 as zero_vol_ct,\n            occupancy_6 as occupancy_avg,\n            zero_occ_ct_6 as zero_occ_ct,\n            zero_vol_pos_occ_ct_6 as zero_vol_pos_occ_ct,\n            zero_occ_pos_vol_ct_6 as zero_occ_pos_vol_ct,\n            high_volume_ct_6 as high_volume_ct,\n            high_occupancy_ct_6 as high_occupancy_ct,\n            speed_weighted_6 as speed_weighted\n        from agg\n    ),\n\n    agg_7 as (\n        select\n            station_id,\n            sample_date,\n            sample_timestamp,\n            district,\n            sample_ct_7 as sample_ct,\n            7 as lane,\n            volume_7 as volume_observed,\n            round(iff(\n                sample_ct_7 >= 10, volume_7,\n                10 / nullifzero(sample_ct_7) * volume_7\n            ))\n                as volume_sum,\n                --Represents the observed or normalized flow value based on the\n                --number of samples recieved by the device\n            zero_vol_ct_7 as zero_vol_ct,\n            occupancy_7 as occupancy_avg,\n            zero_occ_ct_7 as zero_occ_ct,\n            zero_vol_pos_occ_ct_7 as zero_vol_pos_occ_ct,\n            zero_occ_pos_vol_ct_7 as zero_occ_pos_vol_ct,\n            high_volume_ct_7 as high_volume_ct,\n            high_occupancy_ct_7 as high_occupancy_ct,\n            speed_weighted_7 as speed_weighted\n        from agg\n    ),\n\n    agg_8 as (\n        select\n            station_id,\n            sample_date,\n            sample_timestamp,\n            district,\n            sample_ct_8 as sample_ct,\n            8 as lane,\n            volume_8 as volume_observed,\n            round(iff(\n                sample_ct_8 >= 10, volume_8,\n                10 / nullifzero(sample_ct_8) * volume_8\n            ))\n                as volume_sum,\n                --Represents the observed or normalized flow value based on the\n                --number of samples recieved by the device\n            zero_vol_ct_8 as zero_vol_ct,\n            occupancy_8 as occupancy_avg,\n            zero_occ_ct_8 as zero_occ_ct,\n            zero_vol_pos_occ_ct_8 as zero_vol_pos_occ_ct,\n            zero_occ_pos_vol_ct_8 as zero_occ_pos_vol_ct,\n            high_volume_ct_8 as high_volume_ct,\n            high_occupancy_ct_8 as high_occupancy_ct,\n            speed_weighted_8 as speed_weighted\n        from agg\n    ),\n\n\nagg_unioned as (\n    \n        select * from agg_1\n        union all\n    \n        select * from agg_2\n        union all\n    \n        select * from agg_3\n        union all\n    \n        select * from agg_4\n        union all\n    \n        select * from agg_5\n        union all\n    \n        select * from agg_6\n        union all\n    \n        select * from agg_7\n        union all\n    \n        select * from agg_8\n        \n    \n),\n\nagg_with_metadata as (\n    select\n        agg.*,\n        dmeta.detector_id,\n        dmeta.state_postmile,\n        dmeta.absolute_postmile,\n        dmeta.latitude,\n        dmeta.longitude,\n        dmeta.physical_lanes,\n        dmeta.station_type,\n        dmeta.county,\n        dmeta.city,\n        dmeta.freeway,\n        dmeta.direction,\n        dmeta.length,\n        dmeta._valid_from as station_valid_from,\n        dmeta._valid_to as station_valid_to\n    from agg_unioned as agg inner join dmeta\n        on\n            agg.station_id = dmeta.station_id\n            and agg.lane = dmeta.lane\n            and \n\n    agg.sample_date >= dmeta._valid_from\n    and ( agg.sample_date < dmeta._valid_to or dmeta._valid_to is null)\n\n\n\n)\n\nselect * from agg_with_metadata", "relation_name": "ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.277965Z", "completed_at": "2025-08-19T19:33:50.286286Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.286814Z", "completed_at": "2025-08-19T19:33:50.286822Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.013261079788208008, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.dbt_utils_unique_combination_of_columns_int_vds__detector_config_DETECTOR_ID___VALID_TO.3a9e44b39e", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        DETECTOR_ID, _VALID_TO\n    from ANALYTICS_PRD.vds.int_vds__detector_config\n    group by DETECTOR_ID, _VALID_TO\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.282086Z", "completed_at": "2025-08-19T19:33:50.292862Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.293524Z", "completed_at": "2025-08-19T19:33:50.293532Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.01869988441467285, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_vds__detector_config__valid_from.5c4ca5caaf", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect _valid_from\nfrom ANALYTICS_PRD.vds.int_vds__detector_config\nwhere _valid_from is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.289085Z", "completed_at": "2025-08-19T19:33:50.300060Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.300654Z", "completed_at": "2025-08-19T19:33:50.300662Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.012686491012573242, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_vds__detector_config_detector_id.4d9c7cae39", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect detector_id\nfrom ANALYTICS_PRD.vds.int_vds__detector_config\nwhere detector_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.295822Z", "completed_at": "2025-08-19T19:33:50.308709Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.311451Z", "completed_at": "2025-08-19T19:33:50.311460Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.016727924346923828, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.dbt_utils_unique_combination_of_columns_int_vds__nearby_stations_STATION_ID__OTHER_STATION_ID___VALID_TO.d6fedbcfc4", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        STATION_ID, OTHER_STATION_ID, _VALID_TO\n    from ANALYTICS_PRD.vds.int_vds__nearby_stations\n    group by STATION_ID, OTHER_STATION_ID, _VALID_TO\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.303775Z", "completed_at": "2025-08-19T19:33:50.312220Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.313441Z", "completed_at": "2025-08-19T19:33:50.313452Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.011613130569458008, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_vds__nearby_stations_OTHER_STATION_ID.35b161098c", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect OTHER_STATION_ID\nfrom ANALYTICS_PRD.vds.int_vds__nearby_stations\nwhere OTHER_STATION_ID is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.187628Z", "completed_at": "2025-08-19T19:33:50.314217Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.315871Z", "completed_at": "2025-08-19T19:33:50.315879Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.1355760097503662, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_vds__active_stations", "compiled": true, "compiled_code": "with date_range as (\n        \n\n\n\n\n\nwith rawdata as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n     + \n    \n    p8.generated_number * power(2, 8)\n     + \n    \n    p9.generated_number * power(2, 9)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n     cross join \n    \n    p as p8\n     cross join \n    \n    p as p9\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 962\n    order by generated_number\n\n\n\n),\n\nall_periods as (\n\n    select (\n        \n\n    dateadd(\n        day,\n        row_number() over (order by 1) - 1,\n        '2023-01-01'\n        )\n\n\n    ) as date_day\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_day <= current_date + 1 \n\n)\n\nselect * from filtered\n\n\n),\n\ndate_range_updated as (\n    select to_date(date_day) as active_date from date_range\n),\n\nstation_meta as (\n    select * from ANALYTICS_PRD.vds.int_vds__station_config\n),\n\nactive_station as (\n    select\n        dr.*,\n        sm.*\n    from date_range_updated as dr\n    inner join\n        station_meta as sm\n        on\n            \n\n    dr.active_date >= sm._valid_from\n    and ( dr.active_date < sm._valid_to or sm._valid_to is null)\n\n\n            and sm.status = 1\n)\n\nselect * from active_station", "relation_name": "ANALYTICS_PRD.vds.int_vds__active_stations", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.318335Z", "completed_at": "2025-08-19T19:33:50.332618Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.333265Z", "completed_at": "2025-08-19T19:33:50.333275Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.018656253814697266, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_vds__nearby_stations__valid_from.9ce32994d4", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect _valid_from\nfrom ANALYTICS_PRD.vds.int_vds__nearby_stations\nwhere _valid_from is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.323405Z", "completed_at": "2025-08-19T19:33:50.334107Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.335739Z", "completed_at": "2025-08-19T19:33:50.335750Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.01869034767150879, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_vds__nearby_stations_station_id.1cac9af910", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect station_id\nfrom ANALYTICS_PRD.vds.int_vds__nearby_stations\nwhere station_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.327926Z", "completed_at": "2025-08-19T19:33:50.335153Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.337054Z", "completed_at": "2025-08-19T19:33:50.337062Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.014473199844360352, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_diagnostics__constant_occupancy", "compiled": true, "compiled_code": "\n\nwith\n\nsource as (\n    select *\n    from ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes\n    where\n        TO_TIME(sample_timestamp) >= '05:00:00'\n        and TO_TIME(sample_timestamp) <= '21:59:59'\n        and \n    1=1\n    \n),\n\n\ncalculate_occupancy_delta as (\n    select\n        detector_id,\n        sample_timestamp,\n        sample_date,\n        occupancy_avg,\n        occupancy_avg\n        - LAG(occupancy_avg)\n            over (partition by detector_id, sample_date order by sample_timestamp)\n            as occupancy_delta\n    from source\n),\n\nsum_occupancy_delta as (\n    select\n        *,\n        ABS(occupancy_delta) as abs_val_occupancy_delta,\n        SUM(abs_val_occupancy_delta)\n        /* we are looking at a window of 48 rows because that is a 4 hour window\n        (5 min data * 12 = 60 (one hour) then 12 * 4 = 48 which is 4 hours) */\n            over (\n                partition by detector_id, sample_date\n                order by sample_timestamp rows between 47 preceding and current row\n            )\n            as abs_val_occupancy_delta_summed\n    from calculate_occupancy_delta\n    qualify\n        (occupancy_avg > 0)\n        and ROW_NUMBER() over (\n            partition by detector_id, sample_date\n            order by sample_timestamp\n        ) >= 48\n\n)\n\nselect\n    detector_id,\n    sample_date,\n    MIN(abs_val_occupancy_delta_summed) as min_occupancy_delta\nfrom sum_occupancy_delta\ngroup by detector_id, sample_date\norder by sample_date", "relation_name": "ANALYTICS_PRD.diagnostics.int_diagnostics__constant_occupancy", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.340079Z", "completed_at": "2025-08-19T19:33:50.357079Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.357893Z", "completed_at": "2025-08-19T19:33:50.357902Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.02145862579345703, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_diagnostics__samples_per_detector", "compiled": true, "compiled_code": "\n\nwith\n\nsource as (\n    select *\n    from ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes\n    where\n        TO_TIME(sample_timestamp) >= '05:00:00'\n        and TO_TIME(sample_timestamp) <= '21:59:59'\n        and \n    1=1\n    \n),\n\nsamples_per_detector as (\n    select\n        source.district,\n        source.station_id,\n        source.lane,\n        source.detector_id,\n        source.sample_date,\n        /*\n        This following counts a sample if the volume (flow) and occupancy values contain any value\n        based on 30 second raw data recieved per station, lane and time. Null values\n        in volume (flow) and occupancy are currently counted as 0 but if these need to be treated\n        differently the code should be updated as needed to accomodate such a scenario.\n        */\n        SUM(source.sample_ct) as sample_ct,\n\n        /*\n        The following code will count how many times a 30 second raw volume (flow) value equals 0\n        for a given station and associated lane\n        */\n        SUM(source.zero_vol_ct) as zero_vol_ct,\n\n        /*\n        The following code will count how many times a 30 second raw occupancy value equals 0\n        for a given station and associated lane\n        */\n        SUM(source.zero_occ_ct) as zero_occ_ct,\n\n        /*\n        This code counts a sample if the volume (flow) is 0 and occupancy value > 0\n        based on 30 second raw data recieved per station, lane, and time.\n        */\n        SUM(zero_vol_pos_occ_ct) as zero_vol_pos_occ_ct,\n\n        /*\n        This code counts a sample if the occupancy is 0 and a volume (flow) value > 0\n        based on 30 second raw data recieved per station, lane and time.\n        */\n        SUM(zero_occ_pos_vol_ct) as zero_occ_pos_vol_ct,\n\n        /*\n        This SQL file counts the number of volume (flow) and occupancy values that exceed\n        detector threshold values for a station based on the station set assignment. For\n        processing optimization a high flow value or 20 and high occupancy value of 0.7\n        have been hardcoded in the formulas below to avoid joining the set assignment model\n        */\n        SUM(high_volume_ct)\n            as high_volume_ct,\n        SUM(high_occupancy_ct)\n            as high_occupancy_ct\n\n    from source\n    group by\n        source.district, source.station_id, source.lane, source.detector_id, source.sample_date\n)\n\nselect * from samples_per_detector", "relation_name": "ANALYTICS_PRD.diagnostics.int_diagnostics__samples_per_detector", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.360158Z", "completed_at": "2025-08-19T19:33:50.364483Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.364978Z", "completed_at": "2025-08-19T19:33:50.364986Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.005891084671020508, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__detector_agg_five_minutes_SAMPLE_DATE.e5acaa3738", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect SAMPLE_DATE\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes\nwhere SAMPLE_DATE is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.348031Z", "completed_at": "2025-08-19T19:33:50.371360Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.371991Z", "completed_at": "2025-08-19T19:33:50.372003Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.03260684013366699, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.accepted_values_int_clearinghouse__detector_agg_five_minutes_DIRECTION__N__E__S__W__n__e__s__w.54beb6c9cb", "compiled": true, "compiled_code": "\n    \n    \n\nwith all_values as (\n\n    select\n        DIRECTION as value_field,\n        count(*) as n_records\n\n    from ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes\n    group by DIRECTION\n\n)\n\nselect *\nfrom all_values\nwhere value_field not in (\n    'N','E','S','W','n','e','s','w'\n)\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.352189Z", "completed_at": "2025-08-19T19:33:50.378796Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.379954Z", "completed_at": "2025-08-19T19:33:50.379963Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.03456449508666992, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.accepted_values_int_clearinghouse__detector_agg_five_minutes_district___var_districts_.4eb65ef421", "compiled": true, "compiled_code": "\n    \n    \n\nwith all_values as (\n\n    select\n        district as value_field,\n        count(*) as n_records\n\n    from ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes\n    group by district\n\n)\n\nselect *\nfrom all_values\nwhere value_field not in (\n    '1','2','3','4','5','6','7','8','9','10','11','12'\n)\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.367236Z", "completed_at": "2025-08-19T19:33:50.379459Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.380799Z", "completed_at": "2025-08-19T19:33:50.380807Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.014630794525146484, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__detector_agg_five_minutes_SAMPLE_TIMESTAMP.e1c1dfbfcf", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect SAMPLE_TIMESTAMP\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes\nwhere SAMPLE_TIMESTAMP is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.374360Z", "completed_at": "2025-08-19T19:33:50.381582Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.383262Z", "completed_at": "2025-08-19T19:33:50.383270Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.01000070571899414, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__detector_agg_five_minutes_STATION_ID.3ab981641a", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect STATION_ID\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes\nwhere STATION_ID is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.391619Z", "completed_at": "2025-08-19T19:33:50.398269Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.405009Z", "completed_at": "2025-08-19T19:33:50.405020Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.020521879196166992, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__detector_agg_five_minutes_detector_id.01e6cf6ac3", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect detector_id\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes\nwhere detector_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.387422Z", "completed_at": "2025-08-19T19:33:50.404370Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.406135Z", "completed_at": "2025-08-19T19:33:50.406146Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.022163867950439453, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__detector_agg_five_minutes_STATION_TYPE.dbdd66a6fb", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect STATION_TYPE\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes\nwhere STATION_TYPE is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.266780Z", "completed_at": "2025-08-19T19:33:50.407000Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.409357Z", "completed_at": "2025-08-19T19:33:50.409367Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.14639711380004883, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_vds__active_detectors", "compiled": true, "compiled_code": "with date_range as (\n        \n\n\n\n\n\nwith rawdata as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n     + \n    \n    p8.generated_number * power(2, 8)\n     + \n    \n    p9.generated_number * power(2, 9)\n     + \n    \n    p10.generated_number * power(2, 10)\n     + \n    \n    p11.generated_number * power(2, 11)\n     + \n    \n    p12.generated_number * power(2, 12)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n     cross join \n    \n    p as p8\n     cross join \n    \n    p as p9\n     cross join \n    \n    p as p10\n     cross join \n    \n    p as p11\n     cross join \n    \n    p as p12\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 5710\n    order by generated_number\n\n\n\n),\n\nall_periods as (\n\n    select (\n        \n\n    dateadd(\n        day,\n        row_number() over (order by 1) - 1,\n        to_date('01/01/2010', 'mm/dd/yyyy')\n        )\n\n\n    ) as date_day\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_day <= current_date + 1\n\n)\n\nselect * from filtered\n\n\n),\n\ndate_range_updated as (\n    select date_day as active_date from date_range\n),\n\ndetector_meta as (\n    select * from ANALYTICS_PRD.vds.int_vds__detector_config\n),\n\nactive_detector as (\n    select\n        dr.*,\n        dm.*\n    from date_range_updated as dr\n    inner join\n        detector_meta as dm\n        on\n            \n\n    dr.active_date >= dm._valid_from\n    and ( dr.active_date < dm._valid_to or dm._valid_to is null)\n\n\n\n    where dm.status = 1\n)\n\nselect * from active_detector", "relation_name": "ANALYTICS_PRD.vds.int_vds__active_detectors", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.398822Z", "completed_at": "2025-08-19T19:33:50.408818Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.411240Z", "completed_at": "2025-08-19T19:33:50.411252Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.024533510208129883, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_diagnostics__det_diag_set_assignment", "compiled": true, "compiled_code": "with\n\nstation_diagnostic_set_assign as (\n    /*\n    This SQL file assigns which sets of calculations will be used for\n    a station based on information in from the station metadata\n    The station_DIAGNOSTIC_SET_ID variable assigns 1 of 5 values for station\n    diagnostic evaluations. The station_DIAGNOSTIC_METHOD_ID variable assigns\n    1 of 2 values for station diagnostic evaluations.\n    */\n    select\n        active_date,\n        station_id,\n        district,\n        station_type,\n        dt_set_id,\n        _valid_from as station_valid_from,\n        _valid_to as station_valid_to,\n        case\n            when UPPER(dt_set_id) like 'LOW%' then 'Low_Volume'\n            when UPPER(dt_set_id) like 'RURAL%' then 'Rural'\n            when UPPER(dt_set_id) like 'URBAN_D11%' then 'Urban_D11'\n            when UPPER(dt_set_id) like 'D6_RAMPS%' then 'D6_Ramps'\n            else 'Urban'\n        end as station_diagnostic_set_id,\n        case\n            when station_type in ('ML', 'HV') then 'mainline'\n            else 'ramp'\n        end as station_diagnostic_method_id\n\n    from ANALYTICS_PRD.vds.int_vds__active_stations\n),\n\ndiagnostic_threshold_values as (\n    -- Pivot the data in the diagnostic_threshold_value seed file so\n    -- subsequent joins create wide instead of long tables\n    select *\n    from ANALYTICS_PRD.diagnostics.diagnostic_threshold_values\n    pivot (AVG(dt_value) for dt_name in (\n        'high_occ',\n        'high_flow',\n        'high_occ_pct',\n        'zero_occ_pct',\n        'flow_occ_pct',\n        'occ_flow_pct',\n        'repeat_occ',\n        'high_flow_pct',\n        'zero_flow_pct'\n    ))\n        as p (\n            dt_set_id,\n            dt_method,\n            high_occupancy,\n            high_flow,\n            high_occupancy_percent,\n            zero_occupancy_percent,\n            flow_occupancy_percent,\n            occupancy_flow_percent,\n            repeat_occupancy,\n            high_flow_percent,\n            zero_flow_percent\n        )\n),\n\nstation_diagnostic_threshold_values as (\n    /*\n    This SQL file assigns which station threshold values will be used\n    for a station based on information from the station metadata.\n    */\n    select\n        station_diagnostic_set_assign.*,\n        diagnostic_threshold_values.* exclude (dt_set_id, dt_method)\n    from station_diagnostic_set_assign\n    inner join diagnostic_threshold_values\n        on\n            station_diagnostic_set_assign.station_diagnostic_set_id = diagnostic_threshold_values.dt_set_id\n            and station_diagnostic_set_assign.station_diagnostic_method_id = diagnostic_threshold_values.dt_method\n)\n\nselect * from station_diagnostic_threshold_values", "relation_name": "ANALYTICS_PRD.diagnostics.int_diagnostics__det_diag_set_assignment", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.414901Z", "completed_at": "2025-08-19T19:33:50.436505Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.437888Z", "completed_at": "2025-08-19T19:33:50.437898Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.02783370018005371, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__constant_occupancy_detector_id.358b0c76a8", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect detector_id\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__constant_occupancy\nwhere detector_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.420048Z", "completed_at": "2025-08-19T19:33:50.437137Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.439265Z", "completed_at": "2025-08-19T19:33:50.439276Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.02866673469543457, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__constant_occupancy_sample_date.5f54be703f", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect sample_date\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__constant_occupancy\nwhere sample_date is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.427395Z", "completed_at": "2025-08-19T19:33:50.438712Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.440803Z", "completed_at": "2025-08-19T19:33:50.440815Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.026641368865966797, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.accepted_values_int_diagnostics__samples_per_detector_district___var_districts_.f16e5ab328", "compiled": true, "compiled_code": "\n    \n    \n\nwith all_values as (\n\n    select\n        district as value_field,\n        count(*) as n_records\n\n    from ANALYTICS_PRD.diagnostics.int_diagnostics__samples_per_detector\n    group by district\n\n)\n\nselect *\nfrom all_values\nwhere value_field not in (\n    '1','2','3','4','5','6','7','8','9','10','11','12'\n)\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.432348Z", "completed_at": "2025-08-19T19:33:50.441599Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.443935Z", "completed_at": "2025-08-19T19:33:50.443944Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.018535137176513672, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.dbt_utils_unique_combination_of_columns_int_diagnostics__samples_per_detector_SAMPLE_DATE__DETECTOR_ID.285471e8ba", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        SAMPLE_DATE, DETECTOR_ID\n    from ANALYTICS_PRD.diagnostics.int_diagnostics__samples_per_detector\n    group by SAMPLE_DATE, DETECTOR_ID\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.447667Z", "completed_at": "2025-08-19T19:33:50.460698Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.461980Z", "completed_at": "2025-08-19T19:33:50.461995Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.019295692443847656, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__samples_per_detector_detector_id.931e1196f3", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect detector_id\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__samples_per_detector\nwhere detector_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.456765Z", "completed_at": "2025-08-19T19:33:50.466786Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.468674Z", "completed_at": "2025-08-19T19:33:50.468682Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.02289295196533203, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__samples_per_detector_sample_date.a5debcc904", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect sample_date\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__samples_per_detector\nwhere sample_date is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.452784Z", "completed_at": "2025-08-19T19:33:50.468035Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.470598Z", "completed_at": "2025-08-19T19:33:50.470609Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.025897741317749023, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__samples_per_detector_lane.dfaf85c7c1", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect lane\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__samples_per_detector\nwhere lane is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.462872Z", "completed_at": "2025-08-19T19:33:50.470075Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.472472Z", "completed_at": "2025-08-19T19:33:50.472480Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.02042222023010254, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__samples_per_detector_station_id.bbda3aa060", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect station_id\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__samples_per_detector\nwhere station_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.474395Z", "completed_at": "2025-08-19T19:33:50.483426Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.495239Z", "completed_at": "2025-08-19T19:33:50.495255Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.02581787109375, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_diagnostics__no_data_status", "compiled": true, "compiled_code": "\n\nwith\nsource as (\n    select\n        sample_date as active_date,\n        * exclude sample_date\n    from ANALYTICS_PRD.diagnostics.int_diagnostics__samples_per_detector\n    where \n    1=1\n    \n),\n\ndetector_meta as (\n    select * from ANALYTICS_PRD.vds.int_vds__active_detectors\n),\n\nstation_meta as (\n    select * from ANALYTICS_PRD.vds.int_vds__station_config\n),\n\ncontroller_meta as (\n    select * from ANALYTICS_PRD.vds.int_vds__controller_config\n),\n\nequipment_meta as (\n    select\n        dm.*,\n        sm.controller_id,\n        sm.name,\n        sm.angle,\n        cm.line_num,\n        cm.stn_address,\n        cm.controller_type\n    from detector_meta as dm\n    inner join station_meta as sm\n        on\n            dm.station_id = sm.station_id\n            and \n\n    dm.active_date >= sm._valid_from\n    and ( dm.active_date < sm._valid_to or sm._valid_to is null)\n\n\n    inner join controller_meta as cm\n        on\n            sm.controller_id = cm.controller_id\n            and \n\n    dm.active_date >= cm._valid_from\n    and ( dm.active_date < cm._valid_to or cm._valid_to is null)\n\n\n    -- Constrain dates to not exceed those in the samples_per_detector model.\n    where\n        dm.active_date between\n        (select min(source.active_date) from source) and (select max(source.active_date) from source)\n),\n\nequipment_with_samples as (\n    select\n        em.*,\n        source.sample_ct\n    from equipment_meta as em\n    left join source\n        on\n            em.detector_id = source.detector_id\n            and em.active_date = source.active_date\n),\n\ndistrict_feed_check as (\n    select\n        ews.active_date,\n        ews.district,\n        case\n            when (count_if(ews.sample_ct > 0)) > 0 then 'Yes'\n            else 'No'\n        end as district_feed_working\n    from equipment_with_samples as ews\n    inner join ANALYTICS_PRD.clearinghouse.districts as d\n        on ews.district = d.district_id\n    group by ews.active_date, ews.district\n),\n\nline_feed_check as (\n    select\n        ews.active_date,\n        ews.district,\n        ews.line_num,\n        case\n            when ews.line_num is null then 'Yes'\n            when (count_if(ews.sample_ct > 0)) > 0 then 'Yes'\n            else 'No'\n        end as line_num_working\n    from equipment_with_samples as ews\n    group by ews.active_date, ews.district, ews.line_num\n),\n\ncontroller_feed_check as (\n    select\n        ews.active_date,\n        ews.district,\n        ews.controller_id,\n        case\n            when ews.controller_id is null then 'Yes'\n            when (count_if(ews.sample_ct > 0)) > 0 then 'Yes'\n            else 'No'\n        end as controller_feed_working\n    from equipment_with_samples as ews\n    group by ews.active_date, ews.district, ews.controller_id\n),\n\nstation_feed_check as (\n    select\n        ews.active_date,\n        ews.district,\n        ews.station_id,\n        case\n            when ews.station_id is null then 'Yes'\n            when (count_if(ews.sample_ct > 0)) > 0 then 'Yes'\n            else 'No'\n        end as station_feed_working\n    from equipment_with_samples as ews\n    group by ews.active_date, ews.district, ews.station_id\n),\n\ndetector_feed_check as (\n    select\n        ews.active_date,\n        ews.detector_id,\n        case\n            when ews.detector_id is null then 'Yes'\n            when (count_if(ews.sample_ct > 0)) > 0 then 'Yes'\n            else 'No'\n        end as detector_feed_working\n    from equipment_with_samples as ews\n    group by ews.active_date, ews.detector_id\n),\n\ndata_feed_check as (\n    select\n        ews.active_date,\n        ews.district,\n        ews.line_num,\n        ews.controller_id,\n        ews.station_id,\n        ews.detector_id,\n        ews.sample_ct,\n        dfc.district_feed_working,\n        lfc.line_num_working,\n        cfc.controller_feed_working,\n        sfc.station_feed_working,\n        detfc.detector_feed_working\n    from equipment_with_samples as ews\n    left join district_feed_check as dfc\n        on\n            ews.active_date = dfc.active_date\n            and ews.district = dfc.district\n    left join line_feed_check as lfc\n        on\n            ews.active_date = lfc.active_date\n            and ews.district = lfc.district\n            and ews.line_num = lfc.line_num\n    left join controller_feed_check as cfc\n        on\n            ews.active_date = cfc.active_date\n            and ews.district = cfc.district\n            and ews.controller_id = cfc.controller_id\n    left join station_feed_check as sfc\n        on\n            ews.active_date = sfc.active_date\n            and ews.district = sfc.district\n            and ews.station_id = sfc.station_id\n    left join detector_feed_check as detfc\n        on\n            ews.active_date = detfc.active_date\n            and ews.detector_id = detfc.detector_id\n)\n\nselect * from data_feed_check\norder by active_date, district, line_num, controller_id, station_id, detector_id", "relation_name": "ANALYTICS_PRD.diagnostics.int_diagnostics__no_data_status", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.491437Z", "completed_at": "2025-08-19T19:33:50.501209Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.502595Z", "completed_at": "2025-08-19T19:33:50.502604Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.02158331871032715, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__det_diag_set_assignment_active_date.ee11dc3c47", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect active_date\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__det_diag_set_assignment\nwhere active_date is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.483931Z", "completed_at": "2025-08-19T19:33:50.503369Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.505473Z", "completed_at": "2025-08-19T19:33:50.505484Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.0317232608795166, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.accepted_values_int_diagnostics__det_diag_set_assignment_district___var_districts_.e3cb85a5b4", "compiled": true, "compiled_code": "\n    \n    \n\nwith all_values as (\n\n    select\n        district as value_field,\n        count(*) as n_records\n\n    from ANALYTICS_PRD.diagnostics.int_diagnostics__det_diag_set_assignment\n    group by district\n\n)\n\nselect *\nfrom all_values\nwhere value_field not in (\n    '1','2','3','4','5','6','7','8','9','10','11','12'\n)\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.496141Z", "completed_at": "2025-08-19T19:33:50.504397Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.510519Z", "completed_at": "2025-08-19T19:33:50.510529Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.02826070785522461, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__det_diag_set_assignment_station_diagnostic_method_id.2c1f45d42a", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect station_diagnostic_method_id\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__det_diag_set_assignment\nwhere station_diagnostic_method_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.506457Z", "completed_at": "2025-08-19T19:33:50.513858Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.519422Z", "completed_at": "2025-08-19T19:33:50.519433Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.017544269561767578, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__det_diag_set_assignment_station_diagnostic_set_id.2f3c1108ec", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect station_diagnostic_set_id\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__det_diag_set_assignment\nwhere station_diagnostic_set_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.515472Z", "completed_at": "2025-08-19T19:33:50.532789Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.534541Z", "completed_at": "2025-08-19T19:33:50.534553Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.023172378540039062, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__det_diag_set_assignment_station_id.4e5cf4e6c2", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect station_id\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__det_diag_set_assignment\nwhere station_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.521974Z", "completed_at": "2025-08-19T19:33:50.533889Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.540707Z", "completed_at": "2025-08-19T19:33:50.540717Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.026416540145874023, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__det_diag_set_assignment_station_type.df83d5a819", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect station_type\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__det_diag_set_assignment\nwhere station_type is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.526072Z", "completed_at": "2025-08-19T19:33:50.535275Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.542260Z", "completed_at": "2025-08-19T19:33:50.542268Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.027433395385742188, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_diagnostics__detector_status", "compiled": true, "compiled_code": "\n\nwith\nsource as (\n    select * from ANALYTICS_PRD.diagnostics.int_diagnostics__samples_per_detector\n    where \n    1=1\n    \n),\n\ndetector_meta as (\n    select * from ANALYTICS_PRD.vds.int_vds__detector_config\n),\n\nset_assgnmt as (\n    select * from ANALYTICS_PRD.diagnostics.int_diagnostics__det_diag_set_assignment\n    where\n        active_date between\n        (select min(source.sample_date) from source) and (select max(source.sample_date) from source)\n),\n\nassignment_with_meta as (\n    select\n        set_assgnmt.*,\n        dm.detector_id,\n        dm.detector_type,\n        dm.lane,\n        dm.state_postmile,\n        dm.absolute_postmile,\n        dm.latitude,\n        dm.longitude,\n        dm.physical_lanes,\n        dm.county,\n        dm.city,\n        dm.freeway,\n        dm.direction,\n        dm.length\n    from set_assgnmt\n    inner join detector_meta as dm\n        on\n            set_assgnmt.station_id = dm.station_id\n            and \n\n    set_assgnmt.active_date >= dm._valid_from\n    and ( set_assgnmt.active_date < dm._valid_to or dm._valid_to is null)\n\n\n),\n\ndetector_status as (\n    select\n        awm.active_date,\n        awm.station_id,\n        awm.district,\n        awm.station_type,\n        awm.station_diagnostic_method_id,\n        awm.active_date as sample_date,\n        awm.detector_id,\n        awm.detector_type,\n        awm.lane,\n        awm.state_postmile,\n        awm.absolute_postmile,\n        awm.latitude,\n        awm.longitude,\n        awm.physical_lanes,\n        awm.county,\n        awm.city,\n        awm.freeway,\n        awm.direction,\n        awm.length,\n        sps.* exclude (district, station_id, lane, detector_id, sample_date),\n        nds.district_feed_working,\n        nds.line_num_working,\n        nds.controller_feed_working,\n        nds.station_feed_working,\n        nds.detector_feed_working,\n        co.min_occupancy_delta,\n        case\n            when nds.district_feed_working = 'No' then 'District Feed Down'\n            when nds.line_num_working = 'No' then 'Line Down'\n            when nds.controller_feed_working = 'No' then 'Controller Down'\n            when nds.detector_feed_working = 'No' then 'No Data'\n            when sps.sample_ct = 0 or sps.sample_ct is null\n                then 'Down/No Data'\n            /* # of samples < 60% of the max collected during the test period\n            max value: 2 samples per min * 60 mins/hr * 17 hrs in a day == 1224\n            btwn 1 and 1224 is too few samples */\n            when sps.sample_ct between 1 and (0.6 * (2 * 60 * 17))\n                then 'Insufficient Data'\n            when\n                awm.station_diagnostic_method_id = 'ramp'\n                and\n                (sps.zero_vol_ct / sps.sample_ct)\n                >= (awm.zero_flow_percent / 100)\n                then 'Card Off'\n            when\n                awm.station_diagnostic_method_id = 'mainline'\n                and\n                (sps.zero_occ_ct / sps.sample_ct)\n                >= (awm.zero_occupancy_percent / 100)\n                then 'Card Off'\n            when\n                awm.station_diagnostic_method_id = 'ramp'\n                and\n                (sps.high_volume_ct / sps.sample_ct)\n                >= (awm.high_flow_percent / 100)\n                then 'High Val'\n            when\n                awm.station_diagnostic_method_id = 'mainline'\n                and\n                (sps.high_occupancy_ct / sps.sample_ct)\n                >= (awm.high_occupancy_percent / 100)\n                then 'High Val'\n            when\n                awm.station_diagnostic_method_id = 'mainline'\n                and\n                (sps.zero_vol_pos_occ_ct / sps.sample_ct)\n                >= (awm.flow_occupancy_percent / 100)\n                then 'Intermittent'\n            when\n                awm.station_diagnostic_method_id = 'mainline'\n                and\n                (sps.zero_occ_pos_vol_ct / sps.sample_ct)\n                >= (awm.occupancy_flow_percent / 100)\n                then 'Intermittent'\n            when\n            -- the float value can not compare with 0, we set a small threshold to replace with it\n                coalesce(co.min_occupancy_delta < 0.00001, false)\n                and awm.station_diagnostic_method_id = 'mainline'\n                then 'Constant'\n            --Feed unstable case needed\n            else 'Good'\n        end as status\n\n    from assignment_with_meta as awm\n\n    left join source as sps\n        on\n            awm.detector_id = sps.detector_id\n            -- and awm.lane = sps.lane\n            and awm.active_date = sps.sample_date\n\n    left join ANALYTICS_PRD.diagnostics.int_diagnostics__constant_occupancy as co\n        on\n            awm.detector_id = co.detector_id\n            and awm.active_date = co.sample_date\n\n    left join ANALYTICS_PRD.diagnostics.int_diagnostics__no_data_status as nds\n        on\n            awm.active_date = nds.active_date\n            and awm.detector_id = nds.detector_id\n)\n\nselect * from detector_status", "relation_name": "ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.535805Z", "completed_at": "2025-08-19T19:33:50.543657Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.546201Z", "completed_at": "2025-08-19T19:33:50.546213Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.01508188247680664, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.accepted_values_int_diagnostics__no_data_status_district___var_districts_.70e36d9aa7", "compiled": true, "compiled_code": "\n    \n    \n\nwith all_values as (\n\n    select\n        district as value_field,\n        count(*) as n_records\n\n    from ANALYTICS_PRD.diagnostics.int_diagnostics__no_data_status\n    group by district\n\n)\n\nselect *\nfrom all_values\nwhere value_field not in (\n    '1','2','3','4','5','6','7','8','9','10','11','12'\n)\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.555654Z", "completed_at": "2025-08-19T19:33:50.565044Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.570006Z", "completed_at": "2025-08-19T19:33:50.570016Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.024621963500976562, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__no_data_status_active_date.74e12d58d6", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect active_date\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__no_data_status\nwhere active_date is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.549141Z", "completed_at": "2025-08-19T19:33:50.565568Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.571328Z", "completed_at": "2025-08-19T19:33:50.571340Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.02720785140991211, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.dbt_utils_unique_combination_of_columns_int_diagnostics__no_data_status_ACTIVE_DATE__DETECTOR_ID.6021199b99", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        ACTIVE_DATE, DETECTOR_ID\n    from ANALYTICS_PRD.diagnostics.int_diagnostics__no_data_status\n    group by ACTIVE_DATE, DETECTOR_ID\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.560211Z", "completed_at": "2025-08-19T19:33:50.570806Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.574469Z", "completed_at": "2025-08-19T19:33:50.574478Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.027000904083251953, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__no_data_status_detector_id.da89c83682", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect detector_id\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__no_data_status\nwhere detector_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.566120Z", "completed_at": "2025-08-19T19:33:50.573885Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.576357Z", "completed_at": "2025-08-19T19:33:50.576365Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.01681208610534668, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__no_data_status_station_id.4763214a01", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect station_id\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__no_data_status\nwhere station_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.580351Z", "completed_at": "2025-08-19T19:33:50.602375Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.604101Z", "completed_at": "2025-08-19T19:33:50.604112Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.028393030166625977, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.diagnostics__detector_daily_by_station", "compiled": true, "compiled_code": "\n\nwith\n\ndetector_status as (\n    select * from ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status\n),\n\ndetector_status_with_count as (\n    select\n        district,\n        station_id,\n        lane,\n        station_type,\n        sample_date,\n        sample_ct,\n        count_if(status = 'Good') as good_detector,\n        count_if(status != 'Good') as bad_detector,\n        count_if(status = 'Down/No Data') as down_or_no_data,\n        count_if(status = 'Insufficient Data') as insufficient_data,\n        count_if(status = 'Card Off') as card_off,\n        count_if(status = 'High Val') as high_val,\n        count_if(status = 'Intermittent') as intermittent,\n        count_if(status = 'Constant') as constant\n    from detector_status\n    group by district, station_id, lane, station_type, sample_date, sample_ct\n),\n\ndetector_status_by_station as (\n    select\n        district,\n        station_id,\n        station_type,\n        sample_date,\n        count(*) as detector_count,\n        round(avg(sample_ct)) as average_sample_count,\n        sum(good_detector) as good_detector_count,\n        sum(bad_detector) as bad_detector_count,\n        sum(down_or_no_data) as down_or_no_data_count,\n        sum(insufficient_data) as insufficient_data_count,\n        sum(card_off) as card_off_count,\n        sum(high_val) as high_val_count,\n        sum(intermittent) as intermittent_count,\n        sum(constant) as constant_count\n    from detector_status_with_count\n    group by district, station_id, station_type, sample_date\n),\n\ndmeta as (\n    select * from ANALYTICS_PRD.vds.int_vds__station_config\n),\n\ndetector_status_by_station_with_metadata as (\n    select\n        dsbs.*,\n        dmeta.state_postmile,\n        dmeta.absolute_postmile,\n        dmeta.latitude,\n        dmeta.longitude,\n        dmeta.physical_lanes,\n        dmeta.county,\n        dmeta.city,\n        dmeta.freeway,\n        dmeta.direction,\n        dmeta.length\n    from detector_status_by_station as dsbs\n    inner join dmeta\n        on\n            dsbs.station_id = dmeta.station_id\n            and dsbs.sample_date >= dmeta._valid_from\n            and (\n                dsbs.sample_date < dmeta._valid_to\n                or dmeta._valid_to is null\n            )\n    where dsbs.sample_date is not null\n),\n\ndetector_status_by_station_with_metadatac as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            detector_status_by_station_with_metadata.*,\n            c.county_name,\n            c.county_abb\n        from detector_status_by_station_with_metadata\n        inner join county as c\n        on detector_status_by_station_with_metadata.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\ndetector_status_by_station_with_metadatacc as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from detector_status_by_station_with_metadatac as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n)\n\nselect * from detector_status_by_station_with_metadatacc", "relation_name": "ANALYTICS_PRD.diagnostics.diagnostics__detector_daily_by_station", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.585989Z", "completed_at": "2025-08-19T19:33:50.602898Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.605453Z", "completed_at": "2025-08-19T19:33:50.605465Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.027891159057617188, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.diagnostics__detector_daily_detail", "compiled": true, "compiled_code": "\n\nwith\n\ndetector_status as (\n    select * from ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status\n    where sample_date is not null and lane is not null\n),\n\ndetector_statusc as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            detector_status.*,\n            c.county_name,\n            c.county_abb\n        from detector_status\n        inner join county as c\n        on detector_status.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\ndetector_statuscc as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from detector_statusc as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n)\n\nselect * from detector_statuscc", "relation_name": "ANALYTICS_PRD.diagnostics.diagnostics__detector_daily_detail", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.590507Z", "completed_at": "2025-08-19T19:33:50.604924Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.607540Z", "completed_at": "2025-08-19T19:33:50.607549Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.028355836868286133, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_clearinghouse__detector_outlier_agg_five_minutes", "compiled": true, "compiled_code": "\n\n/*We dynamically select dataset for last week and calculate the statistics (mean, std)\nfor outlier detection*/\nwith\nfive_minute_agg_lastweek as (\n    select\n        detector_id,\n        sample_date,\n        volume_sum,\n        occupancy_avg\n    from ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes\n    where\n        sample_date >= dateadd(week, -1, date_trunc('week', current_date))\n        and sample_date < date_trunc('week', current_date)\n        and station_type in ('ML', 'HV')\n),\n\n-- get all good detectors\ngood_detectors as (\n    select\n        detector_id,\n        sample_date\n    from ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status\n    where\n        status = 'Good'\n        and sample_date >= dateadd(week, -1, date_trunc('week', current_date))\n        and sample_date < date_trunc('week', current_date)\n        and station_type in ('ML', 'HV')\n),\n\n-- filter last week's data for good detectors only\nfiltered_five_minute_agg_lastweek as (\n    select\n        f.detector_id,\n        f.sample_date,\n        f.volume_sum,\n        f.occupancy_avg\n    from five_minute_agg_lastweek as f\n    inner join good_detectors as g\n        on\n            f.detector_id = g.detector_id\n            and f.sample_date = g.sample_date\n\n),\n\n-- calculate the statistics\nweekly_stats as (\n    select\n        detector_id,\n        avg(volume_sum) as volume_mean,\n        stddev(volume_sum) as volume_stddev,\n        -- consider using max_capacity\n        percentile_cont(0.95) within group (order by volume_sum) as volume_95th,\n        percentile_cont(0.95) within group (order by occupancy_avg) as occupancy_95th\n    from filtered_five_minute_agg_lastweek\n    group by detector_id\n),\n\n-- retrieve recent five-minute data\nfive_minute_agg as (\n    select *\n    from ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes\n    where \n    1=1\n    \n),\n\n-- impute detected outliers\noutlier_removed_data as (\n    select\n        fa.*,\n        -- update volume_sum if it's an outlier\n        case\n            when\n                (fa.volume_sum - ms.volume_mean) / nullifzero(ms.volume_stddev) > 3\n                then ms.volume_95th\n            else fa.volume_sum\n        end as updated_volume_sum,\n        -- add a volume_label for imputed volume\n        case\n            when\n                (fa.volume_sum - ms.volume_mean) / nullifzero(ms.volume_stddev) > 3\n                then 'observed outlier'\n            else 'observed data'\n        end as volume_label,\n        -- update occupancy if it's an outlier\n        case\n            when\n                fa.occupancy_avg > ms.occupancy_95th\n                then ms.occupancy_95th\n            else fa.occupancy_avg\n        end as updated_occupancy_avg,\n        -- add a column for imputed occupancy\n        case\n            when\n                fa.occupancy_avg > ms.occupancy_95th\n                then 'observed outlier'\n            else 'observed data'\n        end as occupancy_label\n    from five_minute_agg as fa\n    left join\n        weekly_stats as ms\n        on\n            fa.detector_id = ms.detector_id\n\n)\n\nselect * from outlier_removed_data", "relation_name": "ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_outlier_agg_five_minutes", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.628270Z", "completed_at": "2025-08-19T19:33:50.633630Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.634144Z", "completed_at": "2025-08-19T19:33:50.634156Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.021481752395629883, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.dbt_utils_unique_combination_of_columns_int_diagnostics__detector_status_SAMPLE_DATE__DETECTOR_ID.e726e8f900", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        SAMPLE_DATE, DETECTOR_ID\n    from ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status\n    group by SAMPLE_DATE, DETECTOR_ID\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.636842Z", "completed_at": "2025-08-19T19:33:50.641881Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.642954Z", "completed_at": "2025-08-19T19:33:50.642965Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.0075588226318359375, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__detector_status_active_date.5786c23639", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect active_date\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status\nwhere active_date is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.623151Z", "completed_at": "2025-08-19T19:33:50.642444Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.643784Z", "completed_at": "2025-08-19T19:33:50.643798Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.032259464263916016, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.accepted_values_int_diagnostics__detector_status_district___var_districts_.8e1a4f4570", "compiled": true, "compiled_code": "\n    \n    \n\nwith all_values as (\n\n    select\n        district as value_field,\n        count(*) as n_records\n\n    from ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status\n    group by district\n\n)\n\nselect *\nfrom all_values\nwhere value_field not in (\n    '1','2','3','4','5','6','7','8','9','10','11','12'\n)\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.651918Z", "completed_at": "2025-08-19T19:33:50.656026Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.656570Z", "completed_at": "2025-08-19T19:33:50.656578Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.010397911071777344, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__detector_status_lane.14b76d7583", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect lane\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status\nwhere lane is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.647823Z", "completed_at": "2025-08-19T19:33:50.658381Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.659378Z", "completed_at": "2025-08-19T19:33:50.659389Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.013727426528930664, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__detector_status_detector_id.89a8ed788a", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect detector_id\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status\nwhere detector_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.660136Z", "completed_at": "2025-08-19T19:33:50.670226Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.670942Z", "completed_at": "2025-08-19T19:33:50.670955Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.013234615325927734, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__detector_status_sample_date.b485240d73", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect sample_date\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status\nwhere sample_date is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.665939Z", "completed_at": "2025-08-19T19:33:50.671753Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.672803Z", "completed_at": "2025-08-19T19:33:50.672811Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.007979154586791992, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__detector_status_station_diagnostic_method_id.d155d64beb", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect station_diagnostic_method_id\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status\nwhere station_diagnostic_method_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.681474Z", "completed_at": "2025-08-19T19:33:50.686084Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.687100Z", "completed_at": "2025-08-19T19:33:50.687110Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.012012720108032227, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__detector_status_station_type.4e21d76782", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect station_type\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status\nwhere station_type is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.675724Z", "completed_at": "2025-08-19T19:33:50.686607Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.687896Z", "completed_at": "2025-08-19T19:33:50.687904Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.01439213752746582, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__detector_status_station_id.59dc345670", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect station_id\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status\nwhere station_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.691929Z", "completed_at": "2025-08-19T19:33:50.699683Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.700254Z", "completed_at": "2025-08-19T19:33:50.700262Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.010532855987548828, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_diagnostics__detector_status_status.e5917f66af", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect status\nfrom ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status\nwhere status is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.695940Z", "completed_at": "2025-08-19T19:33:50.706721Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.707298Z", "completed_at": "2025-08-19T19:33:50.707324Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.016985416412353516, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.diagnostics__detector_monthly_by_station", "compiled": true, "compiled_code": "\n\nwith detector_daily_status as (\n    select\n        *,\n        DATE_TRUNC(month, sample_date) as sample_month,\n        ROW_NUMBER() over (partition by sample_month, station_id order by sample_date desc) as rn\n    from ANALYTICS_PRD.diagnostics.diagnostics__detector_daily_by_station\n),\n\ndetector_monthly_status_by_station as (\n    select\n        sample_month,\n        station_id,\n        MAX(case when rn = 1 then county end) as county,\n        MAX(case when rn = 1 then county_name end) as county_name,\n        MAX(case when rn = 1 then county_abb end) as county_abb,\n        MAX(case when rn = 1 then city end) as city,\n        MAX(case when rn = 1 then city_name end) as city_name,\n        MAX(case when rn = 1 then city_abb end) as city_abb,\n        MAX(case when rn = 1 then district end) as district,\n        MAX(case when rn = 1 then state_postmile end) as state_postmile,\n        MAX(case when rn = 1 then absolute_postmile end) as absolute_postmile,\n        MAX(case when rn = 1 then latitude end) as latitude,\n        MAX(case when rn = 1 then longitude end) as longitude,\n        MAX(case when rn = 1 then station_type end) as station_type,\n        MAX(case when rn = 1 then freeway end) as freeway,\n        MAX(case when rn = 1 then direction end) as direction,\n        SUM(detector_count) as monthly_detector_count,\n        SUM(good_detector_count) as monthly_good_detector_count,\n        SUM(bad_detector_count) as monthly_bad_detector_count,\n        SUM(down_or_no_data_count) as down_or_no_data_count,\n        SUM(insufficient_data_count) as insufficient_data_count,\n        SUM(card_off_count) as card_off_count,\n        SUM(high_val_count) as high_val_count,\n        SUM(intermittent_count) as intermittent_count,\n        SUM(constant_count) as constant_count\n    from\n        detector_daily_status\n    group by\n        station_id,\n        sample_month\n)\n\nselect * from detector_monthly_status_by_station", "relation_name": "ANALYTICS_PRD.diagnostics.diagnostics__detector_monthly_by_station", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.702564Z", "completed_at": "2025-08-19T19:33:50.713824Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.714363Z", "completed_at": "2025-08-19T19:33:50.714372Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.012890815734863281, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_diagnostics__detector_daily_by_station_sample_date.b39b495de5", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect sample_date\nfrom ANALYTICS_PRD.diagnostics.diagnostics__detector_daily_by_station\nwhere sample_date is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.709616Z", "completed_at": "2025-08-19T19:33:50.720721Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.721235Z", "completed_at": "2025-08-19T19:33:50.721245Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.012716531753540039, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_diagnostics__detector_daily_by_station_station_id.27c37be2ad", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect station_id\nfrom ANALYTICS_PRD.diagnostics.diagnostics__detector_daily_by_station\nwhere station_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.716696Z", "completed_at": "2025-08-19T19:33:50.729485Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.732596Z", "completed_at": "2025-08-19T19:33:50.732609Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.017022132873535156, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_diagnostics__detector_daily_detail_sample_date.1fb8da6fc8", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect sample_date\nfrom ANALYTICS_PRD.diagnostics.diagnostics__detector_daily_detail\nwhere sample_date is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.725418Z", "completed_at": "2025-08-19T19:33:50.739075Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.739871Z", "completed_at": "2025-08-19T19:33:50.739882Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.017412662506103516, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_diagnostics__detector_daily_detail_station_id.f9d82989ac", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect station_id\nfrom ANALYTICS_PRD.diagnostics.diagnostics__detector_daily_detail\nwhere station_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.595877Z", "completed_at": "2025-08-19T19:33:50.750872Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.751464Z", "completed_at": "2025-08-19T19:33:50.751471Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.16683101654052734, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_imputation__global_coefficients", "compiled": true, "compiled_code": "\n\n-- Generate dates using dbt_utils.date_spine\nwith date_spine as (\n    select date_day::date as regression_date\n    from (\n        \n\n\n\n\n\nwith rawdata as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n     + \n    \n    p8.generated_number * power(2, 8)\n     + \n    \n    p9.generated_number * power(2, 9)\n     + \n    \n    p10.generated_number * power(2, 10)\n     + \n    \n    p11.generated_number * power(2, 11)\n     + \n    \n    p12.generated_number * power(2, 12)\n     + \n    \n    p13.generated_number * power(2, 13)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n     cross join \n    \n    p as p8\n     cross join \n    \n    p as p9\n     cross join \n    \n    p as p10\n     cross join \n    \n    p as p11\n     cross join \n    \n    p as p12\n     cross join \n    \n    p as p13\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 9819\n    order by generated_number\n\n\n\n),\n\nall_periods as (\n\n    select (\n        \n\n    dateadd(\n        day,\n        row_number() over (order by 1) - 1,\n        '1998-10-01'\n        )\n\n\n    ) as date_day\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_day <= current_date()\n\n)\n\nselect * from filtered\n\n\n    ) as spine\n),\n\n-- Filter dates to get the desired date sequence\nregression_dates as (\n    select *\n    from date_spine\n    where\n        extract(day from regression_date) = 3\n        and extract(month from regression_date) in (2, 5, 8, 11)\n),\n\nregression_dates_to_evaluate as (\n    select * from regression_dates\n    \n),\n\n-- Get all of the detectors that are producing good data, based on\n-- the diagnostic tests\ngood_detectors as (\n    select\n        detector_id,\n        district,\n        sample_date\n    from ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status\n    where status = 'Good'\n),\n\ndetector_dates_for_regression as (\n    select\n        good_detectors.*,\n        regression_dates_to_evaluate.regression_date\n    from good_detectors\n    inner join regression_dates_to_evaluate\n        on\n            good_detectors.sample_date::date >= regression_dates_to_evaluate.regression_date\n            and good_detectors.sample_date\n            < dateadd(day, 7, regression_dates_to_evaluate.regression_date)\n),\n\nagg as (\n    select * from ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes\n    where station_type in ('ML', 'HV') -- TODO: make a variable for \"travel station types\"\n),\n\n/* Get the five-minute unimputed data. This is joined on the\nregression dates to only get samples which are within a week of\nthe regression date. It's also joined with the \"good detectors\"\ntable to only get samples from dates that we think were producing\ngood data. */\ndetector_counts as (\n    select\n        agg.detector_id,\n        agg.sample_date,\n        agg.sample_timestamp,\n        agg.volume_sum,\n        agg.occupancy_avg,\n        agg.speed_weighted,\n        agg.district,\n        agg.freeway,\n        agg.direction,\n        agg.station_type,\n        -- TODO: Can we give this a better name? Can we move this into the base model?\n        coalesce(agg.speed_weighted, (agg.volume_sum * 22) / nullifzero(agg.occupancy_avg) * (1 / 5280) * 12)\n            as speed_five_mins,\n        detector_dates_for_regression.regression_date\n    from agg\n    inner join detector_dates_for_regression\n        on\n            agg.detector_id = detector_dates_for_regression.detector_id\n            and agg.sample_date = detector_dates_for_regression.sample_date\n),\n\nglobal_agg as (\n    select\n        sample_date,\n        sample_timestamp,\n        district,\n        freeway,\n        direction,\n        station_type,\n        /* Note: since this is an aggregate *across* stations rather than\n        within a single station, it is more appropriate to average the sum\n        rather than sum it. In any event, these averages are intended to be\n        used for computing regression coefficients, so this just makes the\n        regression coefficient the same up to a constant factor*/\n        avg(volume_sum) as volume_sum,\n        avg(occupancy_avg) as occupancy_avg,\n        sum(volume_sum * speed_weighted) / nullifzero(sum(volume_sum)) as speed_weighted\n    from detector_counts\n    group by sample_date, sample_timestamp, district, freeway, direction, station_type\n),\n\n-- Join the 5-minute aggregated data with the district-freeway aggregation\ndetector_counts_with_global_averages as (\n    select\n        a.detector_id,\n        a.district,\n        a.regression_date,\n        a.freeway,\n        a.direction,\n        a.station_type,\n        a.speed_five_mins as speed,\n        a.volume_sum as volume,\n        a.occupancy_avg as occupancy,\n        g.volume_sum as global_volume,\n        g.occupancy_avg as global_occupancy,\n        g.speed_weighted as global_speed\n    from detector_counts as a\n    inner join global_agg as g\n        on\n            a.sample_date = g.sample_date\n            and a.sample_timestamp = g.sample_timestamp\n            and a.district = g.district\n            and a.freeway = g.freeway\n            and a.direction = g.direction\n            and a.station_type = g.station_type\n),\n\n-- Aggregate the self-joined table to get the slope\n-- and intercept of the regression.\ndetector_counts_regression as (\n    select\n        detector_id,\n        district,\n        freeway,\n        station_type,\n        direction,\n        regression_date,\n        -- speed regression model\n        regr_slope(speed, global_speed) as speed_slope,\n        regr_intercept(speed, global_speed) as speed_intercept,\n        -- flow or volume regression model\n        regr_slope(volume, global_volume) as volume_slope,\n        regr_intercept(volume, global_volume) as volume_intercept,\n        -- occupancy regression model\n        regr_slope(occupancy, global_occupancy) as occupancy_slope,\n        regr_intercept(occupancy, global_occupancy) as occupancy_intercept\n    from detector_counts_with_global_averages\n    group by detector_id, district, freeway, direction, station_type, regression_date\n    -- No point in regressing if the variables are all null,\n    -- this can save significant time.\n    having\n        (count(volume) > 0 and count(global_volume) > 0)\n        or (count(occupancy) > 0 and count(global_occupancy) > 0)\n        or (count(speed) > 0 and count(global_speed) > 0)\n)\n\nselect * from detector_counts_regression", "relation_name": "ANALYTICS_PRD.imputation.int_imputation__global_coefficients", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.735060Z", "completed_at": "2025-08-19T19:33:50.758053Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.758833Z", "completed_at": "2025-08-19T19:33:50.758844Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.024878501892089844, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_diagnostics__detector_daily_detail_status.b36d972576", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect status\nfrom ANALYTICS_PRD.diagnostics.diagnostics__detector_daily_detail\nwhere status is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.742286Z", "completed_at": "2025-08-19T19:33:50.760867Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.762411Z", "completed_at": "2025-08-19T19:33:50.762419Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.021311044692993164, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_clearinghouse__detector_g_factor_based_speed", "compiled": true, "compiled_code": "\n\nwith\n\ndetector_agg as (\n    select\n        detector_id,\n        sample_date,\n        sample_timestamp,\n        station_id,\n        lane,\n        station_type,\n        updated_volume_sum as volume_sum,\n        updated_occupancy_avg as occupancy_avg,\n        volume_observed\n    from ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_outlier_agg_five_minutes\n    where \n    1=1\n    \n),\n\nweek_gen as (\n    select\n        *,\n        date_trunc('week', sample_date) as week_start,\n        date_trunc('hour', sample_timestamp) as hour,\n        date_trunc('day', sample_date) as day\n    from detector_agg\n),\n\n/* Generate 60-th percentile of the observed occupancies as occupancy threshold for a week dataset */\nthreshold as (\n    select\n        *,\n        percentile_cont(0.6) within group (order by occupancy_avg)\n            over (partition by detector_id, week_start)\n            as occupancy_threshold,\n\n        max(lane)\n            over (partition by station_id, station_type)\n            as lane_number\n\n    from week_gen\n),\n\n/* Generate a table of free-flow speeds that are used to calculate g factor.\n * For detailed information, please refer to https://pems.dot.ca.gov/?dnode=Help&content=help_calc#speeds\n*/\nfree_speed as (\n    select\n        *,\n        case\n            when\n                station_type = 'HV'\n                then 65\n            when\n                station_type = 'ML'\n                and lane_number = 1\n                then 65\n            when\n                station_type = 'ML'\n                and lane_number = 2\n                and lane = 1\n                then 71.2\n            when\n                station_type = 'ML'\n                and lane_number = 2\n                and lane = 2\n                then 65.1\n            when\n                station_type = 'ML'\n                and lane_number = 3\n                and lane = 1\n                then 71.9\n            when\n                station_type = 'ML'\n                and lane_number = 3\n                and lane = 2\n                then 69.7\n            when\n                station_type = 'ML'\n                and lane_number = 3\n                and lane = 3\n                then 62.7\n            when\n                station_type = 'ML'\n                and lane_number = 4\n                and lane = 1\n                then 74.8\n            when\n                station_type = 'ML'\n                and lane_number = 4\n                and lane = 2\n                then 70.9\n            when\n                station_type = 'ML'\n                and lane_number = 4\n                and lane = 3\n                then 67.4\n            when\n                station_type = 'ML'\n                and lane_number = 4\n                and lane = 4\n                then 62.8\n            when\n                station_type = 'ML'\n                and lane_number = 5\n                and lane = 1\n                then 76.5\n            when\n                station_type = 'ML'\n                and lane_number = 5\n                and lane = 2\n                then 74.0\n            when\n                station_type = 'ML'\n                and lane_number = 5\n                and lane = 3\n                then 72.0\n            when\n                station_type = 'ML'\n                and lane_number = 5\n                and lane = 4\n                then 69.2\n            when\n                station_type = 'ML'\n                and lane_number = 5\n                and lane = 5\n                then 64.5\n            when\n                station_type = 'ML'\n                and lane_number = 6\n                and lane = 1\n                then 76.5\n            when\n                station_type = 'ML'\n                and lane_number = 6\n                and lane = 2\n                then 74.0\n            when\n                station_type = 'ML'\n                and lane_number = 6\n                and lane = 3\n                then 72.0\n            when\n                station_type = 'ML'\n                and lane_number = 6\n                and lane = 4\n                then 69.2\n            when\n                station_type = 'ML'\n                and lane_number = 6\n                and lane = 5\n                then 64.5\n            when\n                station_type = 'ML'\n                and lane_number = 6\n                and lane = 6\n                then 64.5\n            when\n                station_type = 'ML'\n                and lane_number = 7\n                and lane = 1\n                then 76.5\n            when\n                station_type = 'ML'\n                and lane_number = 7\n                and lane = 2\n                then 74.0\n            when\n                station_type = 'ML'\n                and lane_number = 7\n                and lane = 3\n                then 72.0\n            when\n                station_type = 'ML'\n                and lane_number = 7\n                and lane = 4\n                then 69.2\n            when\n                station_type = 'ML'\n                and lane_number = 7\n                and lane = 5\n                then 64.5\n            when\n                station_type = 'ML'\n                and lane_number = 7\n                and lane = 6\n                then 64.5\n            when\n                station_type = 'ML'\n                and lane_number = 7\n                and lane = 7\n                then 64.5\n            when\n                station_type = 'ML'\n                and lane_number = 8\n                and lane = 1\n                then 76.5\n            when\n                station_type = 'ML'\n                and lane_number = 8\n                and lane = 2\n                then 74.0\n            when\n                station_type = 'ML'\n                and lane_number = 8\n                and lane = 3\n                then 72.0\n            when\n                station_type = 'ML'\n                and lane_number = 8\n                and lane = 4\n                then 69.2\n            when\n                station_type = 'ML'\n                and lane_number = 8\n                and lane = 5\n                then 64.5\n            when\n                station_type = 'ML'\n                and lane_number = 8\n                and lane = 6\n                then 64.5\n            when\n                station_type = 'ML'\n                and lane_number = 8\n                and lane = 7\n                then 64.5\n            when\n                station_type = 'ML'\n                and lane_number = 8\n                and lane = 8\n                then 64.5\n            else 64.5\n        end as free_flow_speed\n\n    from threshold\n),\n\n/* Calculate hourly based g factor, set as 22 if there is a null dataset in the mean function */\nhourly_g_factor as (\n    select\n        *,\n        coalesce(\n            avg(case\n                when occupancy_avg < occupancy_threshold\n                    then occupancy_avg / nullifzero(volume_sum) * free_flow_speed * 440\n            end)\n                over (partition by detector_id, week_start, day, hour),\n            22)\n            as raw_g_factor\n    from free_speed\n),\n\n/* smoothing g factor */\nsmoothed_g_factor as (\n    select\n        *,\n        avg(raw_g_factor) over (partition by detector_id, day order by hour rows between 6 preceding and 6 following)\n            as g_factor\n    from hourly_g_factor\n),\n\n/* Calculate exponential filter denoted as p factor */\np_factor_value as (\n    select\n        *,\n        volume_sum / (volume_sum + 50) as p_factor\n    from smoothed_g_factor\n),\n\n/* Calculate preliminary speed based on g factor, occupancy, and flow */\nspeed_preliminary_value as (\n    select\n        *,\n        volume_sum * g_factor / nullifzero(occupancy_avg) * (1 / 440) as speed_preliminary\n    from p_factor_value\n),\n\nspeed_smoothed_value as (\n    select\n        spv.*,\n        res.value_smoothed as speed_smoothed\n    from\n        speed_preliminary_value as spv,\n        table(\n            ANALYTICS_PRD.public.exponential_smooth(spv.speed_preliminary, spv.p_factor::float)\n                over (partition by spv.detector_id order by spv.sample_timestamp)\n        ) as res\n),\n\ng_factor_speed_smoothed as (\n    select\n        *,\n        case\n            when\n                lane = 1\n                and speed_smoothed > 86.5\n                then 86.5\n            when\n                lane = 2\n                and speed_smoothed > 84\n                then 84\n            when\n                lane = 3\n                and speed_smoothed > 82\n                then 82\n            when\n                lane = 4\n                and speed_smoothed > 79.5\n                then 79.5\n            when\n                lane in (5, 6, 7, 8)\n                and speed_smoothed > 74.5\n                then 74.5\n            when\n                lane in (1, 2, 3, 4, 5, 6, 7, 8)\n                and speed_smoothed < 3\n                then 3\n            else speed_smoothed\n        end as imputed_speed\n    from speed_smoothed_value\n)\n\nselect * from g_factor_speed_smoothed", "relation_name": "ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_g_factor_based_speed", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.753827Z", "completed_at": "2025-08-19T19:33:50.761394Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.763174Z", "completed_at": "2025-08-19T19:33:50.763185Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.010425806045532227, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.accepted_values_int_clearinghouse__detector_outlier_agg_five_minutes_direction__N__E__S__W__n__e__s__w.657666a48a", "compiled": true, "compiled_code": "\n    \n    \n\nwith all_values as (\n\n    select\n        direction as value_field,\n        count(*) as n_records\n\n    from ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_outlier_agg_five_minutes\n    group by direction\n\n)\n\nselect *\nfrom all_values\nwhere value_field not in (\n    'N','E','S','W','n','e','s','w'\n)\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.763970Z", "completed_at": "2025-08-19T19:33:50.771843Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.774272Z", "completed_at": "2025-08-19T19:33:50.774280Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.014186859130859375, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__detector_outlier_agg_five_minutes_detector_id.00b390acfa", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect detector_id\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_outlier_agg_five_minutes\nwhere detector_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.613794Z", "completed_at": "2025-08-19T19:33:50.787830Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.792755Z", "completed_at": "2025-08-19T19:33:50.792766Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.18262767791748047, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_imputation__local_regional_regression_coefficients", "compiled": true, "compiled_code": "\n\n-- Generate dates using dbt_utils.date_spine\nwith date_spine as (\n    select cast(date_day as date) as regression_date\n    from (\n        \n\n\n\n\n\nwith rawdata as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n     + \n    \n    p8.generated_number * power(2, 8)\n     + \n    \n    p9.generated_number * power(2, 9)\n     + \n    \n    p10.generated_number * power(2, 10)\n     + \n    \n    p11.generated_number * power(2, 11)\n     + \n    \n    p12.generated_number * power(2, 12)\n     + \n    \n    p13.generated_number * power(2, 13)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n     cross join \n    \n    p as p8\n     cross join \n    \n    p as p9\n     cross join \n    \n    p as p10\n     cross join \n    \n    p as p11\n     cross join \n    \n    p as p12\n     cross join \n    \n    p as p13\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 9819\n    order by generated_number\n\n\n\n),\n\nall_periods as (\n\n    select (\n        \n\n    dateadd(\n        day,\n        row_number() over (order by 1) - 1,\n        '1998-10-01'\n        )\n\n\n    ) as date_day\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_day <= current_date()\n\n)\n\nselect * from filtered\n\n\n    ) as spine\n),\n\n-- -- Filter dates to get the desired date sequence\nregression_dates as (\n    select *\n    from date_spine\n    where\n        extract(day from regression_date) = 3\n        and extract(month from regression_date) in (2, 5, 8, 11)\n),\n\nregression_dates_to_evaluate as (\n    select * from regression_dates\n    \n),\n\nagg as (\n    select *\n    from ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes\n),\n\n-- Select all station pairs that are active for the chosen regression dates\nnearby_stations as (\n    select\n        nearby.station_id,\n        nearby.other_station_id,\n        nearby.other_station_is_local,\n        regression_dates_to_evaluate.regression_date\n    from ANALYTICS_PRD.vds.int_vds__nearby_stations as nearby\n    inner join regression_dates_to_evaluate\n        on\n            \n\n    regression_dates_to_evaluate.regression_date >= nearby._valid_from\n    and ( regression_dates_to_evaluate.regression_date < nearby._valid_to or nearby._valid_to is null)\n\n\n\n    /* This filters the nearby_stations model further to make sure we don't do the pairwise\n    join below on more dates than we need. In theory, the parwise join *should* be able to\n    do this filtering already, but in some profiling Snowflake was doing some join reordering\n    that caused an unnecessary row explosion, where the date filtering was happening\n    after the pairwise join. So this helps avoid that behavior. */\n    where regression_dates_to_evaluate.regression_date >= (select min(agg.sample_date) from agg)\n),\n\n\n-- Get all of the detectors that are producing good data, based on\n-- the diagnostic tests\ngood_detectors as (\n    select\n        detector_id,\n        district,\n        sample_date\n    from ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status\n    where status = 'Good'\n),\n\n/* Get the five-minute unimputed data. This is joined on the\nregression dates to only get samples which are within a week of\nthe regression date. It's also joined with the \"good detectors\"\ntable to only get samples from dates that we think were producing\ngood data. */\ndetector_counts as (\n    select\n        agg.station_id,\n        agg.detector_id,\n        agg.sample_date,\n        agg.sample_timestamp,\n        agg.volume_sum,\n        agg.occupancy_avg,\n        agg.speed_weighted,\n        good_detectors.district,\n        -- TODO: Can we give this a better name? Can we move this into the base model?\n        coalesce(agg.speed_weighted, (agg.volume_sum * 22) / nullifzero(agg.occupancy_avg) * (1 / 5280) * 12)\n            as speed_five_mins,\n        regression_dates_to_evaluate.regression_date\n    from agg\n    inner join regression_dates_to_evaluate\n        on\n            agg.sample_date >= regression_dates_to_evaluate.regression_date\n            and agg.sample_date\n            < dateadd(day, 7, regression_dates_to_evaluate.regression_date)\n    inner join good_detectors\n        on\n            agg.detector_id = good_detectors.detector_id\n            and agg.sample_date = good_detectors.sample_date\n),\n\n\n-- Self-join the 5-minute aggregated data with itself,\n-- joining on the whether a station is itself or one\n-- of it's neighbors. This is a big table, as we get\n-- the product of all of the lanes in nearby stations\ndetector_counts_pairwise as (\n    select\n        a.station_id,\n        b.station_id as other_station_id,\n        a.detector_id,\n        b.detector_id as other_detector_id,\n        a.district,\n        a.regression_date,\n        a.speed_five_mins as speed,\n        b.speed_five_mins as other_speed,\n        a.volume_sum as volume,\n        b.volume_sum as other_volume,\n        a.occupancy_avg as occupancy,\n        b.occupancy_avg as other_occupancy,\n        nearby_stations.other_station_is_local\n    from detector_counts as a\n    left join nearby_stations\n        on\n            a.station_id = nearby_stations.station_id\n            and a.regression_date = nearby_stations.regression_date\n    inner join detector_counts as b\n        on\n            nearby_stations.other_station_id = b.station_id\n            and a.sample_date = b.sample_date\n            and a.sample_timestamp = b.sample_timestamp\n),\n\n-- Aggregate the self-joined table to get the slope\n-- and intercept of the regression.\ndetector_counts_regression as (\n    select\n        detector_id,\n        other_detector_id,\n        district,\n        regression_date,\n        other_station_is_local,\n        -- speed regression model\n        regr_slope(speed, other_speed) as speed_slope,\n        regr_intercept(speed, other_speed) as speed_intercept,\n        -- flow or volume regression model\n        regr_slope(volume, other_volume) as volume_slope,\n        regr_intercept(volume, other_volume) as volume_intercept,\n        -- occupancy regression model\n        regr_slope(occupancy, other_occupancy) as occupancy_slope,\n        regr_intercept(occupancy, other_occupancy) as occupancy_intercept\n    from detector_counts_pairwise\n    where not (detector_id = other_detector_id)-- don't bother regressing on self!\n    group by detector_id, other_detector_id, district, regression_date, other_station_is_local\n    -- No point in regressing if the variables are all null,\n    -- this can save significant time.\n    having\n        (count(volume) > 0 and count(other_volume) > 0)\n        or (count(occupancy) > 0 and count(other_occupancy) > 0)\n        or (count(speed) > 0 and count(other_speed) > 0)\n)\n\nselect * from detector_counts_regression", "relation_name": "ANALYTICS_PRD.imputation.int_imputation__local_regional_regression_coefficients", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.777529Z", "completed_at": "2025-08-19T19:33:50.792186Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.794241Z", "completed_at": "2025-08-19T19:33:50.794252Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.023634910583496094, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_diagnostics__detector_monthly_by_station_sample_month.65c0e266da", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect sample_month\nfrom ANALYTICS_PRD.diagnostics.diagnostics__detector_monthly_by_station\nwhere sample_month is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.781594Z", "completed_at": "2025-08-19T19:33:50.793638Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.796184Z", "completed_at": "2025-08-19T19:33:50.796193Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.024951457977294922, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_diagnostics__detector_monthly_by_station_station_id.f981d3d0da", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect station_id\nfrom ANALYTICS_PRD.diagnostics.diagnostics__detector_monthly_by_station\nwhere station_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.788367Z", "completed_at": "2025-08-19T19:33:50.795706Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.798067Z", "completed_at": "2025-08-19T19:33:50.798075Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.011440038681030273, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_imputation__global_coefficients_DETECTOR_ID.d40559e09a", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect DETECTOR_ID\nfrom ANALYTICS_PRD.imputation.int_imputation__global_coefficients\nwhere DETECTOR_ID is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.802222Z", "completed_at": "2025-08-19T19:33:50.823995Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.825371Z", "completed_at": "2025-08-19T19:33:50.825381Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.027914762496948242, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_imputation__global_coefficients_REGRESSION_DATE.d22c3c3b6c", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect REGRESSION_DATE\nfrom ANALYTICS_PRD.imputation.int_imputation__global_coefficients\nwhere REGRESSION_DATE is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.819300Z", "completed_at": "2025-08-19T19:33:50.826163Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.829023Z", "completed_at": "2025-08-19T19:33:50.829035Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.023031949996948242, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__detector_g_factor_based_speed_G_FACTOR.98dd4d6f90", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect G_FACTOR\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_g_factor_based_speed\nwhere G_FACTOR is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.814164Z", "completed_at": "2025-08-19T19:33:50.827566Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.831867Z", "completed_at": "2025-08-19T19:33:50.831875Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.031102895736694336, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__detector_g_factor_based_speed_DETECTOR_ID.e6f27fc3ea", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect DETECTOR_ID\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_g_factor_based_speed\nwhere DETECTOR_ID is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.835197Z", "completed_at": "2025-08-19T19:33:50.841182Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.850127Z", "completed_at": "2025-08-19T19:33:50.850138Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.01947331428527832, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__detector_g_factor_based_speed_SAMPLE_DATE.ab07a36bce", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect SAMPLE_DATE\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_g_factor_based_speed\nwhere SAMPLE_DATE is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.845876Z", "completed_at": "2025-08-19T19:33:50.857108Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.857659Z", "completed_at": "2025-08-19T19:33:50.857671Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.018279314041137695, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__detector_g_factor_based_speed_STATION_ID.f8c7c79bff", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect STATION_ID\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_g_factor_based_speed\nwhere STATION_ID is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.841695Z", "completed_at": "2025-08-19T19:33:50.858586Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.859092Z", "completed_at": "2025-08-19T19:33:50.859100Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.024520397186279297, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__detector_g_factor_based_speed_SAMPLE_TIMESTAMP.3d332d0f16", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect SAMPLE_TIMESTAMP\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_g_factor_based_speed\nwhere SAMPLE_TIMESTAMP is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.852918Z", "completed_at": "2025-08-19T19:33:50.859944Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.860454Z", "completed_at": "2025-08-19T19:33:50.860461Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.00880742073059082, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__detector_g_factor_based_speed_STATION_TYPE.08902fbf35", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect STATION_TYPE\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_g_factor_based_speed\nwhere STATION_TYPE is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.807272Z", "completed_at": "2025-08-19T19:33:50.926381Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:50.926886Z", "completed_at": "2025-08-19T19:33:50.926895Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.12753915786743164, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_clearinghouse__detector_agg_five_minutes_with_missing_rows", "compiled": true, "compiled_code": "\n\nwith timestamp_spine as (\n    \n\n  \n  \n\n  with date_spine as (\n    \n\n\n\n\n\nwith rawdata as (\n\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n     + \n    \n    p8.generated_number * power(2, 8)\n     + \n    \n    p9.generated_number * power(2, 9)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n     cross join \n    \n    p as p8\n     cross join \n    \n    p as p9\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 961\n    order by generated_number\n\n\n\n),\n\nall_periods as (\n\n    select (\n        \n\n    dateadd(\n        day,\n        row_number() over (order by 1) - 1,\n        '2023-01-01'\n        )\n\n\n    ) as date_day\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_day <= current_date()\n\n)\n\nselect * from filtered\n\n\n  ),\n\n  series as (\n    \n\n    \n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    \n    p0.generated_number * power(2, 0)\n     + \n    \n    p1.generated_number * power(2, 1)\n     + \n    \n    p2.generated_number * power(2, 2)\n     + \n    \n    p3.generated_number * power(2, 3)\n     + \n    \n    p4.generated_number * power(2, 4)\n     + \n    \n    p5.generated_number * power(2, 5)\n     + \n    \n    p6.generated_number * power(2, 6)\n     + \n    \n    p7.generated_number * power(2, 7)\n     + \n    \n    p8.generated_number * power(2, 8)\n    \n    \n    + 1\n    as generated_number\n\n    from\n\n    \n    p as p0\n     cross join \n    \n    p as p1\n     cross join \n    \n    p as p2\n     cross join \n    \n    p as p3\n     cross join \n    \n    p as p4\n     cross join \n    \n    p as p5\n     cross join \n    \n    p as p6\n     cross join \n    \n    p as p7\n     cross join \n    \n    p as p8\n    \n    \n\n    )\n\n    select *\n    from unioned\n    where generated_number <= 288.0\n    order by generated_number\n\n\n  )\n\n  select DATEADD(s, (generated_number - 1) * 300, date_day) as timestamp_column\n  from date_spine\n  cross join series\n\n\n),\n\ndetector_agg as (\n    select * from ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes\n    -- This clause isn't strictly necessary but helps with performance on incremental builds\n    where \n    1=1\n    \n),\n\ndetector_meta as (\n    select * from ANALYTICS_PRD.vds.int_vds__detector_config\n),\n\n/* Get date range where a detector is expected to be collecting data. */\ndetector_date_range as (\n    select\n        detector_id,\n        active_date as sample_date\n    from ANALYTICS_PRD.vds.int_vds__active_detectors\n    where \n    1=1\n    \n),\n\n/* Expand timestamp spine to include values per detector but only for days within the detector's date range */\nspine as (\n    select\n        ts.timestamp_column,\n        dd.detector_id\n    from timestamp_spine as ts inner join detector_date_range as dd\n        on to_date(ts.timestamp_column) = dd.sample_date\n),\n\n-- Add the model where gfactor speed has been calculated\ngfactor_speed as (\n    select\n        detector_id,\n        sample_timestamp,\n        imputed_speed\n    from ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_g_factor_based_speed\n),\n\n/* Join 5-minute aggregated data to the spine to get a table without missing rows */\nbase as (\n    select\n        spine.detector_id,\n        coalesce(agg.sample_date, to_date(spine.timestamp_column)) as sample_date,\n        coalesce(agg.sample_timestamp, spine.timestamp_column) as sample_timestamp,\n        coalesce(agg.station_id, dmeta.station_id) as station_id,\n        coalesce(agg.district, dmeta.district) as district,\n        agg.sample_ct,\n        coalesce(agg.lane, dmeta.lane) as lane,\n        agg.volume_sum,\n        agg.zero_vol_ct,\n        agg.occupancy_avg,\n        agg.zero_occ_ct,\n        agg.zero_vol_pos_occ_ct,\n        agg.zero_occ_pos_vol_ct,\n        agg.high_volume_ct,\n        agg.high_occupancy_ct,\n        coalesce(agg.speed_weighted, gs.imputed_speed) as speed_weighted,\n        agg.volume_observed,\n        coalesce(agg.state_postmile, dmeta.state_postmile) as state_postmile,\n        coalesce(agg.absolute_postmile, dmeta.absolute_postmile) as absolute_postmile,\n        coalesce(agg.latitude, dmeta.latitude) as latitude,\n        coalesce(agg.longitude, dmeta.longitude) as longitude,\n        coalesce(agg.physical_lanes, dmeta.physical_lanes) as physical_lanes,\n        coalesce(agg.station_type, dmeta.station_type) as station_type,\n        coalesce(agg.county, dmeta.county) as county,\n        coalesce(agg.city, dmeta.city) as city,\n        coalesce(agg.freeway, dmeta.freeway) as freeway,\n        coalesce(agg.direction, dmeta.direction) as direction,\n        coalesce(agg.length, dmeta.length) as length,\n        coalesce(agg.station_valid_from, dmeta._valid_from) as station_valid_from,\n        coalesce(agg.station_valid_to, dmeta._valid_to) as station_valid_to\n    from spine\n    left join detector_agg as agg\n        on spine.timestamp_column = agg.sample_timestamp and spine.detector_id = agg.detector_id\n\n    -- The previously \"missing\" rows will need metadata filled in\n    left join detector_meta as dmeta\n        on\n            agg.sample_ct is null -- this filters for missing rows since it is a computed value in upstream models\n            and spine.detector_id = dmeta.detector_id\n            and to_date(spine.timestamp_column) >= dmeta._valid_from\n            and (\n                to_date(spine.timestamp_column) < dmeta._valid_to\n                or dmeta._valid_to is null\n            )\n    left join gfactor_speed as gs\n        on\n            agg.detector_id = gs.detector_id\n            and agg.sample_timestamp = gs.sample_timestamp\n)\n\nselect * from base", "relation_name": "ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes_with_missing_rows", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.933997Z", "completed_at": "2025-08-19T19:33:51.058458Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.059581Z", "completed_at": "2025-08-19T19:33:51.059593Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.12984991073608398, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_imputation__detector_agg_five_minutes", "compiled": true, "compiled_code": "\n\n/* Unimputed data aggregated to five minutes\" */\nwith base as (\n    select\n        station_id,\n        detector_id,\n        lane,\n        district,\n        sample_date,\n        sample_timestamp,\n        volume_sum,\n        occupancy_avg,\n        freeway,\n        direction,\n        county,\n        city,\n        length,\n        station_type,\n        absolute_postmile,\n        sample_ct,\n        station_valid_from,\n        station_valid_to,\n        case\n            when volume_sum = 0 and occupancy_avg = 0 then 0\n            else speed_weighted\n        end as speed_weighted\n    from ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes_with_missing_rows\n    where \n    1=1\n    \n),\n\n/* Get all detectors that are \"real\" in that they represent lanes that exist\n   (rather than lane 8 in a two lane road) with a status of \"Good\" */\ngood_detectors as (\n    select * from ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status\n    where status = 'Good'\n),\n\nnearby_stations as (\n    select * from ANALYTICS_PRD.vds.int_vds__nearby_stations\n),\n\n/* Local/regional regression coefficients. These are pairwise betweens detectors\n   that are near to each other. If they are within five miles, they are considered\n   \"regional\". If they are in the same station or the immediate upstream/downstream\n   station they are considered \"local\" */\nlocal_regional_coeffs as (\n    select * from ANALYTICS_PRD.imputation.int_imputation__local_regional_regression_coefficients\n),\n\n/* Global regression coefficients. These are per-detector, and regress the detector's\n   values with the freeway-direction-type-district average for those values at the same\n   timestamp. */\nglobal_coeffs as (\n    select * from ANALYTICS_PRD.imputation.int_imputation__global_coefficients\n),\n\n/* Join unimputed data with the \"good detectors\" model to flag whether we consider a\ndetector to be operating correctly for a given day. */\nunimputed as (\n    select\n        base.station_id,\n        base.detector_id,\n        base.lane,\n        base.district,\n        base.sample_date,\n        base.sample_timestamp,\n        base.volume_sum,\n        base.occupancy_avg,\n        base.speed_weighted,\n        base.freeway,\n        base.direction,\n        base.county,\n        base.city,\n        base.length,\n        base.station_type,\n        base.absolute_postmile,\n        base.sample_ct,\n        base.station_valid_from,\n        base.station_valid_to,\n        -- If the detector_id in the join is not null, it means that the detector\n        -- is considered to be \"good\" for a given date.\n        (good_detectors.detector_id is not null) as detector_is_good,\n        base.speed_weighted as speed_five_mins\n    from base\n    left join good_detectors\n        on\n            base.detector_id = good_detectors.detector_id\n            and base.sample_date = good_detectors.sample_date\n    where base.station_type in ('ML', 'HV') -- TODO: make a variable for \"travel station types\"\n),\n\n/* Split the unimputed data into two sets, one requiring imputation\n  (it's status is not \"Good\") and one not requiring imputation (it's status is\n  \"Good\") */\nsamples_requiring_imputation as (\n    select\n        station_id,\n        detector_id,\n        district,\n        sample_date,\n        sample_timestamp,\n        freeway,\n        direction,\n        station_type,\n        volume_sum,\n        occupancy_avg,\n        speed_five_mins\n    from unimputed\n    where not detector_is_good\n    -- there can still be gaps in detectors that are \"Good\",\n    -- so we try to impute for those as well.\n    or volume_sum is null\n    or occupancy_avg is null\n    or speed_five_mins is null\n),\n\nsamples_not_requiring_imputation as (\n    select\n        station_id,\n        detector_id,\n        district,\n        sample_date,\n        sample_timestamp,\n        freeway,\n        direction,\n        station_type,\n        volume_sum,\n        occupancy_avg,\n        speed_five_mins\n    from unimputed\n    where\n        detector_is_good\n        and volume_sum is not null\n        and occupancy_avg is not null\n        and speed_five_mins is not null\n),\n\n/** LOCAL/REGIONAL Regression follows **/\n\n/* Join the samples requiring imputation with all neighboring stations\n   not requiring imputation. These neighbors will be considered candidates\n   for helping to impute missing data. */\nsamples_requiring_imputation_with_local_regional_neighbors as (\n    select\n        imp.*,\n        non_imp.station_id as other_station_id,\n        non_imp.detector_id as other_detector_id,\n        non_imp.occupancy_avg as occupancy_avg_nbr,\n        non_imp.volume_sum as volume_sum_nbr,\n        non_imp.speed_five_mins as speed_five_mins_nbr,\n        nearby_stations.other_station_is_local\n    from samples_requiring_imputation as imp\n    inner join nearby_stations\n        on\n            imp.station_id = nearby_stations.station_id\n            and imp.sample_date >= nearby_stations._valid_from\n            and (imp.sample_date < nearby_stations._valid_to or nearby_stations._valid_to is null)\n    inner join samples_not_requiring_imputation as non_imp\n        on\n            nearby_stations.other_station_id = non_imp.station_id\n            and (imp.detector_id != non_imp.detector_id)\n            and imp.sample_date = non_imp.sample_date\n            and imp.sample_timestamp = non_imp.sample_timestamp\n),\n\n/* Join the samples requiring imputation with the local and regional\n   coefficients. This will both give us the coefficients needed for\n   regressing, as well as give us the ID/Lane of the other station\n   that we'll be regressing against. This makes the number of rows\n   increase significantly, as we get pairwise coefficients for a\n   detector and all of its regional neighbors! */\nsamples_requiring_imputation_with_local_regional_coeffs as (\n    select\n        samples.*,\n        local_regional_coeffs.speed_slope,\n        local_regional_coeffs.speed_intercept,\n        local_regional_coeffs.volume_slope,\n        local_regional_coeffs.volume_intercept,\n        local_regional_coeffs.occupancy_slope,\n        local_regional_coeffs.occupancy_intercept,\n        local_regional_coeffs.regression_date\n    from samples_requiring_imputation_with_local_regional_neighbors as samples\n    asof join local_regional_coeffs\n        match_condition(samples.sample_date >= local_regional_coeffs.regression_date)\n        on\n            samples.detector_id = local_regional_coeffs.detector_id\n            and samples.district = local_regional_coeffs.district\n),\n\n/* Actually do the local and regional imputation! We compute it for all\n   the neighboring detectors, then aggregate up to the median of the imputed\n   values, and finally clamp them to physical numbers (like greater than 0). */\nlocal_imputed as (\n    select\n        detector_id,\n        sample_date,\n        sample_timestamp,\n        -- Volume calculation\n        greatest(median(volume_slope * volume_sum_nbr + volume_intercept), 0) as volume_local_regression,\n        -- Occupancy calculation\n        least(greatest(median(occupancy_slope * occupancy_avg_nbr + occupancy_intercept), 0), 1)\n            as occupancy_local_regression,\n        -- Speed calculation\n        greatest(median(speed_slope * speed_five_mins_nbr + speed_intercept), 0) as speed_local_regression,\n        avg(volume_sum_nbr) as volume_local_avg,\n        avg(occupancy_avg_nbr) as occupancy_local_avg,\n        sum(volume_sum_nbr * speed_five_mins_nbr) / nullifzero(sum(volume_sum_nbr)) as speed_local_avg,\n        any_value(regression_date) as regression_date\n    from\n        samples_requiring_imputation_with_local_regional_coeffs\n    where other_station_is_local = true\n    group by detector_id, sample_date, sample_timestamp\n),\n\nregional_imputed as (\n    select\n        detector_id,\n        sample_date,\n        sample_timestamp,\n        -- Volume calculation\n        greatest(median(volume_slope * volume_sum_nbr + volume_intercept), 0) as volume_regional_regression,\n        -- Occupancy calculation\n        least(greatest(median(occupancy_slope * occupancy_avg_nbr + occupancy_intercept), 0), 1)\n            as occupancy_regional_regression,\n        -- Speed calculation\n        greatest(median(speed_slope * speed_five_mins_nbr + speed_intercept), 0) as speed_regional_regression,\n        avg(volume_sum_nbr) as volume_regional_avg,\n        avg(occupancy_avg_nbr) as occupancy_regional_avg,\n        sum(volume_sum_nbr * speed_five_mins_nbr) / nullifzero(sum(volume_sum_nbr)) as speed_regional_avg,\n        any_value(regression_date) as regression_date\n    from\n        samples_requiring_imputation_with_local_regional_coeffs\n    group by detector_id, sample_date, sample_timestamp\n),\n\n/** Global regression follows! **/\n\n/* Join the samples requiring imputation with the global\n   coefficients. */\nsamples_requiring_imputation_with_global_coeffs as (\n    select\n        samples_requiring_imputation.*,\n        global_coeffs.speed_slope,\n        global_coeffs.speed_intercept,\n        global_coeffs.volume_slope,\n        global_coeffs.volume_intercept,\n        global_coeffs.occupancy_slope,\n        global_coeffs.occupancy_intercept,\n        global_coeffs.regression_date\n    from samples_requiring_imputation\n    asof join global_coeffs\n        match_condition(samples_requiring_imputation.sample_date >= global_coeffs.regression_date)\n        on\n            samples_requiring_imputation.detector_id = global_coeffs.detector_id\n            and samples_requiring_imputation.district = global_coeffs.district\n),\n\n/* Aggregate the samples not requiring imputation up to the freeway/district/station-type\n   level. This creates the value against which we will be aggregating for each timestamp.\n   It's important that this aggregation look idential to that in\n   int_imputation__global_coefficients, otherwise the regression will be wrong. */\nfreeway_district_agg as (\n    select\n        sample_date,\n        sample_timestamp,\n        district,\n        freeway,\n        direction,\n        station_type,\n        /* Note: since this is an aggregate *across* stations rather than\n        within a single station, it is more appropriate to average the sum\n        rather than sum it. In any event, these averages are intended to be\n        used for computing regression coefficients, so this just makes the\n        regression coefficient the same up to a constant factor*/\n        avg(volume_sum) as volume_sum,\n        avg(occupancy_avg) as occupancy_avg,\n        sum(volume_sum * speed_five_mins) / nullifzero(sum(volume_sum)) as speed_five_mins\n    from samples_not_requiring_imputation\n    group by sample_date, sample_timestamp, district, freeway, direction, station_type\n),\n\n/* Join the averages in with the samples requiring imputation. */\nsamples_requiring_imputation_with_global as (\n    select\n        imp.*,\n        non_imp.speed_five_mins as speed_five_mins_global,\n        non_imp.volume_sum as volume_sum_global,\n        non_imp.occupancy_avg as occupancy_avg_global\n    from samples_requiring_imputation_with_global_coeffs as imp\n    inner join freeway_district_agg as non_imp\n        on\n            imp.freeway = non_imp.freeway\n            and imp.direction = non_imp.direction\n            and imp.station_type = non_imp.station_type\n            and imp.district = non_imp.district\n            and imp.sample_date = non_imp.sample_date\n            and imp.sample_timestamp = non_imp.sample_timestamp\n),\n\n/* Finally, do the global imputation! */\nglobal_imputed as (\n    select\n        detector_id,\n        sample_date,\n        sample_timestamp,\n        -- Volume calculation\n        greatest(volume_slope * volume_sum_global + volume_intercept, 0) as volume_global_regression,\n        -- Occupancy calculation\n        least(greatest(occupancy_slope * occupancy_avg_global + occupancy_intercept, 0), 1)\n            as occupancy_global_regression,\n        -- Speed calculation\n        greatest(speed_slope * speed_five_mins_global + speed_intercept, 0) as speed_global_regression,\n        regression_date\n    from\n        samples_requiring_imputation_with_global\n),\n\n/** Put the local, regional, and global datasets all together **/\nagg_with_local_regional_global_imputation as (\n    select\n        unimputed.*,\n        local_imputed.regression_date as local_regression_date,\n        local_imputed.volume_local_regression,\n        local_imputed.occupancy_local_regression,\n        local_imputed.speed_local_regression,\n        local_imputed.volume_local_avg,\n        local_imputed.occupancy_local_avg,\n        local_imputed.speed_local_avg,\n        regional_imputed.regression_date as regional_regression_date,\n        regional_imputed.volume_regional_regression,\n        regional_imputed.occupancy_regional_regression,\n        regional_imputed.speed_regional_regression,\n        regional_imputed.volume_regional_avg,\n        regional_imputed.occupancy_regional_avg,\n        regional_imputed.speed_regional_avg,\n        global_imputed.regression_date as global_regression_date,\n        global_imputed.volume_global_regression,\n        global_imputed.occupancy_global_regression,\n        global_imputed.speed_global_regression\n    from unimputed\n    left join local_imputed\n        on\n            unimputed.detector_id = local_imputed.detector_id\n            and unimputed.sample_date = local_imputed.sample_date\n            and unimputed.sample_timestamp = local_imputed.sample_timestamp\n    left join regional_imputed\n        on\n            unimputed.detector_id = regional_imputed.detector_id\n            and unimputed.sample_date = regional_imputed.sample_date\n            and unimputed.sample_timestamp = regional_imputed.sample_timestamp\n    left join global_imputed\n        on\n            unimputed.detector_id = global_imputed.detector_id\n            and unimputed.sample_date = global_imputed.sample_date\n            and unimputed.sample_timestamp = global_imputed.sample_timestamp\n)\n\nselect * from agg_with_local_regional_global_imputation", "relation_name": "ANALYTICS_PRD.imputation.int_imputation__detector_agg_five_minutes", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.946404Z", "completed_at": "2025-08-19T19:33:51.059028Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.060978Z", "completed_at": "2025-08-19T19:33:51.060987Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.12964248657226562, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.five_minute_daily_count_int_clearinghouse__detector_agg_five_minutes_with_missing_rows_detector_id__sample_date.d97c07d228", "compiled": true, "compiled_code": "\nwith\nvalidation_errors as (\n    select detector_id,sample_date\n    from ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes_with_missing_rows\n    group by detector_id,sample_date\n    having count(*) != 288\n)\n\nselect * from validation_errors\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.942039Z", "completed_at": "2025-08-19T19:33:51.060429Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.063008Z", "completed_at": "2025-08-19T19:33:51.063019Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.13222455978393555, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.accepted_values_int_clearinghouse__detector_agg_five_minutes_with_missing_rows_DIRECTION__N__E__S__W__n__e__s__w.c7d6de60bf", "compiled": true, "compiled_code": "\n    \n    \n\nwith all_values as (\n\n    select\n        DIRECTION as value_field,\n        count(*) as n_records\n\n    from ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes_with_missing_rows\n    group by DIRECTION\n\n)\n\nselect *\nfrom all_values\nwhere value_field not in (\n    'N','E','S','W','n','e','s','w'\n)\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:50.950779Z", "completed_at": "2025-08-19T19:33:51.061776Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.064504Z", "completed_at": "2025-08-19T19:33:51.064513Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.1321265697479248, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__detector_agg_five_minutes_with_missing_rows_DETECTOR_ID.a53f2c9f78", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect DETECTOR_ID\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes_with_missing_rows\nwhere DETECTOR_ID is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.069631Z", "completed_at": "2025-08-19T19:33:51.083672Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.088719Z", "completed_at": "2025-08-19T19:33:51.088730Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.02349543571472168, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__detector_agg_five_minutes_with_missing_rows_SAMPLE_DATE.4d03e0dbd9", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect SAMPLE_DATE\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes_with_missing_rows\nwhere SAMPLE_DATE is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.074672Z", "completed_at": "2025-08-19T19:33:51.089511Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.090792Z", "completed_at": "2025-08-19T19:33:51.090804Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.024456501007080078, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__detector_agg_five_minutes_with_missing_rows_SAMPLE_TIMESTAMP.510fb18280", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect SAMPLE_TIMESTAMP\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes_with_missing_rows\nwhere SAMPLE_TIMESTAMP is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.079387Z", "completed_at": "2025-08-19T19:33:51.091559Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.093721Z", "completed_at": "2025-08-19T19:33:51.093729Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.025732755661010742, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__detector_agg_five_minutes_with_missing_rows_STATION_ID.2d79e2598b", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect STATION_ID\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes_with_missing_rows\nwhere STATION_ID is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.084277Z", "completed_at": "2025-08-19T19:33:51.092115Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.094527Z", "completed_at": "2025-08-19T19:33:51.094535Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.025516510009765625, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_clearinghouse__detector_agg_five_minutes_with_missing_rows_STATION_TYPE.538b044f46", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect STATION_TYPE\nfrom ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes_with_missing_rows\nwhere STATION_TYPE is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.097478Z", "completed_at": "2025-08-19T19:33:51.108750Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.113773Z", "completed_at": "2025-08-19T19:33:51.113784Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.021262407302856445, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_imputation__detector_imputed_agg_five_minutes", "compiled": true, "compiled_code": "\n\n-- read observed and imputed five minutes data\nwith obs_imputed_five_minutes_agg as (\n    select *\n    from ANALYTICS_PRD.imputation.int_imputation__detector_agg_five_minutes\n    where \n    1=1\n    \n),\n\n-- now select the final speed, volume and occupancy\n-- tag if it is observed or imputed\nhybrid_five_mins_agg as (\n    select\n        station_id,\n        detector_id,\n        station_type,\n        lane,\n        direction,\n        county,\n        city,\n        district,\n        freeway,\n        length,\n        detector_is_good,\n        sample_date,\n        sample_timestamp,\n        absolute_postmile,\n        sample_ct,\n        station_valid_from,\n        station_valid_to,\n        -- select the imputed value\n        case\n            when detector_is_good = false or volume_sum is null\n                then\n                    coalesce(\n                        volume_local_regression,\n                        volume_regional_regression,\n                        volume_global_regression,\n                        volume_local_avg,\n                        volume_regional_avg\n                    )\n            else volume_sum\n        end as volume_sum,\n        case\n            when detector_is_good = false or speed_five_mins is null\n                then\n                    coalesce(\n                        speed_local_regression,\n                        speed_regional_regression,\n                        speed_global_regression,\n                        speed_local_avg,\n                        speed_regional_avg\n                    )\n            else speed_five_mins\n        end as speed_five_mins,\n        case\n            when detector_is_good = false or occupancy_avg is null\n                then\n                    coalesce(\n                        occupancy_local_regression,\n                        occupancy_regional_regression,\n                        occupancy_global_regression,\n                        occupancy_local_avg,\n                        occupancy_regional_avg\n                    )\n            else occupancy_avg\n        end as occupancy_avg,\n        -- assign the imputation date\n        case\n            when\n                detector_is_good = false\n                or volume_sum is null\n                or occupancy_avg is null\n                or speed_five_mins is null\n                then\n                    coalesce(local_regression_date, regional_regression_date, global_regression_date)\n            else sample_date\n        end as regression_date,\n\n        -- assign the imputation method\n        case\n            when\n                (detector_is_good = false or volume_sum is null) and volume_local_regression is not null\n                then 'local'\n            when\n                (detector_is_good = false or volume_sum is null) and volume_regional_regression is not null\n                then 'regional'\n            when\n                (detector_is_good = false or volume_sum is null) and volume_global_regression is not null\n                then 'global'\n            when\n                (detector_is_good = false or volume_sum is null) and volume_local_avg is not null\n                then 'local_avg'\n            when\n                (detector_is_good = false or volume_sum is null) and volume_regional_avg is not null\n                then 'regional_avg'\n            when\n                (detector_is_good = false or volume_sum is null)\n                and volume_local_regression is null\n                and volume_regional_regression is null\n                and volume_global_regression is null\n                and volume_local_avg is null\n                and volume_regional_avg is null\n                then 'observed_unimputed'\n            else 'observed'\n        end as volume_imputation_method,\n        case\n            when\n                (detector_is_good = false or speed_five_mins is null) and speed_local_regression is not null\n                then 'local'\n            when\n                (detector_is_good = false or speed_five_mins is null) and speed_regional_regression is not null\n                then 'regional'\n            when\n                (detector_is_good = false or speed_five_mins is null) and speed_global_regression is not null\n                then 'global'\n            when\n                (detector_is_good = false or speed_five_mins is null) and speed_local_avg is not null\n                then 'local_avg'\n            when\n                (detector_is_good = false or speed_five_mins is null) and speed_regional_avg is not null\n                then 'regional_avg'\n            when\n                (detector_is_good = false or speed_five_mins is null)\n                and speed_local_regression is null\n                and speed_regional_regression is null\n                and speed_global_regression is null\n                and speed_local_avg is null\n                and speed_regional_avg is null\n                then 'observed_unimputed'\n            else 'observed'\n        end as speed_imputation_method,\n        case\n            when\n                (detector_is_good = false or occupancy_avg is null) and occupancy_local_regression is not null\n                then 'local'\n            when\n                (detector_is_good = false or occupancy_avg is null) and occupancy_regional_regression is not null\n                then 'regional'\n            when\n                (detector_is_good = false or occupancy_avg is null) and occupancy_global_regression is not null\n                then 'global'\n            when\n                (detector_is_good = false or occupancy_avg is null) and occupancy_local_avg is not null\n                then 'local_avg'\n            when\n                (detector_is_good = false or occupancy_avg is null) and occupancy_regional_avg is not null\n                then 'regional_avg'\n            when\n                (detector_is_good = false or occupancy_avg is null)\n                and occupancy_local_regression is null\n                and occupancy_regional_regression is null\n                and occupancy_global_regression is null\n                and occupancy_local_avg is null\n                and occupancy_regional_avg is null\n                then 'observed_unimputed'\n            else 'observed'\n        end as occupancy_imputation_method\n    from obs_imputed_five_minutes_agg\n)\n\n-- select the final observed and imputed five mins agg table\nselect * from hybrid_five_mins_agg", "relation_name": "ANALYTICS_PRD.imputation.int_imputation__detector_imputed_agg_five_minutes", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.104162Z", "completed_at": "2025-08-19T19:33:51.114759Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.121279Z", "completed_at": "2025-08-19T19:33:51.121291Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.025585651397705078, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_imputation__detector_agg_five_minutes_DETECTOR_ID.aaf4638c12", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect DETECTOR_ID\nfrom ANALYTICS_PRD.imputation.int_imputation__detector_agg_five_minutes\nwhere DETECTOR_ID is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.115291Z", "completed_at": "2025-08-19T19:33:51.122962Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.125060Z", "completed_at": "2025-08-19T19:33:51.125068Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.021679401397705078, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_imputation__detector_agg_five_minutes_SAMPLE_TIMESTAMP.0db4de7197", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect SAMPLE_TIMESTAMP\nfrom ANALYTICS_PRD.imputation.int_imputation__detector_agg_five_minutes\nwhere SAMPLE_TIMESTAMP is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.109896Z", "completed_at": "2025-08-19T19:33:51.123464Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.125837Z", "completed_at": "2025-08-19T19:33:51.125845Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.02299785614013672, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_imputation__detector_agg_five_minutes_SAMPLE_DATE.a7f33cd064", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect SAMPLE_DATE\nfrom ANALYTICS_PRD.imputation.int_imputation__detector_agg_five_minutes\nwhere SAMPLE_DATE is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.129244Z", "completed_at": "2025-08-19T19:33:51.152903Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.154460Z", "completed_at": "2025-08-19T19:33:51.154472Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.03002333641052246, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.imputation__detector_imputed_agg_five_minutes", "compiled": true, "compiled_code": "\n\n\nwith imputation_five_mins as (\n    select *\n    from ANALYTICS_PRD.imputation.int_imputation__detector_imputed_agg_five_minutes\n    where\n        station_type in ('ML', 'HV')\n        and sample_date >= dateadd(day, -4, current_date)\n),\n\nimputation_five_minsc as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            imputation_five_mins.*,\n            c.county_name,\n            c.county_abb\n        from imputation_five_mins\n        inner join county as c\n        on imputation_five_mins.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\nimputation_five_minscc as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from imputation_five_minsc as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n)\n\nselect * from imputation_five_minscc", "relation_name": "ANALYTICS_PRD.imputation.imputation__detector_imputed_agg_five_minutes", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.134089Z", "completed_at": "2025-08-19T19:33:51.153690Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.155830Z", "completed_at": "2025-08-19T19:33:51.155841Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.029308080673217773, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.imputation__detector_summary", "compiled": true, "compiled_code": "\n\n-- read observed and imputed five minutes data\nwith obs_imputed_five_minutes_agg as (\n    select *\n    from ANALYTICS_PRD.imputation.int_imputation__detector_imputed_agg_five_minutes\n    where \n        -- Look back to account for any late-arriving data\n            sample_date > (\n                select\n                    dateadd(\n                        day,\n                        -2,\n                        max(sample_date)\n                    )\n                from ANALYTICS_PRD.imputation.imputation__detector_summary\n            )\n            \n    \n),\n\nimputation_count as (\n    select\n        station_id,\n        detector_id,\n        lane,\n        sample_date,\n        count(*) as sample_ct,\n        count_if(occupancy_imputation_method = 'local') as occ_local_imputation_sample,\n        count_if(occupancy_imputation_method = 'regional') as occ_regional_imputation_sample,\n        count_if(occupancy_imputation_method = 'global') as occ_global_imputation_sample,\n        count_if(occupancy_imputation_method = 'local_avg') as occ_local_avg_imputation_sample,\n        count_if(occupancy_imputation_method = 'regional_avg') as occ_regional_avg_imputation_sample,\n        count_if(occupancy_imputation_method = 'observed') as occ_observed_sample,\n        count_if(occupancy_imputation_method is NULL) as occ_unobserved_unimputed,\n        count_if(volume_imputation_method = 'local') as vol_local_imputation_sample,\n        count_if(volume_imputation_method = 'regional') as vol_regional_imputation_sample,\n        count_if(volume_imputation_method = 'global') as vol_global_imputation_sample,\n        count_if(volume_imputation_method = 'local_avg') as vol_local_avg_imputation_sample,\n        count_if(volume_imputation_method = 'regional_avg') as vol_regional_avg_imputation_sample,\n        count_if(volume_imputation_method = 'observed') as vol_observed_sample,\n        count_if(volume_imputation_method is NULL) as vol_unobserved_unimputed,\n        count_if(speed_imputation_method = 'local') as speed_local_imputation_sample,\n        count_if(speed_imputation_method = 'regional') as speed_regional_imputation_sample,\n        count_if(speed_imputation_method = 'global') as speed_global_imputation_sample,\n        count_if(speed_imputation_method = 'local_avg') as speed_local_avg_imputation_sample,\n        count_if(speed_imputation_method = 'regional_avg') as speed_regional_avg_imputation_sample,\n        count_if(speed_imputation_method = 'observed') as speed_observed_sample,\n        count_if(speed_imputation_method is NULL) as speed_unobserved_unimputed\n    from obs_imputed_five_minutes_agg\n    group by detector_id, sample_date, station_id, lane\n),\n\nimputation_pct as (\n    select\n        detector_id,\n        station_id,\n        lane,\n        sample_date,\n        sample_ct,\n        coalesce(occ_local_imputation_sample, 0) / nullifzero(sample_ct)\n        * 100 as pct_of_occupancy_local_regression,\n        coalesce(occ_regional_imputation_sample, 0) / nullifzero(sample_ct)\n        * 100 as pct_of_occupancy_regional_regression,\n        coalesce(occ_global_imputation_sample, 0) / nullifzero(sample_ct) * 100 as pct_of_occupancy_global_regression,\n        coalesce(occ_local_avg_imputation_sample, 0) / nullifzero(sample_ct) * 100 as pct_of_occupancy_local_avg,\n        coalesce(occ_regional_avg_imputation_sample, 0) / nullifzero(sample_ct) * 100 as pct_of_occupancy_regional_avg,\n        coalesce(occ_unobserved_unimputed, 0) / nullifzero(sample_ct) * 100 as pct_of_occupancy_unobserved_unimputed,\n        coalesce(occ_observed_sample, 0) / nullifzero(sample_ct) * 100 as pct_of_occupancy_observed,\n\n        coalesce(vol_local_imputation_sample, 0) / nullifzero(sample_ct) * 100 as pct_of_volume_local_regression,\n        coalesce(vol_regional_imputation_sample, 0) / nullifzero(sample_ct) * 100 as pct_of_volume_regional_regression,\n        coalesce(vol_global_imputation_sample, 0) / nullifzero(sample_ct) * 100 as pct_of_volume_global_regression,\n        coalesce(vol_local_avg_imputation_sample, 0) / nullifzero(sample_ct) * 100 as pct_of_volume_local_avg,\n        coalesce(vol_regional_avg_imputation_sample, 0) / nullifzero(sample_ct) * 100 as pct_of_volume_regional_avg,\n        coalesce(vol_unobserved_unimputed, 0) / nullifzero(sample_ct) * 100 as pct_of_volume_unobserved_unimputed,\n        coalesce(vol_observed_sample, 0) / nullifzero(sample_ct) * 100 as pct_of_volume_observed,\n\n        coalesce(speed_local_imputation_sample, 0) / nullifzero(sample_ct) * 100 as pct_of_speed_local_regression,\n        coalesce(speed_regional_imputation_sample, 0) / nullifzero(sample_ct)\n        * 100 as pct_of_speed_regional_regression,\n        coalesce(speed_global_imputation_sample, 0) / nullifzero(sample_ct) * 100 as pct_of_speed_global_regression,\n        coalesce(speed_local_avg_imputation_sample, 0) / nullifzero(sample_ct) * 100 as pct_of_speed_local_avg,\n        coalesce(speed_regional_avg_imputation_sample, 0) / nullifzero(sample_ct) * 100 as pct_of_speed_regional_avg,\n        coalesce(speed_unobserved_unimputed, 0) / nullifzero(sample_ct) * 100 as pct_of_speed_unobserved_unimputed,\n        coalesce(speed_observed_sample, 0) / nullifzero(sample_ct) * 100 as pct_of_speed_observed\n    from imputation_count\n)\n\nselect * from imputation_pct", "relation_name": "ANALYTICS_PRD.imputation.imputation__detector_summary", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.141940Z", "completed_at": "2025-08-19T19:33:51.155246Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.157750Z", "completed_at": "2025-08-19T19:33:51.157758Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.024907350540161133, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_performance__detector_metrics_agg_five_minutes", "compiled": true, "compiled_code": "\n\nwith\nfive_minute_agg as (\n    select\n        station_id,\n        lane,\n        detector_id,\n        sample_date,\n        sample_timestamp,\n        district,\n        county,\n        city,\n        freeway,\n        direction,\n        length,\n        sample_ct,\n        volume_sum,\n        occupancy_avg,\n        speed_five_mins,\n        station_type,\n        absolute_postmile,\n        volume_imputation_method,\n        speed_imputation_method,\n        occupancy_imputation_method,\n        station_valid_from,\n        station_valid_to\n    from ANALYTICS_PRD.imputation.int_imputation__detector_imputed_agg_five_minutes\n    where \n    1=1\n    \n),\n\nvmt_vht_metrics as (\n    select\n        *,\n        --vehicle-miles/5-min\n        volume_sum * length as vmt,\n        --vehicle-hours/5-min\n        volume_sum * length / nullifzero(speed_five_mins) as vht,\n        --q is in miles per hour for single station\n        vmt / nullifzero(vht) as q_value,\n        -- travel time\n        60 / nullifzero(q_value) as tti\n    from five_minute_agg\n),\n\ndelay_metrics as (\n    select\n        vvm.*,\n        /*  The formula for delay is: F * (L/V - L/V_t). F = flow (volume),\n        L = length of the segment, V = current speed, and V_t = threshold speed. */\n        \n            greatest(vvm.volume_sum * ((vvm.length / nullifzero(vvm.speed_five_mins)) - (vvm.length / 35)), 0)\n                as delay_35_mph\n            \n                ,\n            \n\n        \n            greatest(vvm.volume_sum * ((vvm.length / nullifzero(vvm.speed_five_mins)) - (vvm.length / 40)), 0)\n                as delay_40_mph\n            \n                ,\n            \n\n        \n            greatest(vvm.volume_sum * ((vvm.length / nullifzero(vvm.speed_five_mins)) - (vvm.length / 45)), 0)\n                as delay_45_mph\n            \n                ,\n            \n\n        \n            greatest(vvm.volume_sum * ((vvm.length / nullifzero(vvm.speed_five_mins)) - (vvm.length / 50)), 0)\n                as delay_50_mph\n            \n                ,\n            \n\n        \n            greatest(vvm.volume_sum * ((vvm.length / nullifzero(vvm.speed_five_mins)) - (vvm.length / 55)), 0)\n                as delay_55_mph\n            \n                ,\n            \n\n        \n            greatest(vvm.volume_sum * ((vvm.length / nullifzero(vvm.speed_five_mins)) - (vvm.length / 60)), 0)\n                as delay_60_mph\n            \n\n        \n\n    from vmt_vht_metrics as vvm\n),\n\nproductivity_metrics as (\n    select\n        dm.*,\n        /*\n        The formula for Productivity is: Length * (1 - (actual flow / flow capacity))\n        */\n        \n            case\n                when dm.speed_five_mins >= 35\n                    then 0\n                else dm.length * (1 - (dm.volume_sum / mc.max_capacity_5min))\n            end\n                as lost_productivity_35_mph\n            \n                ,\n            \n\n        \n            case\n                when dm.speed_five_mins >= 40\n                    then 0\n                else dm.length * (1 - (dm.volume_sum / mc.max_capacity_5min))\n            end\n                as lost_productivity_40_mph\n            \n                ,\n            \n\n        \n            case\n                when dm.speed_five_mins >= 45\n                    then 0\n                else dm.length * (1 - (dm.volume_sum / mc.max_capacity_5min))\n            end\n                as lost_productivity_45_mph\n            \n                ,\n            \n\n        \n            case\n                when dm.speed_five_mins >= 50\n                    then 0\n                else dm.length * (1 - (dm.volume_sum / mc.max_capacity_5min))\n            end\n                as lost_productivity_50_mph\n            \n                ,\n            \n\n        \n            case\n                when dm.speed_five_mins >= 55\n                    then 0\n                else dm.length * (1 - (dm.volume_sum / mc.max_capacity_5min))\n            end\n                as lost_productivity_55_mph\n            \n                ,\n            \n\n        \n            case\n                when dm.speed_five_mins >= 60\n                    then 0\n                else dm.length * (1 - (dm.volume_sum / mc.max_capacity_5min))\n            end\n                as lost_productivity_60_mph\n            \n\n        \n\n    from delay_metrics as dm\n    inner join ANALYTICS_PRD.performance.int_performance__max_capacity as mc\n        on dm.detector_id = mc.detector_id\n)\n\nselect * from productivity_metrics", "relation_name": "ANALYTICS_PRD.performance.int_performance__detector_metrics_agg_five_minutes", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.148500Z", "completed_at": "2025-08-19T19:33:51.156594Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.159240Z", "completed_at": "2025-08-19T19:33:51.159249Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.025771141052246094, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.quality_imputation_daily_sample_count", "compiled": true, "compiled_code": "\n\n-- read observed and imputed five minutes data\nwith obs_imputed_five_minutes_agg as (\n    select *\n    from ANALYTICS_PRD.imputation.int_imputation__detector_imputed_agg_five_minutes\n    where station_type in ('HV', 'ML') and \n        -- Look back to account for any late-arriving data\n            sample_date > (\n                select\n                    dateadd(\n                        day,\n                        -2,\n                        max(sample_date)\n                    )\n                from ANALYTICS_PRD.quality.quality_imputation_daily_sample_count\n            )\n            \n    \n),\n\nimputation_status_count as (\n    select\n        sample_date,\n        count(*) as sample_ct,\n        count_if(occupancy_imputation_method = 'local') as occ_local_imputation_sample,\n        count_if(occupancy_imputation_method = 'regional') as occ_regional_imputation_sample,\n        count_if(occupancy_imputation_method = 'global') as occ_global_imputation_sample,\n        count_if(occupancy_imputation_method = 'local_avg') as occ_local_avg_imputation_sample,\n        count_if(occupancy_imputation_method = 'regional_avg') as occ_regional_avg_imputation_sample,\n        count_if(occupancy_imputation_method = 'observed') as occ_observed_sample,\n        count_if(occupancy_imputation_method = 'observed_unimputed') as occ_unobserved_unimputed,\n        count_if(volume_imputation_method = 'local') as vol_local_imputation_sample,\n        count_if(volume_imputation_method = 'regional') as vol_regional_imputation_sample,\n        count_if(volume_imputation_method = 'global') as vol_global_imputation_sample,\n        count_if(volume_imputation_method = 'local_avg') as vol_local_avg_imputation_sample,\n        count_if(volume_imputation_method = 'regional_avg') as vol_regional_avg_imputation_sample,\n        count_if(volume_imputation_method = 'observed') as vol_observed_sample,\n        count_if(volume_imputation_method = 'observed_unimputed') as vol_unobserved_unimputed,\n        count_if(speed_imputation_method = 'local') as speed_local_imputation_sample,\n        count_if(speed_imputation_method = 'regional') as speed_regional_imputation_sample,\n        count_if(speed_imputation_method = 'global') as speed_global_imputation_sample,\n        count_if(speed_imputation_method = 'local_avg') as speed_local_avg_imputation_sample,\n        count_if(speed_imputation_method = 'regional_avg') as speed_regional_avg_imputation_sample,\n        count_if(speed_imputation_method = 'observed') as speed_observed_sample,\n        count_if(speed_imputation_method = 'observed_unimputed') as speed_unobserved_unimputed,\n        count_if(occupancy_imputation_method != 'observed' and occupancy_imputation_method != 'observed_unimputed')\n            as occ_imputed_sample,\n        count_if(volume_imputation_method != 'observed' and volume_imputation_method != 'observed_unimputed')\n            as vol_imputed_sample,\n        count_if(speed_imputation_method != 'observed' and speed_imputation_method != 'observed_unimputed')\n            as speed_imputed_sample\n    from obs_imputed_five_minutes_agg\n    group by sample_date\n),\n\nsample_count as (\n    select\n        *,\n        (vol_imputed_sample / nullif(sample_ct, 0)) * 100 as pct_vol_imputed,\n        (vol_observed_sample / nullif(sample_ct, 0)) * 100 as pct_vol_observed,\n        (vol_unobserved_unimputed / nullif(sample_ct, 0)) * 100 as pct_vol_observed_unimputed,\n        (speed_imputed_sample / nullif(sample_ct, 0)) * 100 as pct_speed_imputed,\n        (speed_observed_sample / nullif(sample_ct, 0)) * 100 as pct_speed_observed,\n        (speed_unobserved_unimputed / nullif(sample_ct, 0)) * 100 as pct_speed_observed_unimputed,\n        (occ_imputed_sample / nullif(sample_ct, 0)) * 100 as pct_occ_imputed,\n        (occ_observed_sample / nullif(sample_ct, 0)) * 100 as pct_occ_observed,\n        (occ_unobserved_unimputed / nullif(sample_ct, 0)) * 100 as pct_occ_observed_unimputed\n    from imputation_status_count\n)\n\nselect *\nfrom sample_count", "relation_name": "ANALYTICS_PRD.quality.quality_imputation_daily_sample_count", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.164800Z", "completed_at": "2025-08-19T19:33:51.184497Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.185778Z", "completed_at": "2025-08-19T19:33:51.185787Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.025696277618408203, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_imputation__detector_imputed_agg_five_minutes_DETECTOR_ID.0d89789d52", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect DETECTOR_ID\nfrom ANALYTICS_PRD.imputation.int_imputation__detector_imputed_agg_five_minutes\nwhere DETECTOR_ID is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.169568Z", "completed_at": "2025-08-19T19:33:51.185096Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.187162Z", "completed_at": "2025-08-19T19:33:51.187171Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.02586197853088379, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_imputation__detector_imputed_agg_five_minutes_SAMPLE_TIMESTAMP.90fedfff93", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect SAMPLE_TIMESTAMP\nfrom ANALYTICS_PRD.imputation.int_imputation__detector_imputed_agg_five_minutes\nwhere SAMPLE_TIMESTAMP is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.178593Z", "completed_at": "2025-08-19T19:33:51.186681Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.189090Z", "completed_at": "2025-08-19T19:33:51.189098Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.024931669235229492, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_imputation__detector_imputed_agg_five_minutes_DETECTOR_ID.a9425d1e13", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect DETECTOR_ID\nfrom ANALYTICS_PRD.imputation.imputation__detector_imputed_agg_five_minutes\nwhere DETECTOR_ID is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.174521Z", "completed_at": "2025-08-19T19:33:51.188547Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.191015Z", "completed_at": "2025-08-19T19:33:51.191027Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.027956247329711914, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_imputation__detector_imputed_agg_five_minutes_COUNTY.8c9047e291", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect COUNTY\nfrom ANALYTICS_PRD.imputation.imputation__detector_imputed_agg_five_minutes\nwhere COUNTY is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.194935Z", "completed_at": "2025-08-19T19:33:51.208795Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.214002Z", "completed_at": "2025-08-19T19:33:51.214011Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.023605823516845703, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_imputation__detector_imputed_agg_five_minutes_SAMPLE_TIMESTAMP.bef7636b70", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect SAMPLE_TIMESTAMP\nfrom ANALYTICS_PRD.imputation.imputation__detector_imputed_agg_five_minutes\nwhere SAMPLE_TIMESTAMP is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.200121Z", "completed_at": "2025-08-19T19:33:51.213344Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.214969Z", "completed_at": "2025-08-19T19:33:51.214978Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.022732973098754883, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.dbt_utils_unique_combination_of_columns_imputation__detector_summary_SAMPLE_DATE__DETECTOR_ID.3345fe8e87", "compiled": true, "compiled_code": "\n\n\n\n\n\nwith validation_errors as (\n\n    select\n        SAMPLE_DATE, DETECTOR_ID\n    from ANALYTICS_PRD.imputation.imputation__detector_summary\n    group by SAMPLE_DATE, DETECTOR_ID\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.205046Z", "completed_at": "2025-08-19T19:33:51.215798Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.218004Z", "completed_at": "2025-08-19T19:33:51.218012Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.024159669876098633, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_imputation__detector_summary_DETECTOR_ID.5142929aaa", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect DETECTOR_ID\nfrom ANALYTICS_PRD.imputation.imputation__detector_summary\nwhere DETECTOR_ID is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.209441Z", "completed_at": "2025-08-19T19:33:51.216305Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.218788Z", "completed_at": "2025-08-19T19:33:51.218795Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.019902706146240234, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_imputation__detector_summary_SAMPLE_DATE.4bb2a39e43", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect SAMPLE_DATE\nfrom ANALYTICS_PRD.imputation.imputation__detector_summary\nwhere SAMPLE_DATE is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.223916Z", "completed_at": "2025-08-19T19:33:51.242801Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.250835Z", "completed_at": "2025-08-19T19:33:51.250848Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.03136801719665527, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_performance__detector_metrics_agg_hourly", "compiled": true, "compiled_code": "\n\n-- read the volume, occupancy and speed five minutes data\nwith station_five_mins_data as (\n    select\n        *,\n        date_trunc('hour', sample_timestamp) as sample_timestamp_trunc\n    from ANALYTICS_PRD.performance.int_performance__detector_metrics_agg_five_minutes\n    where \n    1=1\n    \n),\n\n-- now aggregate five mins volume, occupancy and speed to hourly\nhourly_spatial_temporal_metrics as (\n    select\n        detector_id,\n        sample_date,\n        sample_timestamp_trunc as sample_hour,\n        any_value(station_id) as station_id,\n        any_value(station_type) as station_type,\n        any_value(lane) as lane,\n        any_value(district) as district,\n        any_value(county) as county,\n        any_value(city) as city,\n        any_value(freeway) as freeway,\n        any_value(direction) as direction,\n        any_value(length) as length,\n        sum(volume_sum) as hourly_volume,\n        avg(occupancy_avg) as hourly_occupancy,\n        sum(volume_sum * speed_five_mins) / nullifzero(sum(volume_sum)) as hourly_speed,\n        sum(vmt) as hourly_vmt,\n        sum(vht) as hourly_vht,\n        hourly_vmt / nullifzero(hourly_vht) as hourly_q_value,\n        -- travel time\n        60 / nullifzero(hourly_q_value) as hourly_tti,\n        \n            sum(delay_35_mph)\n                as delay_35_mph\n            \n                ,\n            \n\n        \n            sum(delay_40_mph)\n                as delay_40_mph\n            \n                ,\n            \n\n        \n            sum(delay_45_mph)\n                as delay_45_mph\n            \n                ,\n            \n\n        \n            sum(delay_50_mph)\n                as delay_50_mph\n            \n                ,\n            \n\n        \n            sum(delay_55_mph)\n                as delay_55_mph\n            \n                ,\n            \n\n        \n            sum(delay_60_mph)\n                as delay_60_mph\n            \n\n        ,\n        \n            sum(lost_productivity_35_mph)\n                as lost_productivity_35_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_40_mph)\n                as lost_productivity_40_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_45_mph)\n                as lost_productivity_45_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_50_mph)\n                as lost_productivity_50_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_55_mph)\n                as lost_productivity_55_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_60_mph)\n                as lost_productivity_60_mph\n            \n\n        \n    from station_five_mins_data\n    group by detector_id, sample_date, sample_hour\n)\n\nselect * from hourly_spatial_temporal_metrics", "relation_name": "ANALYTICS_PRD.performance.int_performance__detector_metrics_agg_hourly", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.229049Z", "completed_at": "2025-08-19T19:33:51.251629Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.253086Z", "completed_at": "2025-08-19T19:33:51.253095Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.033097267150878906, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_performance__station_metrics_agg_five_minutes", "compiled": true, "compiled_code": "\n\nwith detector_agg_five_minutes as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__detector_metrics_agg_five_minutes\n    where \n    1=1\n    \n),\n\nstation_aggregated as (\n    select\n        station_id,\n        sample_date,\n        sample_timestamp,\n        any_value(absolute_postmile) as absolute_postmile,\n        any_value(freeway) as freeway,\n        any_value(direction) as direction,\n        any_value(station_type) as station_type,\n        any_value(district) as district,\n        any_value(county) as county,\n        any_value(city) as city,\n        any_value(length) as length,\n        any_value(station_valid_from) as station_valid_from,\n        any_value(station_valid_to) as station_valid_to,\n        round(sum(vmt), 1) as vmt,\n        round(sum(vht), 2) as vht,\n        sum(sample_ct) as sample_ct,\n        round(sum(volume_sum), 0) as volume_sum,\n        round(avg(occupancy_avg), 4) as occupancy_avg,\n        round(sum(volume_sum * speed_five_mins) / nullifzero(sum(volume_sum)), 1) as speed_five_mins,\n        \n            round(sum(lost_productivity_35_mph), 2) as lost_productivity_35_mph\n            \n                ,\n            \n        \n            round(sum(lost_productivity_40_mph), 2) as lost_productivity_40_mph\n            \n                ,\n            \n        \n            round(sum(lost_productivity_45_mph), 2) as lost_productivity_45_mph\n            \n                ,\n            \n        \n            round(sum(lost_productivity_50_mph), 2) as lost_productivity_50_mph\n            \n                ,\n            \n        \n            round(sum(lost_productivity_55_mph), 2) as lost_productivity_55_mph\n            \n                ,\n            \n        \n            round(sum(lost_productivity_60_mph), 2) as lost_productivity_60_mph\n            \n        \n    from detector_agg_five_minutes\n    group by station_id, sample_date, sample_timestamp\n),\n\nstation_aggregated_with_delay as (\n    select\n        *,\n        \n            round(greatest(volume_sum * ((length / nullifzero(speed_five_mins)) - (length / 35)), 0), 2)\n                as delay_35_mph\n            \n                ,\n            \n        \n            round(greatest(volume_sum * ((length / nullifzero(speed_five_mins)) - (length / 40)), 0), 2)\n                as delay_40_mph\n            \n                ,\n            \n        \n            round(greatest(volume_sum * ((length / nullifzero(speed_five_mins)) - (length / 45)), 0), 2)\n                as delay_45_mph\n            \n                ,\n            \n        \n            round(greatest(volume_sum * ((length / nullifzero(speed_five_mins)) - (length / 50)), 0), 2)\n                as delay_50_mph\n            \n                ,\n            \n        \n            round(greatest(volume_sum * ((length / nullifzero(speed_five_mins)) - (length / 55)), 0), 2)\n                as delay_55_mph\n            \n                ,\n            \n        \n            round(greatest(volume_sum * ((length / nullifzero(speed_five_mins)) - (length / 60)), 0), 2)\n                as delay_60_mph\n            \n        \n    from station_aggregated\n)\n\nselect * from station_aggregated_with_delay", "relation_name": "ANALYTICS_PRD.performance.int_performance__station_metrics_agg_five_minutes", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.243508Z", "completed_at": "2025-08-19T19:33:51.253882Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.256083Z", "completed_at": "2025-08-19T19:33:51.256091Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.032767295837402344, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.quality__row_count_summary", "compiled": true, "compiled_code": "\nwith\n\nML_HV_DETECTOR_STATUS_DAILY_COUNT as (\n    /*\n    * This CTE returns the number of total rows created daily in\n    * the int_diagnostics__detector_status model. This count should be\n    * to checked against the daily detector counts for the following models:\n    * - int_clearinghouse__detector_agg_five_minutes_with_missing_rows\n    * - int_imputation__detector_imputed_agg_five_minutes\n    * - int_performance__detector_metrics_agg_five_minutes\n    * The daily detector counts for these models should match for\n    */\n    select\n        SAMPLE_DATE,\n        count(*) as ML_HV_DETECTOR_STATUS_TOTAL_COUNT\n    from ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status\n    where STATION_TYPE = 'ML' or STATION_TYPE = 'HV'\n    group by SAMPLE_DATE\n),\n\n-- Clearinghouse Detector Count per Day\nML_HV_CLEARINGHOUSE_DETECTOR_DAILY_COUNT as (\n    select\n        SAMPLE_DATE,\n        count(distinct DETECTOR_ID) as ML_HV_CLEARINGHOUSE_DETECTOR_COUNT\n    from ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes_with_missing_rows\n    where STATION_TYPE = 'ML' or STATION_TYPE = 'HV'\n    group by SAMPLE_DATE\n),\n\n-- Imputation Detector Count per Day\nML_HV_IMPUTATION_DETECTOR_DAILY_COUNT as (\n    select\n        SAMPLE_DATE,\n        count(distinct DETECTOR_ID) as ML_HV_IMPUTATION_DETECTOR_COUNT\n    from ANALYTICS_PRD.imputation.int_imputation__detector_imputed_agg_five_minutes\n    group by SAMPLE_DATE\n),\n\n-- Performance Detector Count per Day\nML_HV_PERFORMANCE_DETECTOR_DAILY_COUNT as (\n    select\n        SAMPLE_DATE,\n        count(distinct DETECTOR_ID) as ML_HV_PERFORMANCE_DETECTOR_COUNT\n    from ANALYTICS_PRD.performance.int_performance__detector_metrics_agg_five_minutes\n    group by SAMPLE_DATE\n),\n\n-- Returns count for all station types per Day\nDETECTOR_STATUS_COUNT as (\n    select\n        SAMPLE_DATE,\n        count_if(STATUS = 'Good') as GOOD_STATUS_COUNT,\n        count_if(STATUS != 'Good') as BAD_STATUS_COUNT,\n        count(*) as ALL_DETECTOR_STATUS_TOTAL_COUNT\n    from ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status\n    group by SAMPLE_DATE\n),\n\nDAILY_DETECTOR_COUNT_CHECK as (\n    select\n        MHDSDC.*,\n        CDDC.ML_HV_CLEARINGHOUSE_DETECTOR_COUNT,\n        IDDC.ML_HV_IMPUTATION_DETECTOR_COUNT,\n        PDDC.ML_HV_PERFORMANCE_DETECTOR_COUNT,\n        DSC.GOOD_STATUS_COUNT,\n        DSC.BAD_STATUS_COUNT,\n        DSC.ALL_DETECTOR_STATUS_TOTAL_COUNT\n    from ML_HV_DETECTOR_STATUS_DAILY_COUNT as MHDSDC\n    left join ML_HV_CLEARINGHOUSE_DETECTOR_DAILY_COUNT as CDDC\n        on MHDSDC.SAMPLE_DATE = CDDC.SAMPLE_DATE\n    left join ML_HV_IMPUTATION_DETECTOR_DAILY_COUNT as IDDC\n        on MHDSDC.SAMPLE_DATE = IDDC.SAMPLE_DATE\n    left join ML_HV_PERFORMANCE_DETECTOR_DAILY_COUNT as PDDC\n        on MHDSDC.SAMPLE_DATE = PDDC.SAMPLE_DATE\n    left join DETECTOR_STATUS_COUNT as DSC\n        on MHDSDC.SAMPLE_DATE = DSC.SAMPLE_DATE\n)\n\nselect * from DAILY_DETECTOR_COUNT_CHECK", "relation_name": "ANALYTICS_PRD.quality.quality__row_count_summary", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.237708Z", "completed_at": "2025-08-19T19:33:51.254466Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.256925Z", "completed_at": "2025-08-19T19:33:51.256937Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.03413987159729004, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_performance__station_metrics_agg_hourly", "compiled": true, "compiled_code": "\n-- read the volume, occupancy and speed five minutes data\nwith station_five_mins_data as (\n    select\n        *,\n        date_trunc('hour', sample_timestamp) as sample_timestamp_trunc\n    from ANALYTICS_PRD.performance.int_performance__detector_metrics_agg_five_minutes\n    where \n    1=1\n    \n),\n\n-- now aggregate five mins volume, occupancy and speed to hourly\nhourly_station_temporal_metrics as (\n    select\n        station_id,\n        sample_date,\n        sample_timestamp_trunc as sample_hour,\n        any_value(station_type) as station_type,\n        any_value(district) as district,\n        any_value(county) as county,\n        any_value(city) as city,\n        any_value(freeway) as freeway,\n        any_value(direction) as direction,\n        any_value(length) as length,\n        sum(volume_sum) as hourly_volume,\n        avg(occupancy_avg) as hourly_occupancy,\n        sum(volume_sum * speed_five_mins) / nullifzero(sum(volume_sum)) as hourly_speed,\n        sum(vmt) as hourly_vmt,\n        sum(vht) as hourly_vht,\n        hourly_vmt / nullifzero(hourly_vht) as hourly_q_value,\n        -- travel time\n        60 / nullifzero(hourly_q_value) as hourly_tti,\n        \n            greatest(\n                hourly_volume * ((any_value(length) / nullifzero(hourly_speed)) - (any_value(length) / 35)), 0\n            )\n                as delay_35_mph\n            \n                ,\n            \n        \n            greatest(\n                hourly_volume * ((any_value(length) / nullifzero(hourly_speed)) - (any_value(length) / 40)), 0\n            )\n                as delay_40_mph\n            \n                ,\n            \n        \n            greatest(\n                hourly_volume * ((any_value(length) / nullifzero(hourly_speed)) - (any_value(length) / 45)), 0\n            )\n                as delay_45_mph\n            \n                ,\n            \n        \n            greatest(\n                hourly_volume * ((any_value(length) / nullifzero(hourly_speed)) - (any_value(length) / 50)), 0\n            )\n                as delay_50_mph\n            \n                ,\n            \n        \n            greatest(\n                hourly_volume * ((any_value(length) / nullifzero(hourly_speed)) - (any_value(length) / 55)), 0\n            )\n                as delay_55_mph\n            \n                ,\n            \n        \n            greatest(\n                hourly_volume * ((any_value(length) / nullifzero(hourly_speed)) - (any_value(length) / 60)), 0\n            )\n                as delay_60_mph\n            \n        ,\n        \n            sum(lost_productivity_35_mph)\n                as lost_productivity_35_mph\n            \n                ,\n            \n        \n            sum(lost_productivity_40_mph)\n                as lost_productivity_40_mph\n            \n                ,\n            \n        \n            sum(lost_productivity_45_mph)\n                as lost_productivity_45_mph\n            \n                ,\n            \n        \n            sum(lost_productivity_50_mph)\n                as lost_productivity_50_mph\n            \n                ,\n            \n        \n            sum(lost_productivity_55_mph)\n                as lost_productivity_55_mph\n            \n                ,\n            \n        \n            sum(lost_productivity_60_mph)\n                as lost_productivity_60_mph\n            \n        \n    from station_five_mins_data\n    group by station_id, sample_date, sample_hour\n)\n\nselect * from hourly_station_temporal_metrics", "relation_name": "ANALYTICS_PRD.performance.int_performance__station_metrics_agg_hourly", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.265945Z", "completed_at": "2025-08-19T19:33:51.275598Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.280934Z", "completed_at": "2025-08-19T19:33:51.280944Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.02278900146484375, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_performance__detector_metrics_agg_five_minutes_sample_date.731be9516c", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect sample_date\nfrom ANALYTICS_PRD.performance.int_performance__detector_metrics_agg_five_minutes\nwhere sample_date is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.259940Z", "completed_at": "2025-08-19T19:33:51.280188Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.282516Z", "completed_at": "2025-08-19T19:33:51.282527Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.027625560760498047, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_performance__detector_metrics_agg_five_minutes_detector_id.b69f9c6ce1", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect detector_id\nfrom ANALYTICS_PRD.performance.int_performance__detector_metrics_agg_five_minutes\nwhere detector_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.271471Z", "completed_at": "2025-08-19T19:33:51.281909Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.284335Z", "completed_at": "2025-08-19T19:33:51.284343Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.01972508430480957, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_performance__detector_metrics_agg_five_minutes_sample_timestamp.cc991dd3f8", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect sample_timestamp\nfrom ANALYTICS_PRD.performance.int_performance__detector_metrics_agg_five_minutes\nwhere sample_timestamp is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.276248Z", "completed_at": "2025-08-19T19:33:51.283241Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.285677Z", "completed_at": "2025-08-19T19:33:51.285685Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.020438194274902344, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_performance__detector_metrics_agg_five_minutes_station_id.4c5c10799a", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect station_id\nfrom ANALYTICS_PRD.performance.int_performance__detector_metrics_agg_five_minutes\nwhere station_id is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.290694Z", "completed_at": "2025-08-19T19:33:51.314807Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.315763Z", "completed_at": "2025-08-19T19:33:51.315774Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.029376983642578125, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_performance__detector_metrics_agg_daily", "compiled": true, "compiled_code": "\n\n-- read the station hourly data\nwith station_hourly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__detector_metrics_agg_hourly\n    where \n    1=1\n    \n),\n\n-- now aggregate hourly volume, occupancy and speed to daily level\ndaily_spatial_temporal_agg as (\n    select\n        detector_id,\n        sample_date,\n        any_value(station_id) as station_id,\n        any_value(station_type) as station_type,\n        any_value(lane) as lane,\n        any_value(district) as district,\n        any_value(county) as county,\n        any_value(city) as city,\n        any_value(freeway) as freeway,\n        any_value(direction) as direction,\n        sum(hourly_volume) as daily_volume,\n        avg(hourly_occupancy) as daily_occupancy,\n        sum(hourly_volume * hourly_speed) / nullifzero(sum(hourly_volume)) as daily_speed,\n        sum(hourly_vmt) as daily_vmt,\n        sum(hourly_vht) as daily_vht,\n        daily_vmt / nullifzero(daily_vht) as daily_q_value,\n        -- travel time\n        60 / nullifzero(daily_q_value) as daily_tti,\n        \n            sum(delay_35_mph)\n                as delay_35_mph\n            \n                ,\n            \n\n        \n            sum(delay_40_mph)\n                as delay_40_mph\n            \n                ,\n            \n\n        \n            sum(delay_45_mph)\n                as delay_45_mph\n            \n                ,\n            \n\n        \n            sum(delay_50_mph)\n                as delay_50_mph\n            \n                ,\n            \n\n        \n            sum(delay_55_mph)\n                as delay_55_mph\n            \n                ,\n            \n\n        \n            sum(delay_60_mph)\n                as delay_60_mph\n            \n\n        ,\n        \n            sum(lost_productivity_35_mph)\n                as lost_productivity_35_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_40_mph)\n                as lost_productivity_40_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_45_mph)\n                as lost_productivity_45_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_50_mph)\n                as lost_productivity_50_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_55_mph)\n                as lost_productivity_55_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_60_mph)\n                as lost_productivity_60_mph\n            \n\n        \n    from station_hourly_data\n    group by detector_id, sample_date\n)\n\nselect * from daily_spatial_temporal_agg", "relation_name": "ANALYTICS_PRD.performance.int_performance__detector_metrics_agg_daily", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.297240Z", "completed_at": "2025-08-19T19:33:51.322834Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.323378Z", "completed_at": "2025-08-19T19:33:51.323389Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.03592395782470703, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_performance__bottleneck_delay_metrics_agg_five_minutes", "compiled": true, "compiled_code": "\n\nwith\n\nstation_five_minute as (\n    select\n        station_id,\n        sample_date,\n        sample_timestamp,\n        nullifzero(speed_five_mins) as speed_five_mins,\n        district,\n        county,\n        freeway,\n        freeway in (71, 153, 282, 580, 780) as is_backward_routes,\n        direction,\n        station_type,\n        absolute_postmile,\n        length,\n        volume_sum,\n        delay_35_mph,\n        delay_40_mph,\n        delay_45_mph,\n        delay_50_mph,\n        delay_55_mph,\n        delay_60_mph\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_five_minutes\n    where\n        \n    1=1\n    \n        and station_type in ('ML', 'HV')\n),\n\ncalcs as (\n    select\n        *,\n\n        /*Absolute postmile increases going north and east. When the direction of the freeway for a\n        station is north or east, the \"upstream\" station has a smaller postmile, and we need to lag\n        to get the speed there. When the direction is west or south, the \"upstream\" station has a\n        larger postmile, and we need to lead to get the speed there. */\n        /*There are five routes (NS: Route 71; EW: Route 153, 282, 580, 780) in California which do not\n        follow this rule. We need to specify them in the speed difference and distance difference\n        calculation*/\n        /*Need to check all calculations ordered by absolute_postmile and fix the logic for 5 routes\n        specifically*/\n        case\n            when\n                is_backward_routes\n                then speed_five_mins - lead(speed_five_mins)\n                    over (\n                        partition by sample_timestamp, freeway, direction, station_type order by absolute_postmile desc\n                    )\n            else speed_five_mins - lead(speed_five_mins)\n                over (partition by sample_timestamp, freeway, direction, station_type order by absolute_postmile asc)\n        end as speed_delta_ne,\n\n        case\n            when\n                is_backward_routes\n                then absolute_postmile - lead(absolute_postmile)\n                    over (\n                        partition by sample_timestamp, freeway, direction, station_type order by absolute_postmile desc\n                    )\n            else absolute_postmile - lead(absolute_postmile)\n                over (partition by sample_timestamp, freeway, direction, station_type order by absolute_postmile asc)\n        end as distance_delta_ne,\n\n        case\n            when\n                is_backward_routes\n                then speed_five_mins - lag(speed_five_mins)\n                    over (\n                        partition by sample_timestamp, freeway, direction, station_type order by absolute_postmile desc\n                    )\n            else speed_five_mins - lag(speed_five_mins)\n                over (partition by sample_timestamp, freeway, direction, station_type order by absolute_postmile asc)\n        end as speed_delta_sw,\n\n        case\n            when\n                is_backward_routes\n                then absolute_postmile - lag(absolute_postmile)\n                    over (\n                        partition by sample_timestamp, freeway, direction, station_type order by absolute_postmile desc\n                    )\n            else absolute_postmile - lag(absolute_postmile)\n                over (partition by sample_timestamp, freeway, direction, station_type order by absolute_postmile asc)\n        end as distance_delta_sw\n\n    from station_five_minute\n),\n\nbottleneck_criteria as (\n    select\n        *,\n        case\n            when\n                speed_five_mins < 40\n                and abs(distance_delta_ne) < 3\n                and speed_delta_ne <= -20\n                and (direction = 'N' or direction = 'E')\n                then 1\n            when\n                speed_five_mins < 40\n                and abs(distance_delta_sw) < 3\n                and speed_delta_sw <= -20\n                and (direction = 'S' or direction = 'W')\n                then 1\n            else 0\n        end as bottleneck_check\n\n    from calcs\n),\n\ntemporal_extent_check as (\n    select\n        *,\n        sum(bottleneck_check) over (\n            partition by station_id, sample_date\n            order by sample_timestamp asc rows between current row and 6 following\n        ) as bottleneck_check_summed\n    from bottleneck_criteria\n),\n\ntemporal_extent as (\n    select\n        * exclude (bottleneck_check, bottleneck_check_summed),\n        iff(bottleneck_check = 1 and bottleneck_check_summed >= 5, true, false) as is_bottleneck\n    from temporal_extent_check\n),\n\ncongestion as (\n    select\n        *,\n        speed_five_mins < 40 as is_congested,\n\n        /* Create a helper length field which is zero if we don't consider this station\n        congested and the station length if we do. This will be summed later to get\n        the congestion extent */\n        iff(is_congested, length, 0) as congestion_length,\n\n        /* Absolute postmile increases going north and east. When the direction of the freeway for a\n        station is north or east, the \"upstream\" station has a smaller postmile, and we need to lag\n        to get the speed there. When the direction is west or south, the \"upstream\" station has a\n        larger postmile, and we need to lead to get the speed there. */\n        /*There are five routes (NS: Route 71; EW: Route 282, 580, 780) in California which do not\n        follow this rule. We need to specify them in the speed difference and distance difference\n        calculation*/\n        case\n            when (is_backward_routes and direction in ('N', 'E'))\n                then\n                    lag(is_congested)\n                        over (\n                            partition by sample_timestamp, freeway, direction, station_type\n                            order by absolute_postmile desc\n                        )\n            when (direction in ('N', 'E') and is_backward_routes = false)\n                then\n                    lag(is_congested)\n                        over (\n                            partition by sample_timestamp, freeway, direction, station_type\n                            order by absolute_postmile asc\n                        )\n            when (is_backward_routes and direction in ('S', 'W'))\n                then\n                    lead(is_congested)\n                        over (\n                            partition by sample_timestamp, freeway, direction, station_type\n                            order by absolute_postmile desc\n                        )\n            when (direction in ('S', 'W') and is_backward_routes = false)\n                then\n                    lead(is_congested)\n                        over (\n                            partition by sample_timestamp, freeway, direction, station_type\n                            order by absolute_postmile asc\n                        )\n        end as upstream_is_congested,\n        iff(is_congested = upstream_is_congested, 0, 1) as congestion_status_change\n    from temporal_extent\n),\n\ncongestion_events as (\n    select\n        *,\n        case\n            when is_backward_routes\n                then\n                    sum(congestion_status_change)\n                        over (\n                            partition by sample_timestamp, freeway, direction, station_type\n                            order by absolute_postmile desc\n                            rows between unbounded preceding and current row\n                        )\n            else\n                sum(congestion_status_change)\n                    over (\n                        partition by sample_timestamp, freeway, direction, station_type\n                        order by absolute_postmile asc\n                        rows between unbounded preceding and current row\n                    )\n        end as congestion_sequence\n    from congestion\n),\n\ncongestion_length as (\n    select\n        *,\n        case\n            when\n                (direction in ('N', 'E') and is_backward_routes = false)\n                or (direction in ('S', 'W') and is_backward_routes)\n                then\n                    sum(congestion_length) over (\n                        partition by sample_timestamp, freeway, direction, station_type, congestion_sequence\n                        order by absolute_postmile asc\n                        rows between unbounded preceding and current row\n                    )\n            when\n                (direction in ('S', 'W') and is_backward_routes = false)\n                or (direction in ('N', 'E') and is_backward_routes)\n                then\n                    sum(congestion_length) over (\n                        partition by sample_timestamp, freeway, direction, station_type, congestion_sequence\n                        order by absolute_postmile asc\n                        rows between current row and unbounded following\n                    )\n        end as bottleneck_extent\n    from congestion_events\n    qualify is_bottleneck = true -- TODO: also filter if upstream is a bottleneck start?\n\n),\n\nagg_spatial_delay as (\n    select\n        *,\n        \n            case\n                when\n                    (direction in ('N', 'E') and is_backward_routes = false)\n                    or (direction in ('S', 'W') and is_backward_routes)\n                    then\n                        sum(delay_35_mph) over (\n                            partition by sample_timestamp, freeway, direction, station_type, congestion_sequence\n                            order by absolute_postmile asc\n                            rows between unbounded preceding and current row\n                        )\n                when\n                    (direction in ('S', 'W') and is_backward_routes = false)\n                    or (direction in ('N', 'E') and is_backward_routes)\n                    then\n                        sum(delay_35_mph) over (\n                            partition by sample_timestamp, freeway, direction, station_type, congestion_sequence\n                            order by absolute_postmile asc\n                            rows between current row and unbounded following\n                        )\n            end as spatial_delay_35_mph\n            \n                ,\n            \n\n        \n            case\n                when\n                    (direction in ('N', 'E') and is_backward_routes = false)\n                    or (direction in ('S', 'W') and is_backward_routes)\n                    then\n                        sum(delay_40_mph) over (\n                            partition by sample_timestamp, freeway, direction, station_type, congestion_sequence\n                            order by absolute_postmile asc\n                            rows between unbounded preceding and current row\n                        )\n                when\n                    (direction in ('S', 'W') and is_backward_routes = false)\n                    or (direction in ('N', 'E') and is_backward_routes)\n                    then\n                        sum(delay_40_mph) over (\n                            partition by sample_timestamp, freeway, direction, station_type, congestion_sequence\n                            order by absolute_postmile asc\n                            rows between current row and unbounded following\n                        )\n            end as spatial_delay_40_mph\n            \n                ,\n            \n\n        \n            case\n                when\n                    (direction in ('N', 'E') and is_backward_routes = false)\n                    or (direction in ('S', 'W') and is_backward_routes)\n                    then\n                        sum(delay_45_mph) over (\n                            partition by sample_timestamp, freeway, direction, station_type, congestion_sequence\n                            order by absolute_postmile asc\n                            rows between unbounded preceding and current row\n                        )\n                when\n                    (direction in ('S', 'W') and is_backward_routes = false)\n                    or (direction in ('N', 'E') and is_backward_routes)\n                    then\n                        sum(delay_45_mph) over (\n                            partition by sample_timestamp, freeway, direction, station_type, congestion_sequence\n                            order by absolute_postmile asc\n                            rows between current row and unbounded following\n                        )\n            end as spatial_delay_45_mph\n            \n                ,\n            \n\n        \n            case\n                when\n                    (direction in ('N', 'E') and is_backward_routes = false)\n                    or (direction in ('S', 'W') and is_backward_routes)\n                    then\n                        sum(delay_50_mph) over (\n                            partition by sample_timestamp, freeway, direction, station_type, congestion_sequence\n                            order by absolute_postmile asc\n                            rows between unbounded preceding and current row\n                        )\n                when\n                    (direction in ('S', 'W') and is_backward_routes = false)\n                    or (direction in ('N', 'E') and is_backward_routes)\n                    then\n                        sum(delay_50_mph) over (\n                            partition by sample_timestamp, freeway, direction, station_type, congestion_sequence\n                            order by absolute_postmile asc\n                            rows between current row and unbounded following\n                        )\n            end as spatial_delay_50_mph\n            \n                ,\n            \n\n        \n            case\n                when\n                    (direction in ('N', 'E') and is_backward_routes = false)\n                    or (direction in ('S', 'W') and is_backward_routes)\n                    then\n                        sum(delay_55_mph) over (\n                            partition by sample_timestamp, freeway, direction, station_type, congestion_sequence\n                            order by absolute_postmile asc\n                            rows between unbounded preceding and current row\n                        )\n                when\n                    (direction in ('S', 'W') and is_backward_routes = false)\n                    or (direction in ('N', 'E') and is_backward_routes)\n                    then\n                        sum(delay_55_mph) over (\n                            partition by sample_timestamp, freeway, direction, station_type, congestion_sequence\n                            order by absolute_postmile asc\n                            rows between current row and unbounded following\n                        )\n            end as spatial_delay_55_mph\n            \n                ,\n            \n\n        \n            case\n                when\n                    (direction in ('N', 'E') and is_backward_routes = false)\n                    or (direction in ('S', 'W') and is_backward_routes)\n                    then\n                        sum(delay_60_mph) over (\n                            partition by sample_timestamp, freeway, direction, station_type, congestion_sequence\n                            order by absolute_postmile asc\n                            rows between unbounded preceding and current row\n                        )\n                when\n                    (direction in ('S', 'W') and is_backward_routes = false)\n                    or (direction in ('N', 'E') and is_backward_routes)\n                    then\n                        sum(delay_60_mph) over (\n                            partition by sample_timestamp, freeway, direction, station_type, congestion_sequence\n                            order by absolute_postmile asc\n                            rows between current row and unbounded following\n                        )\n            end as spatial_delay_60_mph\n            \n\n        \n    from congestion_length\n),\n\nshift as (\n    select\n        *,\n        case\n            when\n                cast(sample_timestamp as time) >= '05:00:00'\n                and cast(sample_timestamp as time) <= '09:59:59'\n                then 'AM'\n            when\n                cast(sample_timestamp as time) >= '10:00:00'\n                and cast(sample_timestamp as time) <= '14:59:59'\n                then 'NOON'\n            when\n                cast(sample_timestamp as time) >= '15:00:00'\n                and cast(sample_timestamp as time) <= '20:00:00'\n                then 'PM'\n        end as time_shift\n    from agg_spatial_delay\n),\n\nbottleneck_delay as (\n    select\n        * exclude (\n            congestion_sequence,\n            congestion_status_change,\n            speed_delta_ne,\n            speed_delta_sw,\n            distance_delta_sw,\n            distance_delta_ne,\n            volume_sum,\n            is_backward_routes,\n            length,\n            upstream_is_congested,\n            is_congested,\n            speed_five_mins,\n            congestion_length,\n            delay_35_mph,\n            delay_40_mph,\n            delay_45_mph,\n            delay_50_mph,\n            delay_55_mph,\n            delay_60_mph\n        )\n    from shift\n\n)\n\nselect * from bottleneck_delay", "relation_name": "ANALYTICS_PRD.performance.int_performance__bottleneck_delay_metrics_agg_five_minutes", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.305687Z", "completed_at": "2025-08-19T19:33:51.326995Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.327566Z", "completed_at": "2025-08-19T19:33:51.327573Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.038491249084472656, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.quality__station_row_count_summary", "compiled": true, "compiled_code": "with\n\nML_HV_DETECTOR_STATUS_DAILY_COUNT as (\n    /*\n    * This CTE returns the number of total rows by station created daily in\n    * the int_diagnostics__detector_status model. This count should be\n    * to checked against the daily station counts for the following models:\n    * - int_clearinghouse__detector_agg_five_minutes_with_missing_rows\n    * - int_imputation__detector_imputed_agg_five_minutes\n    * - int_performance__station_metrics_agg_five_minutes\n    * The daily station counts for these models should match for HV and ML\n    * station types\n    */\n    select\n        SAMPLE_DATE,\n        count(distinct STATION_ID) as ML_HV_DETECTOR_STATUS_STATION_COUNT\n    from ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status\n    where\n        STATION_TYPE in ('ML', 'HV')\n        and SAMPLE_DATE >= current_date - 16\n    group by SAMPLE_DATE\n),\n\n-- Clearinghouse Station Count per Day\nML_HV_CLEARINGHOUSE_STATION_DAILY_COUNT as (\n    select\n        SAMPLE_DATE,\n        count(distinct STATION_ID) as ML_HV_CLEARINGHOUSE_STATION_COUNT\n    from ANALYTICS_PRD.clearinghouse.int_clearinghouse__detector_agg_five_minutes_with_missing_rows\n    where\n        STATION_TYPE in ('ML', 'HV')\n        and SAMPLE_DATE >= current_date - 16\n    group by SAMPLE_DATE\n),\n\n-- Imputation Station Count per Day\nML_HV_IMPUTATION_STATION_DAILY_COUNT as (\n    select\n        SAMPLE_DATE,\n        count(distinct STATION_ID) as ML_HV_IMPUTATION_STATION_COUNT\n    from ANALYTICS_PRD.imputation.int_imputation__detector_imputed_agg_five_minutes\n    where\n        STATION_TYPE in ('ML', 'HV')\n        and SAMPLE_DATE >= current_date - 16\n    group by SAMPLE_DATE\n),\n\n-- Performance Station Count per Day\nML_HV_PERFORMANCE_STATION_DAILY_COUNT as (\n    select\n        SAMPLE_DATE,\n        count(distinct STATION_ID) as ML_HV_PERFORMANCE_STATION_COUNT\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_five_minutes\n    where\n        STATION_TYPE in ('ML', 'HV')\n        and SAMPLE_DATE >= current_date - 16\n    group by SAMPLE_DATE\n),\n\nDAILY_STATION_COUNT_CHECK as (\n    select\n        MHDSDC.*,\n        CSDC.ML_HV_CLEARINGHOUSE_STATION_COUNT,\n        ISDC.ML_HV_IMPUTATION_STATION_COUNT,\n        PSDC.ML_HV_PERFORMANCE_STATION_COUNT\n    from ML_HV_DETECTOR_STATUS_DAILY_COUNT as MHDSDC\n    left join ML_HV_CLEARINGHOUSE_STATION_DAILY_COUNT as CSDC\n        on MHDSDC.SAMPLE_DATE = CSDC.SAMPLE_DATE\n    left join ML_HV_IMPUTATION_STATION_DAILY_COUNT as ISDC\n        on MHDSDC.SAMPLE_DATE = ISDC.SAMPLE_DATE\n    left join ML_HV_PERFORMANCE_STATION_DAILY_COUNT as PSDC\n        on MHDSDC.SAMPLE_DATE = PSDC.SAMPLE_DATE\n)\n\nselect * from DAILY_STATION_COUNT_CHECK", "relation_name": "ANALYTICS_PRD.quality.quality__station_row_count_summary", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.309687Z", "completed_at": "2025-08-19T19:33:51.328950Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.330517Z", "completed_at": "2025-08-19T19:33:51.330525Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.04043889045715332, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_performance__station_metrics_agg_daily", "compiled": true, "compiled_code": "\n\n-- read the volume, occupancy and speed hourly data\nwith station_hourly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_hourly\n),\n\n-- now aggregate hourly volume, occupancy and speed to daily level\ndaily_station_level_spatial_temporal_agg as (\n    select\n        station_id,\n        sample_date,\n        length,\n        any_value(station_type) as station_type,\n        any_value(district) as district,\n        any_value(county) as county,\n        any_value(city) as city,\n        any_value(freeway) as freeway,\n        any_value(direction) as direction,\n        sum(hourly_volume) as daily_volume,\n        avg(hourly_occupancy) as daily_occupancy,\n        sum(hourly_volume * hourly_speed) / nullifzero(sum(hourly_volume)) as daily_speed,\n        sum(hourly_vmt) as daily_vmt,\n        sum(hourly_vht) as daily_vht,\n        daily_vmt / nullifzero(daily_vht) as daily_q_value,\n        -- travel time\n        60 / nullifzero(daily_q_value) as daily_tti,\n        \n            greatest(\n                daily_volume * ((length / nullifzero(daily_speed)) - (length / 35)), 0\n            )\n                as delay_35_mph\n            \n                ,\n            \n\n        \n            greatest(\n                daily_volume * ((length / nullifzero(daily_speed)) - (length / 40)), 0\n            )\n                as delay_40_mph\n            \n                ,\n            \n\n        \n            greatest(\n                daily_volume * ((length / nullifzero(daily_speed)) - (length / 45)), 0\n            )\n                as delay_45_mph\n            \n                ,\n            \n\n        \n            greatest(\n                daily_volume * ((length / nullifzero(daily_speed)) - (length / 50)), 0\n            )\n                as delay_50_mph\n            \n                ,\n            \n\n        \n            greatest(\n                daily_volume * ((length / nullifzero(daily_speed)) - (length / 55)), 0\n            )\n                as delay_55_mph\n            \n                ,\n            \n\n        \n            greatest(\n                daily_volume * ((length / nullifzero(daily_speed)) - (length / 60)), 0\n            )\n                as delay_60_mph\n            \n\n        ,\n        \n            sum(lost_productivity_35_mph)\n                as lost_productivity_35_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_40_mph)\n                as lost_productivity_40_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_45_mph)\n                as lost_productivity_45_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_50_mph)\n                as lost_productivity_50_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_55_mph)\n                as lost_productivity_55_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_60_mph)\n                as lost_productivity_60_mph\n            \n\n        \n    from station_hourly_data\n    group by station_id, sample_date, length\n)\n\nselect * from daily_station_level_spatial_temporal_agg", "relation_name": "ANALYTICS_PRD.performance.int_performance__station_metrics_agg_daily", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.318237Z", "completed_at": "2025-08-19T19:33:51.331820Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.338534Z", "completed_at": "2025-08-19T19:33:51.338548Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.021567344665527344, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_agg_recent_one_week", "compiled": true, "compiled_code": "with station_meta as (\n    select * from ANALYTICS_PRD.vds.int_vds__active_stations\n    where active_date >= dateadd('day', -8, current_date())\n),\n\nstation_county as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            station_meta.*,\n            c.county_name,\n            c.county_abb\n        from station_meta\n        inner join county as c\n        on station_meta.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\nstation_pairs as (\n    select\n        ml.station_id as ml_station_id,\n        ml.district,\n        ml.city,\n        ml.county,\n        ml.freeway,\n        ml.direction,\n        ml.absolute_postmile as ml_absolute_postmile,\n        ml.physical_lanes as ml_lanes,\n        ml.active_date,\n        hov.station_id as hov_station_id,\n        hov.name as hov_name,\n        hov.latitude as hov_latitude,\n        hov.longitude as hov_longitude,\n        hov.absolute_postmile as hov_absolute_postmile,\n        hov.length as hov_length,\n        hov.physical_lanes as hov_lanes,\n        abs(ml.absolute_postmile - hov.absolute_postmile) as delta_postmile\n    from\n        station_county as ml\n    inner join\n        station_county as hov\n        on\n            ml.freeway = hov.freeway\n            and ml.direction = hov.direction\n            and ml.active_date = hov.active_date\n            and ml.station_id != hov.station_id\n            and ml.station_type = 'ML'\n            and hov.station_type = 'HV'\n            and ml.district != 4\n            and hov.district != 4\n),\n\nclosest_station_with_selection as (\n    select\n        *,\n        row_number() over (partition by ml_station_id, active_date order by delta_postmile asc) as distance_ranking\n    from station_pairs\n    where\n        delta_postmile <= 5\n    qualify\n        distance_ranking = 1\n),\n\nhourly_station_volume as (\n    select\n        station_id,\n        direction,\n        sample_date,\n        sample_hour,\n        hourly_volume,\n        hourly_vmt,\n        hourly_vht,\n        station_type\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_hourly\n    where sample_date >= dateadd('day', -8, current_date())\n),\n\n/*\n * Join station metadata pairs with hourly observations. This could be\n * expressed more naturally with 2 joins, 1 for ML stations and 1 for HOV,\n * but doing so incurs a significant performance cost. Instead, we have a\n * more permissive join and an aggregation.\n */\nstation_with_ml_hov_metrics as (\n    select\n        css.*,\n        hourly.sample_date,\n        hourly.sample_hour,\n        max(case when hourly.station_type = 'ML' then hourly.hourly_volume end) as ml_hourly_volume,\n        max(case when hourly.station_type = 'ML' then hourly.hourly_vmt end) as ml_hourly_vmt,\n        max(case when hourly.station_type = 'ML' then hourly.hourly_vht end) as ml_hourly_vht,\n        max(case when hourly.station_type = 'HV' then hourly.hourly_volume end) as hov_hourly_volume,\n        max(case when hourly.station_type = 'HV' then hourly.hourly_vmt end) as hov_hourly_vmt,\n        max(case when hourly.station_type = 'HV' then hourly.hourly_vht end) as hov_hourly_vht\n    from closest_station_with_selection as css\n    inner join hourly_station_volume as hourly\n        on\n            (css.ml_station_id = hourly.station_id or css.hov_station_id = hourly.station_id)\n            and css.direction = hourly.direction\n            and css.active_date = hourly.sample_date\n    group by all\n),\n\nstation_metric_agg as (\n    select\n        hov_station_id,\n        hov_name,\n        hov_latitude,\n        hov_longitude,\n        avg(hov_length) as hov_length_avg,\n        max(hov_absolute_postmile) as hov_absolute_postmile,\n        district,\n        city,\n        county,\n        freeway,\n        direction,\n        sample_date,\n        sample_hour,\n        (sum(ml_hourly_volume) / nullif(sum(ml_lanes), 0)) as ml_hourly_average_volume,\n        (sum(ml_hourly_vmt) / nullif(sum(ml_lanes), 0)) as ml_hourly_average_vmt,\n        (sum(ml_hourly_vht) / nullif(sum(ml_lanes), 0)) as ml_hourly_average_vht,\n        (sum(hov_hourly_volume) / nullif(sum(hov_lanes), 0)) as hov_hourly_average_volume,\n        (sum(hov_hourly_vmt) / nullif(sum(hov_lanes), 0)) as hov_hourly_average_vmt,\n        (sum(hov_hourly_vht) / nullif(sum(hov_lanes), 0)) as hov_hourly_average_vht,\n        (sum(hov_hourly_volume) / nullif(sum(ml_hourly_volume), 0)) * 100 as hov_volume_penetration,\n        (sum(hov_hourly_vmt) / nullif(sum(ml_hourly_vmt), 0)) * 100 as hov_vmt_penetration,\n        (sum(hov_hourly_vht) / nullif(sum(ml_hourly_vht), 0)) * 100 as hov_vht_penetration\n    from station_with_ml_hov_metrics\n    group by\n        hov_station_id,\n        hov_name,\n        hov_latitude,\n        hov_longitude,\n        district,\n        city,\n        county,\n        freeway,\n        direction,\n        sample_date,\n        sample_hour\n),\n\nfinal_data_with_category as (\n    select\n        station_metric_agg.*,\n\n        -- Hourly Category (Based on peak/off-peak periods)\n        case\n            -- AM Peak\n            when\n                to_time(station_metric_agg.sample_hour) between to_time('06:00:00') and to_time(\n                    '09:59:59'\n                )\n                then 'am_peak'\n\n            -- Day Off-Peak\n            when\n                to_time(station_metric_agg.sample_hour) between to_time('10:00:00') and to_time(\n                    '14:59:59'\n                )\n                then 'day_off_peak'\n\n            -- PM Peak\n            when\n                to_time(station_metric_agg.sample_hour) between to_time('15:00:00') and to_time(\n                    '18:59:59'\n                )\n                then 'pm_peak'\n\n            -- Night Off-Peak (default)\n            else 'night_off_peak'\n        end as hourly_category,\n\n        -- Weekday/Weekend Category\n        case\n            when dayofweek(station_metric_agg.sample_date) in (1, 2, 3, 4, 5) then 'Weekday'\n            else 'Weekend'\n        end as weekday_status,\n\n        -- Day of the Week Name\n        case\n            when station_metric_agg.sample_date is null then 'No Date'\n            when dayofweek(station_metric_agg.sample_date) = 0 then 'Sunday'\n            when dayofweek(station_metric_agg.sample_date) = 1 then 'Monday'\n            when dayofweek(station_metric_agg.sample_date) = 2 then 'Tuesday'\n            when dayofweek(station_metric_agg.sample_date) = 3 then 'Wednesday'\n            when dayofweek(station_metric_agg.sample_date) = 4 then 'Thursday'\n            when dayofweek(station_metric_agg.sample_date) = 5 then 'Friday'\n            when dayofweek(station_metric_agg.sample_date) = 6 then 'Saturday'\n            else 'Unknown' -- This should not normally happen\n        end as weekday\n    from station_metric_agg\n)\n\nselect\n    *,\n    extract(hour from sample_hour) as hour_day\nfrom final_data_with_category", "relation_name": "ANALYTICS_PRD.performance.performance__station_agg_recent_one_week", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.333428Z", "completed_at": "2025-08-19T19:33:51.347839Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.354357Z", "completed_at": "2025-08-19T19:33:51.354366Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.02497410774230957, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_performance__bottleneck_delay_metrics_agg_hourly", "compiled": true, "compiled_code": "\n\n-- read the volume, occupancy and speed five minutes data\nwith station_five_mins_data as (\n    select\n        *,\n        date_trunc('hour', sample_timestamp) as sample_timestamp_trunc\n    from ANALYTICS_PRD.performance.int_performance__bottleneck_delay_metrics_agg_five_minutes\n    where \n    1=1\n    \n),\n\n-- aggregate five mins delay and calculate the average bottleneck extent in an hourly basis\nhourly_spatial_bottleneck_delay_metrics as (\n    select\n        station_id,\n        sample_date,\n        sample_timestamp_trunc as sample_hour,\n        any_value(district) as district,\n        any_value(county) as county,\n        any_value(station_type) as station_type,\n        any_value(freeway) as freeway,\n        any_value(direction) as direction,\n        any_value(absolute_postmile) as absolute_postmile,\n        any_value(time_shift) as time_shift,\n        sum(case when is_bottleneck = true then 1 else 0 end) * 5 as hourly_duration,\n        avg(bottleneck_extent) as hourly_bottleneck_extent,\n        -- spatial delay aggregation in hourly level\n        \n            sum(spatial_delay_35_mph)\n                as hourly_spatial_delay_35_mph\n            \n                ,\n            \n        \n            sum(spatial_delay_40_mph)\n                as hourly_spatial_delay_40_mph\n            \n                ,\n            \n        \n            sum(spatial_delay_45_mph)\n                as hourly_spatial_delay_45_mph\n            \n                ,\n            \n        \n            sum(spatial_delay_50_mph)\n                as hourly_spatial_delay_50_mph\n            \n                ,\n            \n        \n            sum(spatial_delay_55_mph)\n                as hourly_spatial_delay_55_mph\n            \n                ,\n            \n        \n            sum(spatial_delay_60_mph)\n                as hourly_spatial_delay_60_mph\n            \n        \n    from station_five_mins_data\n    group by station_id, sample_date, sample_hour\n)\n\nselect * from hourly_spatial_bottleneck_delay_metrics", "relation_name": "ANALYTICS_PRD.performance.int_performance__bottleneck_delay_metrics_agg_hourly", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.341424Z", "completed_at": "2025-08-19T19:33:51.355277Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.361634Z", "completed_at": "2025-08-19T19:33:51.361646Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.029442310333251953, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_performance__detector_metrics_agg_monthly", "compiled": true, "compiled_code": "\n\n-- read the volume, occupancy and speed daily level data\nwith station_daily_data as (\n    select\n        *,\n        -- Extracting the first day of each month\n        -- reference: https://docs.snowflake.com/en/sql-reference/functions/year\n        date_trunc(month, sample_date) as sample_month\n    from ANALYTICS_PRD.performance.int_performance__detector_metrics_agg_daily\n    -- # we do not want to aggregate incomplete month data\n    where date_trunc(month, sample_date) != date_trunc(month, current_date)\n),\n\n-- now aggregate daily volume, occupancy and speed to weekly\nmonthly_spatial_temporal_metrics as (\n    select\n        detector_id,\n        sample_month,\n        any_value(station_id) as station_id,\n        any_value(lane) as lane,\n        any_value(city) as city,\n        any_value(county) as county,\n        any_value(district) as district,\n        any_value(station_type) as station_type,\n        any_value(freeway) as freeway,\n        any_value(direction) as direction,\n        sum(daily_volume) as monthly_volume,\n        avg(daily_occupancy) as monthly_occupancy,\n        sum(daily_vmt) as monthly_vmt,\n        sum(daily_vht) as monthly_vht,\n        monthly_vmt / nullifzero(monthly_vht) as monthly_q_value,\n        -- travel time\n        60 / nullifzero(monthly_q_value) as monthly_tti,\n        \n            sum(delay_35_mph)\n                as delay_35_mph\n            \n                ,\n            \n\n        \n            sum(delay_40_mph)\n                as delay_40_mph\n            \n                ,\n            \n\n        \n            sum(delay_45_mph)\n                as delay_45_mph\n            \n                ,\n            \n\n        \n            sum(delay_50_mph)\n                as delay_50_mph\n            \n                ,\n            \n\n        \n            sum(delay_55_mph)\n                as delay_55_mph\n            \n                ,\n            \n\n        \n            sum(delay_60_mph)\n                as delay_60_mph\n            \n\n        ,\n        \n            sum(lost_productivity_35_mph)\n                as lost_productivity_35_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_40_mph)\n                as lost_productivity_40_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_45_mph)\n                as lost_productivity_45_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_50_mph)\n                as lost_productivity_50_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_55_mph)\n                as lost_productivity_55_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_60_mph)\n                as lost_productivity_60_mph\n            \n\n        \n    from station_daily_data\n    group by detector_id, sample_month\n)\n\nselect * from monthly_spatial_temporal_metrics", "relation_name": "ANALYTICS_PRD.performance.int_performance__detector_metrics_agg_monthly", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.348368Z", "completed_at": "2025-08-19T19:33:51.362639Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.364919Z", "completed_at": "2025-08-19T19:33:51.364931Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.024797677993774414, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_performance__detector_metrics_agg_weekly", "compiled": true, "compiled_code": "\n\n-- read the volume, occupancy and speed daily level data\nwith station_daily_data as (\n    select\n        *,\n        -- Extracting the first day of the week date, and week number\n        -- reference: https://docs.snowflake.com/en/sql-reference/functions-date-time#label-calendar-weeks-weekdays\n        weekofyear(sample_date) as sample_week,\n        date_trunc('week', sample_date) as sample_week_start_date\n    from ANALYTICS_PRD.performance.int_performance__detector_metrics_agg_daily\n    -- we do not want to calculate incomplete week aggregation\n    where date_trunc(week, sample_date) != date_trunc(week, current_date)\n),\n\n-- now aggregate daily volume, occupancy and speed to weekly\nweekly_spatial_temporal_metrics as (\n    select\n        detector_id,\n        sample_week,\n        sample_week_start_date,\n        any_value(station_id) as station_id,\n        any_value(lane) as lane,\n        any_value(city) as city,\n        any_value(county) as county,\n        any_value(district) as district,\n        any_value(station_type) as station_type,\n        any_value(freeway) as freeway,\n        any_value(direction) as direction,\n        sum(daily_volume) as weekly_volume,\n        avg(daily_occupancy) as weekly_occupancy,\n        sum(daily_vmt) as weekly_vmt,\n        sum(daily_vht) as weekly_vht,\n        weekly_vmt / nullifzero(weekly_vht) as weekly_q_value,\n        -- travel time\n        60 / nullifzero(weekly_q_value) as weekly_tti,\n        \n            sum(delay_35_mph)\n                as delay_35_mph\n            \n                ,\n            \n\n        \n            sum(delay_40_mph)\n                as delay_40_mph\n            \n                ,\n            \n\n        \n            sum(delay_45_mph)\n                as delay_45_mph\n            \n                ,\n            \n\n        \n            sum(delay_50_mph)\n                as delay_50_mph\n            \n                ,\n            \n\n        \n            sum(delay_55_mph)\n                as delay_55_mph\n            \n                ,\n            \n\n        \n            sum(delay_60_mph)\n                as delay_60_mph\n            \n\n        ,\n        \n            sum(lost_productivity_35_mph)\n                as lost_productivity_35_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_40_mph)\n                as lost_productivity_40_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_45_mph)\n                as lost_productivity_45_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_50_mph)\n                as lost_productivity_50_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_55_mph)\n                as lost_productivity_55_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_60_mph)\n                as lost_productivity_60_mph\n            \n\n        \n    from station_daily_data\n    group by\n        detector_id, sample_week, sample_week_start_date\n)\n\nselect * from weekly_spatial_temporal_metrics", "relation_name": "ANALYTICS_PRD.performance.int_performance__detector_metrics_agg_weekly", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.355814Z", "completed_at": "2025-08-19T19:33:51.364358Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.366829Z", "completed_at": "2025-08-19T19:33:51.366840Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.019615650177001953, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_performance__station_aadt_with_K_value", "compiled": true, "compiled_code": "\n\n-- Get all of the detectors that are producing good data, based on\n-- the diagnostic tests\nwith good_detectors as (\n    select\n        station_id,\n        lane,\n        district,\n        sample_date\n    from ANALYTICS_PRD.diagnostics.int_diagnostics__detector_status\n    where status = 'Good'\n),\n\n-- read detector daily aggregated performance metrics\n-- join with good dectors\ngood_detectors_daily_agg as (\n    select sd.*\n    from ANALYTICS_PRD.performance.int_performance__detector_metrics_agg_daily as sd\n    inner join good_detectors on\n        sd.station_id = good_detectors.station_id\n        and sd.lane = good_detectors.lane\n        and sd.sample_date = good_detectors.sample_date\n),\n\n--  calculate station level metrics first\ngood_station_daily_agg as (\n    select\n        station_id,\n        city,\n        county,\n        district,\n        freeway,\n        direction,\n        station_type,\n        -- aggregate station volume over all lanes\n        sum(daily_volume) as daily_volume,\n        sample_date\n    from good_detectors_daily_agg\n    group by station_id, city, county, district, freeway, direction, station_type, sample_date\n),\n\n-- AADT_1: Arithmetic Mean\naadt_1 as (\n    select\n        station_id,\n        city,\n        county,\n        district,\n        freeway,\n        direction,\n        station_type,\n        avg(daily_volume) as aadt_1,\n        date_trunc('year', sample_date) as sample_year\n    from good_station_daily_agg\n    group by station_id, city, county, district, freeway, direction, station_type, sample_year\n),\n\n-- AADT_2: ASTM Standard 1442\nmadw as (\n    select\n        station_id,\n        city,\n        county,\n        district,\n        freeway,\n        direction,\n        station_type,\n        -- calculate  Monthly Average Days of the Week (MADW).\n        avg(daily_volume) as madw,\n        extract(dow from sample_date) as day_of_week,\n        date_trunc('month', sample_date) as sample_month,\n        date_trunc('year', sample_date) as sample_year\n    from good_station_daily_agg\n    group by\n        station_id, city, county, freeway, direction, district, station_type, day_of_week, sample_month, sample_year\n),\n\nmadt as (\n    select\n        station_id,\n        city,\n        county,\n        district,\n        direction,\n        freeway,\n        station_type,\n        sample_month,\n        sample_year,\n        count(station_id) as sample_ct,\n        avg(madw) as madt\n    from madw\n    where madw > 0\n    group by station_id, city, county, district, freeway, direction, station_type, sample_month, sample_year\n),\n\naadt_2 as (\n    select\n        station_id,\n        city,\n        county,\n        district,\n        direction,\n        freeway,\n        station_type,\n        sample_year,\n        count(sample_month) as sample_ct,\n        avg(madt) as aadt_2\n    from madt\n    group by station_id, city, county, district, freeway, direction, station_type, sample_year\n    -- all 12 months average traffic volume is required to calculate this metric\n    having count(sample_month) = 12\n),\n\n-- AADT_3: Conventional AASHTO Procedures\naadw as (\n    select\n        station_id,\n        city,\n        county,\n        district,\n        freeway,\n        direction,\n        station_type,\n        -- calculate Annual Average Days of the Week (AADW)\n        avg(madw) as aadw,\n        day_of_week,\n        sample_year\n    from madw\n    where madw > 0\n    group by station_id, city, county, district, freeway, direction, station_type, day_of_week, sample_year\n),\n\naadt_3 as (\n    select\n        station_id,\n        city,\n        county,\n        district,\n        freeway,\n        direction,\n        station_type,\n        sample_year,\n        avg(aadw) as aadt_3\n    from aadw\n    group by station_id, city, county, district, freeway, direction, station_type, sample_year\n),\n\n-- read the detector hourly aggregated model\n-- filter out the good dectors data only\ngood_detectors_hourly_agg as (\n    select sh.*\n    from ANALYTICS_PRD.performance.int_performance__detector_metrics_agg_hourly as sh\n    inner join good_detectors on\n        sh.station_id = good_detectors.station_id\n        and sh.lane = good_detectors.lane\n        and sh.sample_date = good_detectors.sample_date\n),\n\n--  aggregate the hourly volume in station level first\ngood_station_hourly_agg as (\n    select\n        station_id,\n        district,\n        station_type,\n        sample_hour,\n        sample_date,\n        sum(hourly_volume) as hourly_volume\n    from good_detectors_hourly_agg\n    group by station_id, sample_date, sample_hour, district, station_type\n\n),\n\n-- AADT_4: Provisional AASHTO Procedures\nmahw as (\n    select\n        station_id,\n        district,\n        station_type,\n        extract(dow from sample_date) as day_of_week,\n        extract(hour from sample_hour) as hour_of_day,\n        date_trunc('month', sample_date) as sample_month,\n        date_trunc('year', sample_date) as sample_year,\n        -- calculate monthly average flow for each hour of the week\n        avg(hourly_volume) as mahw\n    from good_station_hourly_agg\n    group by station_id, district, station_type, hour_of_day, day_of_week, sample_month, sample_year\n),\n\nmonthly_average_days_of_the_week_traffic as (\n    select\n        station_id,\n        district,\n        station_type,\n        day_of_week,\n        sample_month,\n        sample_year,\n        sum(mahw) as madw\n    from mahw\n    group by station_id, district, station_type, day_of_week, sample_month, sample_year\n),\n\naverages_of_madw as (\n    select\n        station_id,\n        district,\n        station_type,\n        avg(madw) as aadw,\n        day_of_week,\n        sample_year\n    from monthly_average_days_of_the_week_traffic\n    where madw > 0\n    group by station_id, district, station_type, day_of_week, sample_year\n),\n\naadt_4 as (\n    select\n        station_id,\n        district,\n        station_type,\n        avg(aadw) as aadt_4,\n        sample_year\n    from averages_of_madw\n    group by station_id, district, station_type, sample_year\n),\n\n-- AADT_5: Sum of 24 Annual Average Hourly Traffic Volumes\n\nannual_average_hourly_traffic as (\n    select\n        station_id,\n        district,\n        station_type,\n        extract(hour from sample_hour) as hour_of_day,\n        date_trunc('year', sample_date) as sample_year,\n        avg(hourly_volume) as aaht\n    from good_station_hourly_agg\n    group by station_id, district, station_type, hour_of_day, sample_year\n),\n\naadt_5 as (\n    select\n        station_id,\n        district,\n        station_type,\n        sample_year,\n        sum(aaht) as aadt_5\n    from annual_average_hourly_traffic\n    group by station_id, district, station_type, sample_year\n),\n\n-- AADT_6: Modified ASTM Standard\naadt_6 as (\n    select\n        station_id,\n        city,\n        county,\n        district,\n        direction,\n        freeway,\n        station_type,\n        sample_year,\n        avg(madt) as aadt_6\n    from madt\n    group by station_id, city, county, district, freeway, direction, station_type, sample_year\n    -- 1 of the 12 madt values may be missing for this final AADT calculation.\n    having count(madt) >= 11\n),\n\n-- AADT_7: Modified Conventional AASHTO\naadw1 as (\n    select\n        station_id,\n        city,\n        county,\n        district,\n        freeway,\n        direction,\n        station_type,\n        -- calculate Annual Average Days of the Week (AADW)\n        avg(madw) as aadw,\n        count(madw) as sample_ct,\n        day_of_week,\n        sample_year\n    from madw\n    where madw > 0\n    group by station_id, city, county, district, freeway, direction, station_type, day_of_week, sample_year\n    -- 1 of the 12 MADW values may be missing in the AADW subcomputation.\n    having count(madw) >= 11\n),\n\naadt_7 as (\n    select\n        station_id,\n        city,\n        county,\n        district,\n        freeway,\n        direction,\n        station_type,\n        sample_year,\n        avg(aadw) as aadt_7,\n        count(aadw) as sample_ct\n    from aadw1\n    group by station_id, city, county, district, freeway, direction, station_type, sample_year\n    -- 1 of the 7 aadw values may be missing for this final AADT calculation.\n    having count(aadw) >= 6\n),\n\n-- AADT_8: Modified Provisional AASHTO\naverages_of_madw1 as (\n    select\n        station_id,\n        district,\n        station_type,\n        avg(madw) as aadw,\n        day_of_week,\n        count(madw) as sample_ct,\n        sample_year\n    from monthly_average_days_of_the_week_traffic\n    where madw > 0\n    group by station_id, district, station_type, day_of_week, sample_year\n    -- 1 of the 12 MADW values may be missing in the AADW subcomputation\n    having count(madw) >= 11\n),\n\naadt_8 as (\n    select\n        station_id,\n        district,\n        station_type,\n        avg(aadw) as aadt_8,\n        sample_year\n    from averages_of_madw1\n    group by station_id, district, station_type, sample_year\n    -- 1 of the 7 aadw values may be missing for this final AADT calculation.\n    having count(aadw) >= 6\n),\n\n-- now join all aadt_CTE together\naadt_1_8 as (\n    select\n        aadt_1.*,\n        aadt_2.aadt_2,\n        aadt_3.aadt_3,\n        aadt_4.aadt_4,\n        aadt_5.aadt_5,\n        aadt_6.aadt_6,\n        aadt_7.aadt_7,\n        aadt_8.aadt_8\n    from aadt_1\n    left join aadt_2\n        on\n            aadt_1.station_id = aadt_2.station_id\n            and aadt_1.sample_year = aadt_2.sample_year\n    left join aadt_3\n        on\n            aadt_1.station_id = aadt_3.station_id\n            and aadt_1.sample_year = aadt_3.sample_year\n    left join aadt_4\n        on\n            aadt_1.station_id = aadt_4.station_id\n            and aadt_1.sample_year = aadt_4.sample_year\n    left join aadt_5\n        on\n            aadt_1.station_id = aadt_5.station_id\n            and aadt_1.sample_year = aadt_5.sample_year\n    left join aadt_6\n        on\n            aadt_1.station_id = aadt_6.station_id\n            and aadt_1.sample_year = aadt_6.sample_year\n    left join aadt_7\n        on\n            aadt_1.station_id = aadt_7.station_id\n            and aadt_1.sample_year = aadt_7.sample_year\n    left join aadt_8\n        on\n            aadt_1.station_id = aadt_8.station_id\n            and aadt_1.sample_year = aadt_8.sample_year\n),\n\n-- Calculate k-factors\ntraffic_data as (\n    select\n        station_id,\n        district,\n        station_type,\n        hourly_volume,\n        sample_date,\n        date_trunc('year', sample_date) as observation_year\n    from good_station_hourly_agg\n),\n\n-- get 30th highest hour volume in preceding year\nk_30 as (\n    select\n        station_id,\n        district,\n        station_type,\n        hourly_volume as k_30,\n        observation_year,\n        dateadd(year, 1, observation_year) as kfactor_year\n    from traffic_data\n    qualify rank() over (\n        partition by station_id, observation_year\n        order by hourly_volume desc\n    ) = 30\n),\n\n-- get 50th highest hour volume in preceding year\nk_50 as (\n    select\n        station_id,\n        district,\n        station_type,\n        hourly_volume as k_50,\n        observation_year,\n        dateadd(year, 1, observation_year) as kfactor_year\n    from traffic_data\n    qualify rank() over (\n        partition by station_id, observation_year\n        order by hourly_volume desc\n    ) = 50\n),\n\n-- get 100th highest hour volume in preceding year\nk_100 as (\n    select\n        station_id,\n        district,\n        station_type,\n        hourly_volume as k_100,\n        observation_year,\n        dateadd(year, 1, observation_year) as kfactor_year\n    from traffic_data\n    qualify rank() over (\n        partition by station_id, observation_year\n        order by hourly_volume desc\n    ) = 100\n),\n\n-- join all k factors with all AADT\naadt_1_8_kfactors as (\n    select\n        aadt_1_8.*,\n        k_30.k_30,\n        k_50.k_50,\n        k_100.k_100\n    from aadt_1_8\n    left join k_30\n        on\n            aadt_1_8.station_id = k_30.station_id\n            and aadt_1_8.sample_year = k_30.kfactor_year\n    left join k_50\n        on\n            aadt_1_8.station_id = k_50.station_id\n            and aadt_1_8.sample_year = k_50.kfactor_year\n    left join k_100\n        on\n            aadt_1_8.station_id = k_100.station_id\n            and aadt_1_8.sample_year = k_100.kfactor_year\n)\n\nselect distinct\n    station_id,\n    station_type,\n    sample_year,\n    city,\n    county,\n    direction,\n    district,\n    freeway,\n    aadt_1,\n    aadt_2,\n    aadt_3,\n    aadt_4,\n    aadt_5,\n    aadt_6,\n    aadt_7,\n    aadt_8,\n    k_30,\n    k_50,\n    k_100\nfrom aadt_1_8_kfactors", "relation_name": "ANALYTICS_PRD.performance.int_performance__station_aadt_with_K_value", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.368162Z", "completed_at": "2025-08-19T19:33:51.381740Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.388036Z", "completed_at": "2025-08-19T19:33:51.388046Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.024900197982788086, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_performance__station_metrics_agg_monthly", "compiled": true, "compiled_code": "\n\n-- read the volume, occupancy and speed daily level data\nwith station_daily_data as (\n    select\n        *,\n        -- Extracting first day of each month\n        -- reference: https://docs.snowflake.com/en/sql-reference/functions/year\n        date_trunc(month, sample_date) as sample_month\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_daily\n    where date_trunc(month, sample_date) != date_trunc(month, current_date)\n),\n\n-- now aggregate daily volume, occupancy and speed to weekly.\nmonthly_station_level_spatial_temporal_metrics as (\n    select\n        station_id,\n        sample_month,\n        any_value(station_type) as station_type,\n        any_value(district) as district,\n        any_value(county) as county,\n        any_value(city) as city,\n        any_value(freeway) as freeway,\n        any_value(direction) as direction,\n        any_value(length) as length,\n        sum(daily_volume) as monthly_volume,\n        avg(daily_occupancy) as monthly_occupancy,\n        sum(daily_volume * daily_speed) / nullifzero(sum(daily_volume)) as monthly_speed,\n        sum(daily_vmt) as monthly_vmt,\n        sum(daily_vht) as monthly_vht,\n        monthly_vmt / nullifzero(monthly_vht) as monthly_q_value,\n        -- travel time\n        60 / nullifzero(monthly_q_value) as monthly_tti,\n        \n            greatest(\n                monthly_volume\n                * ((any_value(length) / nullifzero(monthly_speed)) - (any_value(length) / 35)),\n                0\n            )\n                as delay_35_mph\n            \n                ,\n            \n\n        \n            greatest(\n                monthly_volume\n                * ((any_value(length) / nullifzero(monthly_speed)) - (any_value(length) / 40)),\n                0\n            )\n                as delay_40_mph\n            \n                ,\n            \n\n        \n            greatest(\n                monthly_volume\n                * ((any_value(length) / nullifzero(monthly_speed)) - (any_value(length) / 45)),\n                0\n            )\n                as delay_45_mph\n            \n                ,\n            \n\n        \n            greatest(\n                monthly_volume\n                * ((any_value(length) / nullifzero(monthly_speed)) - (any_value(length) / 50)),\n                0\n            )\n                as delay_50_mph\n            \n                ,\n            \n\n        \n            greatest(\n                monthly_volume\n                * ((any_value(length) / nullifzero(monthly_speed)) - (any_value(length) / 55)),\n                0\n            )\n                as delay_55_mph\n            \n                ,\n            \n\n        \n            greatest(\n                monthly_volume\n                * ((any_value(length) / nullifzero(monthly_speed)) - (any_value(length) / 60)),\n                0\n            )\n                as delay_60_mph\n            \n\n        ,\n        \n            sum(lost_productivity_35_mph)\n                as lost_productivity_35_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_40_mph)\n                as lost_productivity_40_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_45_mph)\n                as lost_productivity_45_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_50_mph)\n                as lost_productivity_50_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_55_mph)\n                as lost_productivity_55_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_60_mph)\n                as lost_productivity_60_mph\n            \n\n        \n    from station_daily_data\n    group by station_id, sample_month\n)\n\nselect * from monthly_station_level_spatial_temporal_metrics", "relation_name": "ANALYTICS_PRD.performance.int_performance__station_metrics_agg_monthly", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.375300Z", "completed_at": "2025-08-19T19:33:51.392871Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.394256Z", "completed_at": "2025-08-19T19:33:51.394265Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.028075456619262695, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_performance__station_metrics_agg_weekly", "compiled": true, "compiled_code": "\n\n-- read the volume, occupancy and speed daily level data\nwith station_daily_data as (\n    select\n        *,\n        -- Extracting the week and year\n        -- reference: https://docs.snowflake.com/en/sql-reference/functions-date-time#label-calendar-weeks-weekdays\n        year(sample_date) as sample_year,\n        weekofyear(sample_date) as sample_week,\n        date_trunc('week', sample_date) as sample_week_start_date\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_daily\n    -- we do not want to calculate incomplete week aggregation\n    where date_trunc(week, sample_date) != date_trunc(week, current_date)\n),\n\n-- now aggregate daily volume, occupancy and speed to weekly\nweekly_station_level_spatial_temporal_metrics as (\n    select\n        station_id,\n        length,\n        sample_year,\n        sample_week,\n        sample_week_start_date,\n        any_value(station_type) as station_type,\n        any_value(district) as district,\n        any_value(county) as county,\n        any_value(city) as city,\n        any_value(freeway) as freeway,\n        any_value(direction) as direction,\n        sum(daily_volume) as weekly_volume,\n        avg(daily_occupancy) as weekly_occupancy,\n        sum(daily_volume * daily_speed) / nullifzero(sum(daily_volume)) as weekly_speed,\n        sum(daily_vmt) as weekly_vmt,\n        sum(daily_vht) as weekly_vht,\n        weekly_vmt / nullifzero(weekly_vht) as weekly_q_value,\n        -- travel time\n        60 / nullifzero(weekly_q_value) as weekly_tti,\n        \n            greatest(\n                weekly_volume * ((length / nullifzero(weekly_speed)) - (length / 35)), 0\n            )\n                as delay_35_mph\n            \n                ,\n            \n\n        \n            greatest(\n                weekly_volume * ((length / nullifzero(weekly_speed)) - (length / 40)), 0\n            )\n                as delay_40_mph\n            \n                ,\n            \n\n        \n            greatest(\n                weekly_volume * ((length / nullifzero(weekly_speed)) - (length / 45)), 0\n            )\n                as delay_45_mph\n            \n                ,\n            \n\n        \n            greatest(\n                weekly_volume * ((length / nullifzero(weekly_speed)) - (length / 50)), 0\n            )\n                as delay_50_mph\n            \n                ,\n            \n\n        \n            greatest(\n                weekly_volume * ((length / nullifzero(weekly_speed)) - (length / 55)), 0\n            )\n                as delay_55_mph\n            \n                ,\n            \n\n        \n            greatest(\n                weekly_volume * ((length / nullifzero(weekly_speed)) - (length / 60)), 0\n            )\n                as delay_60_mph\n            \n\n        ,\n        \n            sum(lost_productivity_35_mph)\n                as lost_productivity_35_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_40_mph)\n                as lost_productivity_40_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_45_mph)\n                as lost_productivity_45_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_50_mph)\n                as lost_productivity_50_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_55_mph)\n                as lost_productivity_55_mph\n            \n                ,\n            \n\n        \n            sum(lost_productivity_60_mph)\n                as lost_productivity_60_mph\n            \n\n        \n    from station_daily_data\n    group by\n        station_id, sample_year, sample_week, sample_week_start_date, length\n)\n\nselect * from weekly_station_level_spatial_temporal_metrics", "relation_name": "ANALYTICS_PRD.performance.int_performance__station_metrics_agg_weekly", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.382895Z", "completed_at": "2025-08-19T19:33:51.395789Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.397541Z", "completed_at": "2025-08-19T19:33:51.397549Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.02291703224182129, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_agg_daily", "compiled": true, "compiled_code": "\n\nwith daily as (\n    select\n        station_id,\n        sample_date,\n        length,\n        station_type,\n        district,\n        city,\n        freeway,\n        direction,\n        daily_volume,\n        daily_occupancy,\n        daily_speed,\n        daily_vmt,\n        daily_vht,\n        daily_q_value,\n        daily_tti,\n        county\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_daily\n),\n\ndailyc as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            daily.*,\n            c.county_name,\n            c.county_abb\n        from daily\n        inner join county as c\n        on daily.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\ndailycc as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from dailyc as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n)\n\nselect * from dailycc", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_agg_daily", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.389690Z", "completed_at": "2025-08-19T19:33:51.398269Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.403187Z", "completed_at": "2025-08-19T19:33:51.403197Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.022716522216796875, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_agg_daily_city", "compiled": true, "compiled_code": "with station_daily_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_daily\n),\n\n-- now aggregate daily volume, occupancy and speed to daily\nspatial_metrics as (\n    select\n        city,\n        sample_date,\n        sum(daily_volume) as daily_volume_sum,\n        avg(daily_occupancy) as daily_occupancy_avg,\n        sum(daily_volume * daily_speed) / nullifzero(sum(daily_volume)) as daily_speed_avg,\n        sum(daily_vmt) as daily_vmt,\n        sum(daily_vht) as daily_vht,\n        sum(daily_vmt) / nullifzero(sum(daily_vht)) as daily_q_value,\n        60 / nullifzero(sum(daily_q_value)) as daily_tti\n    from station_daily_data\n    where\n        city is not null\n    group by\n        city, sample_date\n),\n\nspatial_metrics_city as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from spatial_metrics as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n)\n\nselect * from spatial_metrics_city", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_agg_daily_city", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.399466Z", "completed_at": "2025-08-19T19:33:51.405908Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.410447Z", "completed_at": "2025-08-19T19:33:51.410458Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.015299320220947266, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_agg_daily_county", "compiled": true, "compiled_code": "with station_daily_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_daily\n),\n\n-- now aggregate daily volume, occupancy and speed to daily\nspatial_metrics as (\n    select\n        county,\n        sample_date,\n        sum(daily_volume) as daily_volume_sum,\n        avg(daily_occupancy) as daily_occupancy_avg,\n        sum(daily_volume * daily_speed) / nullifzero(sum(daily_volume)) as daily_speed_avg,\n        sum(daily_vmt) as daily_vmt,\n        sum(daily_vht) as daily_vht,\n        sum(daily_vmt) / nullifzero(sum(daily_vht)) as daily_q_value,\n        60 / nullifzero(sum(daily_q_value)) as daily_tti\n    from station_daily_data\n    group by\n        county, sample_date\n),\n\ndailyc as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            spatial_metrics.*,\n            c.county_name,\n            c.county_abb\n        from spatial_metrics\n        inner join county as c\n        on spatial_metrics.county = c.county_id\n    )\n\n    select * from station_with_county\n\n)\n\nselect * from dailyc", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_agg_daily_county", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.406494Z", "completed_at": "2025-08-19T19:33:51.416727Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.422281Z", "completed_at": "2025-08-19T19:33:51.422289Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.023581981658935547, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_agg_daily_district", "compiled": true, "compiled_code": "with station_daily_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_daily\n),\n\n-- now aggregate daily volume, occupancy and speed to daily\nspatial_metrics as (\n    select\n        district,\n        sample_date,\n        sum(daily_volume) as daily_volume_sum,\n        avg(daily_occupancy) as daily_occupancy_avg,\n        sum(daily_volume * daily_speed) / nullifzero(sum(daily_volume)) as daily_speed_avg,\n        sum(daily_vmt) as daily_vmt,\n        sum(daily_vht) as daily_vht,\n        sum(daily_vmt) / nullifzero(sum(daily_vht)) as daily_q_value,\n        60 / nullifzero(sum(daily_q_value)) as daily_tti\n    from station_daily_data\n    group by\n        district, sample_date\n)\n\nselect * from spatial_metrics", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_agg_daily_district", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.411326Z", "completed_at": "2025-08-19T19:33:51.423038Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.424930Z", "completed_at": "2025-08-19T19:33:51.424942Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.020326614379882812, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_unpivot_agg_daily", "compiled": true, "compiled_code": "\n\nwith daily as (\n    select * from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_daily\n),\n\ndailyc as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            daily.*,\n            c.county_name,\n            c.county_abb\n        from daily\n        inner join county as c\n        on daily.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\ndailycc as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from dailyc as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n),\n\nunpivot_combined as (\n    select\n        station_id,\n        sample_date,\n        length,\n        station_type,\n        district,\n        city,\n        city_abb,\n        city_name,\n        freeway,\n        direction,\n        county,\n        county_name,\n        county_abb,\n        target_speed,\n        sum(coalesce(delay, 0)) as delay,\n        sum(coalesce(lost_productivity, 0)) as lost_productivity\n    from (\n        \n            select\n                station_id,\n                sample_date,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_name,\n                county_abb,\n                '35' as target_speed,\n                delay_35_mph as delay,\n                lost_productivity_35_mph as lost_productivity\n            from\n                dailycc\n             union all \n        \n            select\n                station_id,\n                sample_date,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_name,\n                county_abb,\n                '40' as target_speed,\n                delay_40_mph as delay,\n                lost_productivity_40_mph as lost_productivity\n            from\n                dailycc\n             union all \n        \n            select\n                station_id,\n                sample_date,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_name,\n                county_abb,\n                '45' as target_speed,\n                delay_45_mph as delay,\n                lost_productivity_45_mph as lost_productivity\n            from\n                dailycc\n             union all \n        \n            select\n                station_id,\n                sample_date,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_name,\n                county_abb,\n                '50' as target_speed,\n                delay_50_mph as delay,\n                lost_productivity_50_mph as lost_productivity\n            from\n                dailycc\n             union all \n        \n            select\n                station_id,\n                sample_date,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_name,\n                county_abb,\n                '55' as target_speed,\n                delay_55_mph as delay,\n                lost_productivity_55_mph as lost_productivity\n            from\n                dailycc\n             union all \n        \n            select\n                station_id,\n                sample_date,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_name,\n                county_abb,\n                '60' as target_speed,\n                delay_60_mph as delay,\n                lost_productivity_60_mph as lost_productivity\n            from\n                dailycc\n            \n        \n    ) as combined_metrics\n    group by\n        sample_date,\n        station_id,\n        length,\n        station_type,\n        district,\n        city,\n        city_abb,\n        city_name,\n        freeway,\n        direction,\n        county,\n        county_name,\n        county_abb,\n        target_speed\n)\n\nselect * from unpivot_combined", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_unpivot_agg_daily", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.417935Z", "completed_at": "2025-08-19T19:33:51.426213Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.431982Z", "completed_at": "2025-08-19T19:33:51.431996Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.022309541702270508, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_unpivot_agg_daily_city", "compiled": true, "compiled_code": "-- read the volume, occupancy and speed daily level data\nwith station_daily_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_daily\n),\n\ndailyc as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from station_daily_data as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n),\n\nunpivot_combined as (\n    select\n        city,\n        city_abb,\n        city_name,\n        sample_date,\n        target_speed,\n        sum(coalesce(delay, 0)) as delay,\n        sum(coalesce(lost_productivity, 0)) as lost_productivity\n    from (\n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_date,\n                '35' as target_speed,\n                nullif(delay_35_mph, 0) as delay,\n                nullif(lost_productivity_35_mph, 0) as lost_productivity\n            from\n                dailyc\n             union all \n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_date,\n                '40' as target_speed,\n                nullif(delay_40_mph, 0) as delay,\n                nullif(lost_productivity_40_mph, 0) as lost_productivity\n            from\n                dailyc\n             union all \n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_date,\n                '45' as target_speed,\n                nullif(delay_45_mph, 0) as delay,\n                nullif(lost_productivity_45_mph, 0) as lost_productivity\n            from\n                dailyc\n             union all \n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_date,\n                '50' as target_speed,\n                nullif(delay_50_mph, 0) as delay,\n                nullif(lost_productivity_50_mph, 0) as lost_productivity\n            from\n                dailyc\n             union all \n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_date,\n                '55' as target_speed,\n                nullif(delay_55_mph, 0) as delay,\n                nullif(lost_productivity_55_mph, 0) as lost_productivity\n            from\n                dailyc\n             union all \n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_date,\n                '60' as target_speed,\n                nullif(delay_60_mph, 0) as delay,\n                nullif(lost_productivity_60_mph, 0) as lost_productivity\n            from\n                dailyc\n            \n        \n    ) as combined_metrics\n    where\n        city is not null\n    group by\n        city, city_abb, city_name, sample_date, target_speed\n)\n\nselect * from unpivot_combined", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_unpivot_agg_daily_city", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.427821Z", "completed_at": "2025-08-19T19:33:51.438462Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.440358Z", "completed_at": "2025-08-19T19:33:51.440370Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.01678633689880371, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_unpivot_agg_daily_county", "compiled": true, "compiled_code": "-- read the volume, occupancy and speed daily level data\nwith station_daily_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_daily\n),\n\ndailyc as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            station_daily_data.*,\n            c.county_name,\n            c.county_abb\n        from station_daily_data\n        inner join county as c\n        on station_daily_data.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\nunpivot_combined as (\n    select\n        county,\n        county_abb,\n        county_name,\n        sample_date,\n        target_speed,\n        sum(coalesce(delay, 0)) as delay,\n        sum(coalesce(lost_productivity, 0)) as lost_productivity\n    from (\n        \n            select\n                county,\n                county_abb,\n                county_name,\n                sample_date,\n                '35' as target_speed,\n                nullif(delay_35_mph, 0) as delay,\n                nullif(lost_productivity_35_mph, 0) as lost_productivity\n            from\n                dailyc\n             union all \n        \n            select\n                county,\n                county_abb,\n                county_name,\n                sample_date,\n                '40' as target_speed,\n                nullif(delay_40_mph, 0) as delay,\n                nullif(lost_productivity_40_mph, 0) as lost_productivity\n            from\n                dailyc\n             union all \n        \n            select\n                county,\n                county_abb,\n                county_name,\n                sample_date,\n                '45' as target_speed,\n                nullif(delay_45_mph, 0) as delay,\n                nullif(lost_productivity_45_mph, 0) as lost_productivity\n            from\n                dailyc\n             union all \n        \n            select\n                county,\n                county_abb,\n                county_name,\n                sample_date,\n                '50' as target_speed,\n                nullif(delay_50_mph, 0) as delay,\n                nullif(lost_productivity_50_mph, 0) as lost_productivity\n            from\n                dailyc\n             union all \n        \n            select\n                county,\n                county_abb,\n                county_name,\n                sample_date,\n                '55' as target_speed,\n                nullif(delay_55_mph, 0) as delay,\n                nullif(lost_productivity_55_mph, 0) as lost_productivity\n            from\n                dailyc\n             union all \n        \n            select\n                county,\n                county_abb,\n                county_name,\n                sample_date,\n                '60' as target_speed,\n                nullif(delay_60_mph, 0) as delay,\n                nullif(lost_productivity_60_mph, 0) as lost_productivity\n            from\n                dailyc\n            \n        \n    ) as combined_metrics\n    group by\n        county, county_abb, county_name, sample_date, target_speed\n)\n\nselect * from unpivot_combined", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_unpivot_agg_daily_county", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.434583Z", "completed_at": "2025-08-19T19:33:51.447131Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.453670Z", "completed_at": "2025-08-19T19:33:51.453684Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.027031421661376953, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_unpivot_agg_daily_district", "compiled": true, "compiled_code": "-- read the volume, occupancy and speed daily level data\nwith station_daily_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_daily\n),\n\nunpivot_combined as (\n    select\n        district,\n        sample_date,\n        target_speed,\n        sum(coalesce(delay, 0)) as delay,\n        sum(coalesce(lost_productivity, 0)) as lost_productivity\n    from (\n        \n            select\n                district,\n                sample_date,\n                '35' as target_speed,\n                nullif(delay_35_mph, 0) as delay,\n                nullif(lost_productivity_35_mph, 0) as lost_productivity\n            from\n                station_daily_data\n             union all \n        \n            select\n                district,\n                sample_date,\n                '40' as target_speed,\n                nullif(delay_40_mph, 0) as delay,\n                nullif(lost_productivity_40_mph, 0) as lost_productivity\n            from\n                station_daily_data\n             union all \n        \n            select\n                district,\n                sample_date,\n                '45' as target_speed,\n                nullif(delay_45_mph, 0) as delay,\n                nullif(lost_productivity_45_mph, 0) as lost_productivity\n            from\n                station_daily_data\n             union all \n        \n            select\n                district,\n                sample_date,\n                '50' as target_speed,\n                nullif(delay_50_mph, 0) as delay,\n                nullif(lost_productivity_50_mph, 0) as lost_productivity\n            from\n                station_daily_data\n             union all \n        \n            select\n                district,\n                sample_date,\n                '55' as target_speed,\n                nullif(delay_55_mph, 0) as delay,\n                nullif(lost_productivity_55_mph, 0) as lost_productivity\n            from\n                station_daily_data\n             union all \n        \n            select\n                district,\n                sample_date,\n                '60' as target_speed,\n                nullif(delay_60_mph, 0) as delay,\n                nullif(lost_productivity_60_mph, 0) as lost_productivity\n            from\n                station_daily_data\n            \n        \n    ) as combined_metrics\n    group by\n        district, sample_date, target_speed\n)\n\nselect * from unpivot_combined", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_unpivot_agg_daily_district", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.441146Z", "completed_at": "2025-08-19T19:33:51.454062Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.455427Z", "completed_at": "2025-08-19T19:33:51.455437Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.022151708602905273, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_performance__bottleneck_delay_metrics_agg_daily", "compiled": true, "compiled_code": "\n\nwith hourly_spatial_bottleneck_delay_metrics as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__bottleneck_delay_metrics_agg_hourly\n    where \n    1=1\n    \n),\n\n/*aggregate hourly delay and bottleneck extent in a daily level. Since one day has\n3 time shifts, the aggregation would be in a time shift level*/\n\ndaily_time_shift_spatial_bottleneck_delay_metrics as (\n    select\n        station_id,\n        sample_date,\n        time_shift,\n        any_value(district) as district,\n        any_value(county) as county,\n        any_value(station_type) as station_type,\n        any_value(freeway) as freeway,\n        any_value(direction) as direction,\n        any_value(absolute_postmile) as absolute_postmile,\n        sum(hourly_duration) as daily_time_shift_duration,\n        avg(hourly_bottleneck_extent) as daily_time_shift_bottleneck_extent,\n        -- spatial delay aggregation in daily level, decomposed into time shift\n        \n            sum(hourly_spatial_delay_35_mph)\n                as daily_time_shift_spatial_delay_35_mph\n            \n                ,\n            \n        \n            sum(hourly_spatial_delay_40_mph)\n                as daily_time_shift_spatial_delay_40_mph\n            \n                ,\n            \n        \n            sum(hourly_spatial_delay_45_mph)\n                as daily_time_shift_spatial_delay_45_mph\n            \n                ,\n            \n        \n            sum(hourly_spatial_delay_50_mph)\n                as daily_time_shift_spatial_delay_50_mph\n            \n                ,\n            \n        \n            sum(hourly_spatial_delay_55_mph)\n                as daily_time_shift_spatial_delay_55_mph\n            \n                ,\n            \n        \n            sum(hourly_spatial_delay_60_mph)\n                as daily_time_shift_spatial_delay_60_mph\n            \n        \n    from hourly_spatial_bottleneck_delay_metrics\n    where time_shift is not NULL\n    group by station_id, sample_date, time_shift\n)\n\nselect * from daily_time_shift_spatial_bottleneck_delay_metrics", "relation_name": "ANALYTICS_PRD.performance.int_performance__bottleneck_delay_metrics_agg_daily", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.448482Z", "completed_at": "2025-08-19T19:33:51.456253Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.461069Z", "completed_at": "2025-08-19T19:33:51.461078Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.02144455909729004, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_aadt_k_value_daily_county", "compiled": true, "compiled_code": "with aadt as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_aadt_with_K_value\n),\n\naadt_with_county as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            aadt.*,\n            c.county_name,\n            c.county_abb\n        from aadt\n        inner join county as c\n        on aadt.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\ngeo as (\n    select\n        station_id,\n        latitude,\n        longitude,\n        concat(longitude, ',', latitude) as location,\n        absolute_postmile\n    from ANALYTICS_PRD.geo.geo__current_stations\n),\n\naadt_county_geo as (\n    select\n        aadt_with_county.*,\n        geo.absolute_postmile,\n        geo.latitude,\n        geo.longitude,\n        geo.location\n    from\n        aadt_with_county\n    inner join\n        geo\n        on aadt_with_county.station_id = geo.station_id\n)\n\nselect * from aadt_county_geo", "relation_name": "ANALYTICS_PRD.performance.performance__station_aadt_k_value_daily_county", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.456955Z", "completed_at": "2025-08-19T19:33:51.462790Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.464118Z", "completed_at": "2025-08-19T19:33:51.464125Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.009521245956420898, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_performance__station_aadt_with_K_value_SAMPLE_YEAR.cf3f5fc885", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect SAMPLE_YEAR\nfrom ANALYTICS_PRD.performance.int_performance__station_aadt_with_K_value\nwhere SAMPLE_YEAR is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.467227Z", "completed_at": "2025-08-19T19:33:51.478632Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.480769Z", "completed_at": "2025-08-19T19:33:51.480780Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.017281770706176758, "adapter_response": {}, "message": null, "failures": null, "unique_id": "test.caldata_mdsa_caltrans_pems.not_null_int_performance__station_aadt_with_K_value_STATION_ID.148096e504", "compiled": true, "compiled_code": "\n    \n    \n\n\n\nselect STATION_ID\nfrom ANALYTICS_PRD.performance.int_performance__station_aadt_with_K_value\nwhere STATION_ID is null\n\n\n", "relation_name": null, "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.473150Z", "completed_at": "2025-08-19T19:33:51.484698Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.486390Z", "completed_at": "2025-08-19T19:33:51.486398Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.020238399505615234, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_performance__station_metrics_agg_yearly", "compiled": true, "compiled_code": "\n\n-- Read the monthly-level data and extract the year\nwith station_monthly_data as (\n    select\n        *,\n        -- Extracting first day of each year\n        date_trunc('year', sample_month) as sample_year\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_monthly\n    -- Exclude incomplete years\n    where date_trunc('year', sample_month) != date_trunc('year', current_date)\n),\n\n-- Aggregate monthly volume, occupancy, and speed to yearly\nyearly_station_level_spatial_temporal_metrics as (\n    select\n        station_id,\n        sample_year,\n        any_value(station_type) as station_type,\n        any_value(district) as district,\n        any_value(county) as county,\n        any_value(city) as city,\n        any_value(freeway) as freeway,\n        any_value(direction) as direction,\n        any_value(length) as length,\n\n        -- Summing volume-based metrics\n        sum(monthly_volume) as yearly_volume,\n        avg(monthly_occupancy) as yearly_occupancy,\n        sum(monthly_vmt) as yearly_vmt,\n        sum(monthly_vht) as yearly_vht,\n\n        -- Weighted average speed: sum(volume * speed) / sum(volume)\n        sum(monthly_volume * monthly_speed) / nullif(sum(monthly_volume), 0) as yearly_speed,\n\n        -- Compute Q-value and TTI safely\n        sum(monthly_vmt) / nullif(sum(monthly_vht), 0) as yearly_q_value,\n        -- Travel time\n        60 / nullif(sum(monthly_vmt) / nullif(sum(monthly_vht), 0), 0) as yearly_tti,\n\n        \n            greatest(\n                sum(monthly_volume)\n                * ((any_value(length) / nullif(sum(monthly_speed), 0)) - (any_value(length) / 35)),\n                0\n            ) as delay_35_mph\n            \n                ,\n            \n        \n            greatest(\n                sum(monthly_volume)\n                * ((any_value(length) / nullif(sum(monthly_speed), 0)) - (any_value(length) / 40)),\n                0\n            ) as delay_40_mph\n            \n                ,\n            \n        \n            greatest(\n                sum(monthly_volume)\n                * ((any_value(length) / nullif(sum(monthly_speed), 0)) - (any_value(length) / 45)),\n                0\n            ) as delay_45_mph\n            \n                ,\n            \n        \n            greatest(\n                sum(monthly_volume)\n                * ((any_value(length) / nullif(sum(monthly_speed), 0)) - (any_value(length) / 50)),\n                0\n            ) as delay_50_mph\n            \n                ,\n            \n        \n            greatest(\n                sum(monthly_volume)\n                * ((any_value(length) / nullif(sum(monthly_speed), 0)) - (any_value(length) / 55)),\n                0\n            ) as delay_55_mph\n            \n                ,\n            \n        \n            greatest(\n                sum(monthly_volume)\n                * ((any_value(length) / nullif(sum(monthly_speed), 0)) - (any_value(length) / 60)),\n                0\n            ) as delay_60_mph\n            \n        ,\n\n        \n            sum(lost_productivity_35_mph) as lost_productivity_35_mph\n            \n                ,\n            \n        \n            sum(lost_productivity_40_mph) as lost_productivity_40_mph\n            \n                ,\n            \n        \n            sum(lost_productivity_45_mph) as lost_productivity_45_mph\n            \n                ,\n            \n        \n            sum(lost_productivity_50_mph) as lost_productivity_50_mph\n            \n                ,\n            \n        \n            sum(lost_productivity_55_mph) as lost_productivity_55_mph\n            \n                ,\n            \n        \n            sum(lost_productivity_60_mph) as lost_productivity_60_mph\n            \n        \n\n    from station_monthly_data\n    group by station_id, sample_year\n)\n\nselect * from yearly_station_level_spatial_temporal_metrics", "relation_name": "ANALYTICS_PRD.performance.int_performance__station_metrics_agg_yearly", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.481423Z", "completed_at": "2025-08-19T19:33:51.486815Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.491247Z", "completed_at": "2025-08-19T19:33:51.491257Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.01879596710205078, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_agg_monthly", "compiled": true, "compiled_code": "\n\nwith monthly as (\n    select\n        station_id,\n        sample_month,\n        length,\n        station_type,\n        district,\n        city,\n        freeway,\n        direction,\n        monthly_volume,\n        monthly_occupancy,\n        monthly_speed,\n        monthly_vmt,\n        monthly_vht,\n        monthly_q_value,\n        monthly_tti,\n        county\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_monthly\n),\n\nmonthlyc as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            monthly.*,\n            c.county_name,\n            c.county_abb\n        from monthly\n        inner join county as c\n        on monthly.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\nmonthlycc as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from monthlyc as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n)\n\nselect * from monthlycc", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_agg_monthly", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.487377Z", "completed_at": "2025-08-19T19:33:51.492107Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.493496Z", "completed_at": "2025-08-19T19:33:51.493504Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.01340937614440918, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_agg_monthly_city", "compiled": true, "compiled_code": "\n\nwith station_monthly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_monthly\n),\n\n-- now aggregate daily volume, occupancy and speed to weekly\nspatial_metrics as (\n    select\n        city,\n        sample_month,\n        sum(monthly_volume) as monthly_volume_sum,\n        avg(monthly_occupancy) as monthly_occupancy_avg,\n        sum(monthly_volume * monthly_speed) / nullifzero(sum(monthly_volume)) as monthly_speed_avg,\n        sum(monthly_vmt) as monthly_vmt,\n        sum(monthly_vht) as monthly_vht,\n        sum(monthly_vmt) / nullifzero(sum(monthly_vht)) as monthly_q_value,\n        60 / nullifzero(sum(monthly_q_value)) as monthly_tti\n    from station_monthly_data\n    where\n        city is not null\n    group by\n        city, sample_month\n),\n\nmonthlyc as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from spatial_metrics as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n)\n\nselect * from monthlyc", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_agg_monthly_city", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.498004Z", "completed_at": "2025-08-19T19:33:51.507142Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.508819Z", "completed_at": "2025-08-19T19:33:51.508831Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.014760494232177734, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_agg_monthly_county", "compiled": true, "compiled_code": "\n\nwith station_monthly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_monthly\n),\n\n-- now aggregate daily volume, occupancy and speed to monthly\nspatial_metrics as (\n    select\n        county,\n        sample_month,\n        sum(monthly_volume) as monthly_volume_sum,\n        avg(monthly_occupancy) as monthly_occupancy_avg,\n        sum(monthly_volume * monthly_speed) / nullifzero(sum(monthly_volume)) as monthly_speed_avg,\n        sum(monthly_vmt) as monthly_vmt,\n        sum(monthly_vht) as monthly_vht,\n        sum(monthly_vmt) / nullifzero(sum(monthly_vht)) as monthly_q_value,\n        60 / nullifzero(sum(monthly_q_value)) as monthly_tti\n    from station_monthly_data\n    group by\n        county, sample_month\n),\n\nmonthlyc as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            spatial_metrics.*,\n            c.county_name,\n            c.county_abb\n        from spatial_metrics\n        inner join county as c\n        on spatial_metrics.county = c.county_id\n    )\n\n    select * from station_with_county\n\n)\n\nselect * from monthlyc", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_agg_monthly_county", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.504137Z", "completed_at": "2025-08-19T19:33:51.515411Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.522349Z", "completed_at": "2025-08-19T19:33:51.522358Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.02596592903137207, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_agg_monthly_district", "compiled": true, "compiled_code": "\n\nwith station_monthly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_monthly\n),\n\n-- now aggregate daily volume, occupancy and speed to weekly\nspatial_metrics as (\n    select\n        district,\n        sample_month,\n        sum(monthly_volume) as monthly_volume_sum,\n        avg(monthly_occupancy) as monthly_occupancy_avg,\n        sum(monthly_volume * monthly_speed) / nullifzero(sum(monthly_volume)) as monthly_speed_avg,\n        sum(monthly_vmt) as monthly_vmt,\n        sum(monthly_vht) as monthly_vht,\n        sum(monthly_vmt) / nullifzero(sum(monthly_vht)) as monthly_q_value,\n        60 / nullifzero(sum(monthly_q_value)) as monthly_tti\n    from station_monthly_data\n    group by\n        district, sample_month\n)\n\nselect * from spatial_metrics", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_agg_monthly_district", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.517998Z", "completed_at": "2025-08-19T19:33:51.525007Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.530898Z", "completed_at": "2025-08-19T19:33:51.530911Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.022835969924926758, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_unpivot_agg_monthly_city", "compiled": true, "compiled_code": "\n\n-- read the volume, occupancy and speed daily level data\nwith station_monthly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_monthly\n),\n\nmonthlyc as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from station_monthly_data as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n),\n\nunpivot_combined as (\n    select\n        city,\n        city_abb,\n        city_name,\n        sample_month,\n        target_speed,\n        sum(coalesce(delay, 0)) as delay,\n        sum(coalesce(lost_productivity, 0)) as lost_productivity\n    from (\n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_month,\n                '35' as target_speed,\n                nullif(delay_35_mph, 0) as delay,\n                nullif(lost_productivity_35_mph, 0) as lost_productivity\n            from\n                monthlyc\n             union all \n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_month,\n                '40' as target_speed,\n                nullif(delay_40_mph, 0) as delay,\n                nullif(lost_productivity_40_mph, 0) as lost_productivity\n            from\n                monthlyc\n             union all \n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_month,\n                '45' as target_speed,\n                nullif(delay_45_mph, 0) as delay,\n                nullif(lost_productivity_45_mph, 0) as lost_productivity\n            from\n                monthlyc\n             union all \n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_month,\n                '50' as target_speed,\n                nullif(delay_50_mph, 0) as delay,\n                nullif(lost_productivity_50_mph, 0) as lost_productivity\n            from\n                monthlyc\n             union all \n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_month,\n                '55' as target_speed,\n                nullif(delay_55_mph, 0) as delay,\n                nullif(lost_productivity_55_mph, 0) as lost_productivity\n            from\n                monthlyc\n             union all \n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_month,\n                '60' as target_speed,\n                nullif(delay_60_mph, 0) as delay,\n                nullif(lost_productivity_60_mph, 0) as lost_productivity\n            from\n                monthlyc\n            \n        \n    ) as combined_metrics\n    where\n        city is not null\n    group by\n        city, city_abb, city_name, sample_month, target_speed\n)\n\nselect * from unpivot_combined", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_unpivot_agg_monthly_city", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.509642Z", "completed_at": "2025-08-19T19:33:51.526088Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.532447Z", "completed_at": "2025-08-19T19:33:51.532459Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.030079126358032227, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_unpivot_agg_monthly", "compiled": true, "compiled_code": "\n\nwith monthly as (\n    select * from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_monthly\n),\n\nmonthlyc as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            monthly.*,\n            c.county_name,\n            c.county_abb\n        from monthly\n        inner join county as c\n        on monthly.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\nmonthlycc as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from monthlyc as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n),\n\nunpivot_combined as (\n    select\n        station_id,\n        sample_month,\n        length,\n        station_type,\n        district,\n        city,\n        city_abb,\n        city_name,\n        freeway,\n        direction,\n        county,\n        county_abb,\n        county_name,\n        target_speed,\n        sum(coalesce(delay, 0)) as delay,\n        sum(coalesce(lost_productivity, 0)) as lost_productivity\n    from (\n        \n            select\n                station_id,\n                sample_month,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_abb,\n                county_name,\n                '35' as target_speed,\n                delay_35_mph as delay,\n                lost_productivity_35_mph as lost_productivity\n            from\n                monthlycc\n             union all \n        \n            select\n                station_id,\n                sample_month,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_abb,\n                county_name,\n                '40' as target_speed,\n                delay_40_mph as delay,\n                lost_productivity_40_mph as lost_productivity\n            from\n                monthlycc\n             union all \n        \n            select\n                station_id,\n                sample_month,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_abb,\n                county_name,\n                '45' as target_speed,\n                delay_45_mph as delay,\n                lost_productivity_45_mph as lost_productivity\n            from\n                monthlycc\n             union all \n        \n            select\n                station_id,\n                sample_month,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_abb,\n                county_name,\n                '50' as target_speed,\n                delay_50_mph as delay,\n                lost_productivity_50_mph as lost_productivity\n            from\n                monthlycc\n             union all \n        \n            select\n                station_id,\n                sample_month,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_abb,\n                county_name,\n                '55' as target_speed,\n                delay_55_mph as delay,\n                lost_productivity_55_mph as lost_productivity\n            from\n                monthlycc\n             union all \n        \n            select\n                station_id,\n                sample_month,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_abb,\n                county_name,\n                '60' as target_speed,\n                delay_60_mph as delay,\n                lost_productivity_60_mph as lost_productivity\n            from\n                monthlycc\n            \n        \n    ) as combined_metrics\n    group by\n        sample_month,\n        station_id,\n        length,\n        station_type,\n        district,\n        city,\n        city_abb,\n        city_name,\n        freeway,\n        direction,\n        county,\n        county_abb,\n        county_name,\n        target_speed\n)\n\nselect * from unpivot_combined", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_unpivot_agg_monthly", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.526623Z", "completed_at": "2025-08-19T19:33:51.537970Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.539897Z", "completed_at": "2025-08-19T19:33:51.539906Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.016785621643066406, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_unpivot_agg_monthly_county", "compiled": true, "compiled_code": "\n\n-- read the volume, occupancy and speed daily level data\nwith station_monthly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_monthly\n),\n\nmonthlyc as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            station_monthly_data.*,\n            c.county_name,\n            c.county_abb\n        from station_monthly_data\n        inner join county as c\n        on station_monthly_data.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\nunpivot_combined as (\n    select\n        county,\n        county_abb,\n        county_name,\n        sample_month,\n        target_speed,\n        sum(coalesce(delay, 0)) as delay,\n        sum(coalesce(lost_productivity, 0)) as lost_productivity\n    from (\n        \n            select\n                county,\n                county_abb,\n                county_name,\n                sample_month,\n                '35' as target_speed,\n                nullif(delay_35_mph, 0) as delay,\n                nullif(lost_productivity_35_mph, 0) as lost_productivity\n            from\n                monthlyc\n             union all \n        \n            select\n                county,\n                county_abb,\n                county_name,\n                sample_month,\n                '40' as target_speed,\n                nullif(delay_40_mph, 0) as delay,\n                nullif(lost_productivity_40_mph, 0) as lost_productivity\n            from\n                monthlyc\n             union all \n        \n            select\n                county,\n                county_abb,\n                county_name,\n                sample_month,\n                '45' as target_speed,\n                nullif(delay_45_mph, 0) as delay,\n                nullif(lost_productivity_45_mph, 0) as lost_productivity\n            from\n                monthlyc\n             union all \n        \n            select\n                county,\n                county_abb,\n                county_name,\n                sample_month,\n                '50' as target_speed,\n                nullif(delay_50_mph, 0) as delay,\n                nullif(lost_productivity_50_mph, 0) as lost_productivity\n            from\n                monthlyc\n             union all \n        \n            select\n                county,\n                county_abb,\n                county_name,\n                sample_month,\n                '55' as target_speed,\n                nullif(delay_55_mph, 0) as delay,\n                nullif(lost_productivity_55_mph, 0) as lost_productivity\n            from\n                monthlyc\n             union all \n        \n            select\n                county,\n                county_abb,\n                county_name,\n                sample_month,\n                '60' as target_speed,\n                nullif(delay_60_mph, 0) as delay,\n                nullif(lost_productivity_60_mph, 0) as lost_productivity\n            from\n                monthlyc\n            \n        \n    ) as combined_metrics\n    group by\n        county, county_abb, county_name, sample_month, target_speed\n)\n\nselect * from unpivot_combined", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_unpivot_agg_monthly_county", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.533968Z", "completed_at": "2025-08-19T19:33:51.541228Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.543331Z", "completed_at": "2025-08-19T19:33:51.543339Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.01782822608947754, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_unpivot_agg_monthly_district", "compiled": true, "compiled_code": "\n\n-- read the volume, occupancy and speed daily level data\nwith station_monthly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_monthly\n),\n\nunpivot_combined as (\n    select\n        district,\n        sample_month,\n        target_speed,\n        sum(coalesce(delay, 0)) as delay,\n        sum(coalesce(lost_productivity, 0)) as lost_productivity\n    from (\n        \n            select\n                district,\n                sample_month,\n                '35' as target_speed,\n                nullif(delay_35_mph, 0) as delay,\n                nullif(lost_productivity_35_mph, 0) as lost_productivity\n            from\n                station_monthly_data\n             union all \n        \n            select\n                district,\n                sample_month,\n                '40' as target_speed,\n                nullif(delay_40_mph, 0) as delay,\n                nullif(lost_productivity_40_mph, 0) as lost_productivity\n            from\n                station_monthly_data\n             union all \n        \n            select\n                district,\n                sample_month,\n                '45' as target_speed,\n                nullif(delay_45_mph, 0) as delay,\n                nullif(lost_productivity_45_mph, 0) as lost_productivity\n            from\n                station_monthly_data\n             union all \n        \n            select\n                district,\n                sample_month,\n                '50' as target_speed,\n                nullif(delay_50_mph, 0) as delay,\n                nullif(lost_productivity_50_mph, 0) as lost_productivity\n            from\n                station_monthly_data\n             union all \n        \n            select\n                district,\n                sample_month,\n                '55' as target_speed,\n                nullif(delay_55_mph, 0) as delay,\n                nullif(lost_productivity_55_mph, 0) as lost_productivity\n            from\n                station_monthly_data\n             union all \n        \n            select\n                district,\n                sample_month,\n                '60' as target_speed,\n                nullif(delay_60_mph, 0) as delay,\n                nullif(lost_productivity_60_mph, 0) as lost_productivity\n            from\n                station_monthly_data\n            \n        \n    ) as combined_metrics\n    group by\n        district, sample_month, target_speed\n)\n\nselect * from unpivot_combined", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_unpivot_agg_monthly_district", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.544214Z", "completed_at": "2025-08-19T19:33:51.557424Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.559300Z", "completed_at": "2025-08-19T19:33:51.559333Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.020224809646606445, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_agg_weekly", "compiled": true, "compiled_code": "\n\nwith weekly as (\n    select\n        station_id,\n        sample_year,\n        sample_week,\n        sample_week_start_date,\n        length,\n        station_type,\n        district,\n        city,\n        freeway,\n        direction,\n        weekly_volume,\n        weekly_occupancy,\n        weekly_speed,\n        weekly_vmt,\n        weekly_vht,\n        weekly_q_value,\n        weekly_tti,\n        county\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_weekly\n),\n\nweeklyc as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            weekly.*,\n            c.county_name,\n            c.county_abb\n        from weekly\n        inner join county as c\n        on weekly.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\nweeklycc as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from weeklyc as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n)\n\nselect * from weeklycc", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_agg_weekly", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.548574Z", "completed_at": "2025-08-19T19:33:51.558072Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.560115Z", "completed_at": "2025-08-19T19:33:51.560123Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.019473552703857422, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_agg_weekly_city", "compiled": true, "compiled_code": "\n\nwith station_weekly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_weekly\n),\n\n-- now aggregate daily volume, occupancy and speed to weekly\nspatial_metrics as (\n    select\n        city,\n        sample_week,\n        sum(weekly_volume) as weekly_volume_sum,\n        avg(weekly_occupancy) as weekly_occupancy_avg,\n        sum(weekly_volume * weekly_speed) / nullifzero(sum(weekly_volume)) as weekly_speed_avg,\n        sum(weekly_vmt) as weekly_vmt,\n        sum(weekly_vht) as weekly_vht,\n        sum(weekly_vmt) / nullifzero(sum(weekly_vht)) as weekly_q_value,\n        60 / nullifzero(sum(weekly_q_value)) as weekly_tti\n    from station_weekly_data\n    where\n        city is not null\n    group by\n        city, sample_week\n),\n\nweeklyc as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from spatial_metrics as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n)\n\nselect * from weeklyc", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_agg_weekly_city", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.554014Z", "completed_at": "2025-08-19T19:33:51.560876Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.565792Z", "completed_at": "2025-08-19T19:33:51.565804Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.017971038818359375, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_agg_weekly_county", "compiled": true, "compiled_code": "\n\nwith station_weekly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_weekly\n),\n\n-- now aggregate daily volume, occupancy and speed to weekly\nspatial_metrics as (\n    select\n        county,\n        sample_week,\n        sum(weekly_volume) as weekly_volume_sum,\n        avg(weekly_occupancy) as weekly_occupancy_avg,\n        sum(weekly_volume * weekly_speed) / nullifzero(sum(weekly_volume)) as weekly_speed_avg,\n        sum(weekly_vmt) as weekly_vmt,\n        sum(weekly_vht) as weekly_vht,\n        sum(weekly_vmt) / nullifzero(sum(weekly_vht)) as weekly_q_value,\n        60 / nullifzero(sum(weekly_q_value)) as weekly_tti\n    from station_weekly_data\n    group by\n        county, sample_week\n),\n\nweeklyc as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            spatial_metrics.*,\n            c.county_name,\n            c.county_abb\n        from spatial_metrics\n        inner join county as c\n        on spatial_metrics.county = c.county_id\n    )\n\n    select * from station_with_county\n\n)\n\nselect * from weeklyc", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_agg_weekly_county", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.561415Z", "completed_at": "2025-08-19T19:33:51.567756Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.569898Z", "completed_at": "2025-08-19T19:33:51.569909Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.016561269760131836, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_agg_weekly_district", "compiled": true, "compiled_code": "\n\nwith station_weekly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_weekly\n),\n\n-- now aggregate daily volume, occupancy and speed to weekly\nspatial_metrics as (\n    select\n        district,\n        sample_week,\n        sum(weekly_volume) as weekly_volume_sum,\n        avg(weekly_occupancy) as weekly_occupancy_avg,\n        sum(weekly_volume * weekly_speed) / nullifzero(sum(weekly_volume)) as weekly_speed_avg,\n        sum(weekly_vmt) as weekly_vmt,\n        sum(weekly_vht) as weekly_vht,\n        sum(weekly_vmt) / nullifzero(sum(weekly_vht)) as weekly_q_value,\n        60 / nullifzero(sum(weekly_q_value)) as weekly_tti\n    from station_weekly_data\n    group by\n        district, sample_week\n)\n\nselect * from spatial_metrics", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_agg_weekly_district", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.571211Z", "completed_at": "2025-08-19T19:33:51.588649Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.590518Z", "completed_at": "2025-08-19T19:33:51.590530Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.02393054962158203, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_unpivot_agg_weekly", "compiled": true, "compiled_code": "\n\nwith weekly as (\n    select * from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_weekly\n),\n\nweeklyc as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            weekly.*,\n            c.county_name,\n            c.county_abb\n        from weekly\n        inner join county as c\n        on weekly.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\nweeklycc as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from weeklyc as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n),\n\nunpivot_combined as (\n    select\n        station_id,\n        sample_year,\n        sample_week,\n        sample_week_start_date,\n        length,\n        station_type,\n        district,\n        city,\n        city_abb,\n        city_name,\n        freeway,\n        direction,\n        county,\n        county_abb,\n        county_name,\n        target_speed,\n        sum(coalesce(delay, 0)) as delay,\n        sum(coalesce(lost_productivity, 0)) as lost_productivity\n    from (\n        \n            select\n                station_id,\n                sample_year,\n                sample_week,\n                sample_week_start_date,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_abb,\n                county_name,\n                '35' as target_speed,\n                delay_35_mph as delay,\n                lost_productivity_35_mph as lost_productivity\n            from\n                weeklycc\n             union all \n        \n            select\n                station_id,\n                sample_year,\n                sample_week,\n                sample_week_start_date,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_abb,\n                county_name,\n                '40' as target_speed,\n                delay_40_mph as delay,\n                lost_productivity_40_mph as lost_productivity\n            from\n                weeklycc\n             union all \n        \n            select\n                station_id,\n                sample_year,\n                sample_week,\n                sample_week_start_date,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_abb,\n                county_name,\n                '45' as target_speed,\n                delay_45_mph as delay,\n                lost_productivity_45_mph as lost_productivity\n            from\n                weeklycc\n             union all \n        \n            select\n                station_id,\n                sample_year,\n                sample_week,\n                sample_week_start_date,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_abb,\n                county_name,\n                '50' as target_speed,\n                delay_50_mph as delay,\n                lost_productivity_50_mph as lost_productivity\n            from\n                weeklycc\n             union all \n        \n            select\n                station_id,\n                sample_year,\n                sample_week,\n                sample_week_start_date,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_abb,\n                county_name,\n                '55' as target_speed,\n                delay_55_mph as delay,\n                lost_productivity_55_mph as lost_productivity\n            from\n                weeklycc\n             union all \n        \n            select\n                station_id,\n                sample_year,\n                sample_week,\n                sample_week_start_date,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_abb,\n                county_name,\n                '60' as target_speed,\n                delay_60_mph as delay,\n                lost_productivity_60_mph as lost_productivity\n            from\n                weeklycc\n            \n        \n    ) as combined_metrics\n    group by\n        sample_year,\n        sample_week,\n        sample_week_start_date,\n        station_id,\n        length,\n        station_type,\n        district,\n        city,\n        city_abb,\n        city_name,\n        freeway,\n        direction,\n        county,\n        county_abb,\n        county_name,\n        target_speed\n)\n\nselect * from unpivot_combined", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_unpivot_agg_weekly", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.576153Z", "completed_at": "2025-08-19T19:33:51.589281Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.591805Z", "completed_at": "2025-08-19T19:33:51.591813Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.024660587310791016, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_unpivot_agg_weekly_city", "compiled": true, "compiled_code": "\n\n-- read the volume, occupancy and speed weekly level data\nwith station_weekly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_weekly\n),\n\nweeklyc as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from station_weekly_data as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n),\n\nunpivot_combined as (\n    select\n        city,\n        city_abb,\n        city_name,\n        sample_week,\n        sample_week_start_date,\n        target_speed,\n        sum(coalesce(delay, 0)) as delay,\n        sum(coalesce(lost_productivity, 0)) as lost_productivity\n    from (\n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_week,\n                sample_week_start_date,\n                '35' as target_speed,\n                nullif(delay_35_mph, 0) as delay,\n                nullif(lost_productivity_35_mph, 0) as lost_productivity\n            from\n                weeklyc\n             union all \n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_week,\n                sample_week_start_date,\n                '40' as target_speed,\n                nullif(delay_40_mph, 0) as delay,\n                nullif(lost_productivity_40_mph, 0) as lost_productivity\n            from\n                weeklyc\n             union all \n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_week,\n                sample_week_start_date,\n                '45' as target_speed,\n                nullif(delay_45_mph, 0) as delay,\n                nullif(lost_productivity_45_mph, 0) as lost_productivity\n            from\n                weeklyc\n             union all \n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_week,\n                sample_week_start_date,\n                '50' as target_speed,\n                nullif(delay_50_mph, 0) as delay,\n                nullif(lost_productivity_50_mph, 0) as lost_productivity\n            from\n                weeklyc\n             union all \n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_week,\n                sample_week_start_date,\n                '55' as target_speed,\n                nullif(delay_55_mph, 0) as delay,\n                nullif(lost_productivity_55_mph, 0) as lost_productivity\n            from\n                weeklyc\n             union all \n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_week,\n                sample_week_start_date,\n                '60' as target_speed,\n                nullif(delay_60_mph, 0) as delay,\n                nullif(lost_productivity_60_mph, 0) as lost_productivity\n            from\n                weeklyc\n            \n        \n    ) as combined_metrics\n    where\n        city is not null\n    group by\n        city, city_abb, city_name, sample_week, sample_week_start_date, target_speed\n)\n\nselect * from unpivot_combined", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_unpivot_agg_weekly_city", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.584286Z", "completed_at": "2025-08-19T19:33:51.591324Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.597325Z", "completed_at": "2025-08-19T19:33:51.597333Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.02671957015991211, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_unpivot_agg_weekly_county", "compiled": true, "compiled_code": "\n\n-- read the volume, occupancy and speed weekly level data\nwith station_weekly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_weekly\n),\n\nweeklyc as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            station_weekly_data.*,\n            c.county_name,\n            c.county_abb\n        from station_weekly_data\n        inner join county as c\n        on station_weekly_data.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\nunpivot_combined as (\n    select\n        county,\n        county_abb,\n        county_name,\n        sample_week,\n        sample_week_start_date,\n        target_speed,\n        sum(coalesce(delay, 0)) as delay,\n        sum(coalesce(lost_productivity, 0)) as lost_productivity\n    from (\n        \n            select\n                county,\n                county_abb,\n                county_name,\n                sample_week,\n                sample_week_start_date,\n                '35' as target_speed,\n                nullif(delay_35_mph, 0) as delay,\n                nullif(lost_productivity_35_mph, 0) as lost_productivity\n            from\n                weeklyc\n             union all \n        \n            select\n                county,\n                county_abb,\n                county_name,\n                sample_week,\n                sample_week_start_date,\n                '40' as target_speed,\n                nullif(delay_40_mph, 0) as delay,\n                nullif(lost_productivity_40_mph, 0) as lost_productivity\n            from\n                weeklyc\n             union all \n        \n            select\n                county,\n                county_abb,\n                county_name,\n                sample_week,\n                sample_week_start_date,\n                '45' as target_speed,\n                nullif(delay_45_mph, 0) as delay,\n                nullif(lost_productivity_45_mph, 0) as lost_productivity\n            from\n                weeklyc\n             union all \n        \n            select\n                county,\n                county_abb,\n                county_name,\n                sample_week,\n                sample_week_start_date,\n                '50' as target_speed,\n                nullif(delay_50_mph, 0) as delay,\n                nullif(lost_productivity_50_mph, 0) as lost_productivity\n            from\n                weeklyc\n             union all \n        \n            select\n                county,\n                county_abb,\n                county_name,\n                sample_week,\n                sample_week_start_date,\n                '55' as target_speed,\n                nullif(delay_55_mph, 0) as delay,\n                nullif(lost_productivity_55_mph, 0) as lost_productivity\n            from\n                weeklyc\n             union all \n        \n            select\n                county,\n                county_abb,\n                county_name,\n                sample_week,\n                sample_week_start_date,\n                '60' as target_speed,\n                nullif(delay_60_mph, 0) as delay,\n                nullif(lost_productivity_60_mph, 0) as lost_productivity\n            from\n                weeklyc\n            \n        \n    ) as combined_metrics\n    group by\n        county, county_abb, county_name, sample_week, sample_week_start_date, target_speed\n)\n\nselect * from unpivot_combined", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_unpivot_agg_weekly_county", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.592591Z", "completed_at": "2025-08-19T19:33:51.600530Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.602712Z", "completed_at": "2025-08-19T19:33:51.602720Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.019208908081054688, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_unpivot_agg_weekly_district", "compiled": true, "compiled_code": "\n\n-- read the volume, occupancy and speed weekly level data\nwith station_weekly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_weekly\n),\n\nunpivot_combined as (\n    select\n        district,\n        sample_week,\n        sample_week_start_date,\n        target_speed,\n        sum(coalesce(delay, 0)) as delay,\n        sum(coalesce(lost_productivity, 0)) as lost_productivity\n    from (\n        \n            select\n                district,\n                sample_week,\n                sample_week_start_date,\n                '35' as target_speed,\n                nullif(delay_35_mph, 0) as delay,\n                nullif(lost_productivity_35_mph, 0) as lost_productivity\n            from\n                station_weekly_data\n             union all \n        \n            select\n                district,\n                sample_week,\n                sample_week_start_date,\n                '40' as target_speed,\n                nullif(delay_40_mph, 0) as delay,\n                nullif(lost_productivity_40_mph, 0) as lost_productivity\n            from\n                station_weekly_data\n             union all \n        \n            select\n                district,\n                sample_week,\n                sample_week_start_date,\n                '45' as target_speed,\n                nullif(delay_45_mph, 0) as delay,\n                nullif(lost_productivity_45_mph, 0) as lost_productivity\n            from\n                station_weekly_data\n             union all \n        \n            select\n                district,\n                sample_week,\n                sample_week_start_date,\n                '50' as target_speed,\n                nullif(delay_50_mph, 0) as delay,\n                nullif(lost_productivity_50_mph, 0) as lost_productivity\n            from\n                station_weekly_data\n             union all \n        \n            select\n                district,\n                sample_week,\n                sample_week_start_date,\n                '55' as target_speed,\n                nullif(delay_55_mph, 0) as delay,\n                nullif(lost_productivity_55_mph, 0) as lost_productivity\n            from\n                station_weekly_data\n             union all \n        \n            select\n                district,\n                sample_week,\n                sample_week_start_date,\n                '60' as target_speed,\n                nullif(delay_60_mph, 0) as delay,\n                nullif(lost_productivity_60_mph, 0) as lost_productivity\n            from\n                station_weekly_data\n            \n        \n    ) as combined_metrics\n    group by\n        district, sample_week, sample_week_start_date, target_speed\n)\n\nselect * from unpivot_combined", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_unpivot_agg_weekly_district", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.603493Z", "completed_at": "2025-08-19T19:33:51.617115Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.618954Z", "completed_at": "2025-08-19T19:33:51.618963Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.020241260528564453, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_performance__bottleneck_delay_metrics_agg_monthly", "compiled": true, "compiled_code": "\n\nwith station_daily_data as (\n    select\n        *,\n        -- Extracting first day of each month\n        -- reference: https://docs.snowflake.com/en/sql-reference/functions/year\n        date_trunc(month, sample_date) as sample_month\n    from ANALYTICS_PRD.performance.int_performance__bottleneck_delay_metrics_agg_daily\n    where date_trunc(month, sample_date) != date_trunc(month, current_date)\n),\n\nmonthly_spatial_bottleneck_delay_metrics as (\n    select\n        station_id,\n        sample_month,\n        time_shift,\n        any_value(district) as district,\n        any_value(county) as county,\n        any_value(station_type) as station_type,\n        any_value(freeway) as freeway,\n        any_value(direction) as direction,\n        any_value(absolute_postmile) as absolute_postmile,\n        avg(daily_time_shift_duration) as monthly_time_shift_duration,\n        sum(case when daily_time_shift_duration > 0 then 1 else 0 end) as monthly_active_days,\n        avg(daily_time_shift_bottleneck_extent) as monthly_time_shift_extent,\n        -- spatial delay aggregation in monthly level, decomposed into time shift\n        \n            sum(daily_time_shift_spatial_delay_35_mph)\n                as monthly_time_shift_spatial_delay_35_mph\n            \n                ,\n            \n        \n            sum(daily_time_shift_spatial_delay_40_mph)\n                as monthly_time_shift_spatial_delay_40_mph\n            \n                ,\n            \n        \n            sum(daily_time_shift_spatial_delay_45_mph)\n                as monthly_time_shift_spatial_delay_45_mph\n            \n                ,\n            \n        \n            sum(daily_time_shift_spatial_delay_50_mph)\n                as monthly_time_shift_spatial_delay_50_mph\n            \n                ,\n            \n        \n            sum(daily_time_shift_spatial_delay_55_mph)\n                as monthly_time_shift_spatial_delay_55_mph\n            \n                ,\n            \n        \n            sum(daily_time_shift_spatial_delay_60_mph)\n                as monthly_time_shift_spatial_delay_60_mph\n            \n        \n    from station_daily_data\n    group by station_id, sample_month, time_shift\n)\n\nselect * from monthly_spatial_bottleneck_delay_metrics", "relation_name": "ANALYTICS_PRD.performance.int_performance__bottleneck_delay_metrics_agg_monthly", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.608187Z", "completed_at": "2025-08-19T19:33:51.618389Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.620834Z", "completed_at": "2025-08-19T19:33:51.620846Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.020928382873535156, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.int_performance__bottleneck_delay_metrics_agg_weekly", "compiled": true, "compiled_code": "\n\nwith station_daily_data as (\n    select\n        *,\n        -- Extracting the start of each week\n        date_trunc(week, sample_date) as sample_week\n    from ANALYTICS_PRD.performance.int_performance__bottleneck_delay_metrics_agg_daily\n    where date_trunc(week, sample_date) != date_trunc(week, current_date)\n),\n\nweekly_spatial_bottleneck_delay_metrics as (\n    select\n        station_id,\n        sample_week,\n        time_shift,\n        any_value(district) as district,\n        any_value(county) as county,\n        any_value(station_type) as station_type,\n        any_value(freeway) as freeway,\n        any_value(direction) as direction,\n        any_value(absolute_postmile) as absolute_postmile,\n        avg(daily_time_shift_duration) as weekly_time_shift_duration,\n        sum(case when daily_time_shift_duration > 0 then 1 else 0 end) as weekly_active_days,\n        avg(daily_time_shift_bottleneck_extent) as weekly_time_shift_extent,\n        -- Spatial delay aggregation at weekly level, decomposed into time shift\n        \n            sum(daily_time_shift_spatial_delay_35_mph)\n                as weekly_time_shift_spatial_delay_35_mph\n            \n                ,\n            \n        \n            sum(daily_time_shift_spatial_delay_40_mph)\n                as weekly_time_shift_spatial_delay_40_mph\n            \n                ,\n            \n        \n            sum(daily_time_shift_spatial_delay_45_mph)\n                as weekly_time_shift_spatial_delay_45_mph\n            \n                ,\n            \n        \n            sum(daily_time_shift_spatial_delay_50_mph)\n                as weekly_time_shift_spatial_delay_50_mph\n            \n                ,\n            \n        \n            sum(daily_time_shift_spatial_delay_55_mph)\n                as weekly_time_shift_spatial_delay_55_mph\n            \n                ,\n            \n        \n            sum(daily_time_shift_spatial_delay_60_mph)\n                as weekly_time_shift_spatial_delay_60_mph\n            \n        \n    from station_daily_data\n    group by\n        station_id,\n        sample_week,\n        time_shift,\n        district,\n        county,\n        station_type,\n        freeway,\n        direction,\n        absolute_postmile\n)\n\nselect * from weekly_spatial_bottleneck_delay_metrics", "relation_name": "ANALYTICS_PRD.performance.int_performance__bottleneck_delay_metrics_agg_weekly", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.613095Z", "completed_at": "2025-08-19T19:33:51.620335Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.627026Z", "completed_at": "2025-08-19T19:33:51.627038Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.02556633949279785, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_bottleneck_agg_daily", "compiled": true, "compiled_code": "\n\n\nwith daily_bottleneck as (\n    select\n        station_id,\n        sample_date,\n        time_shift,\n        cast(district as int) as district,\n        station_type,\n        freeway,\n        direction,\n        absolute_postmile,\n        daily_time_shift_duration,\n        daily_time_shift_bottleneck_extent,\n        county\n    from ANALYTICS_PRD.performance.int_performance__bottleneck_delay_metrics_agg_daily\n),\n\nbottleneck_delay_with_county as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            daily_bottleneck.*,\n            c.county_name,\n            c.county_abb\n        from daily_bottleneck\n        inner join county as c\n        on daily_bottleneck.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\ngeo as (\n    select\n        station_id,\n        latitude,\n        longitude,\n        concat(longitude, ',', latitude) as location\n    from ANALYTICS_PRD.geo.geo__current_stations\n),\n\nbottleneck_delay_county_geo as (\n    select\n        bottleneck_delay_with_county.*,\n        geo.latitude,\n        geo.longitude,\n        geo.location\n    from\n        bottleneck_delay_with_county\n    inner join\n        geo\n        on bottleneck_delay_with_county.station_id = geo.station_id\n)\n\nselect * from bottleneck_delay_county_geo", "relation_name": "ANALYTICS_PRD.performance.performance__station_bottleneck_agg_daily", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.622164Z", "completed_at": "2025-08-19T19:33:51.629948Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.632099Z", "completed_at": "2025-08-19T19:33:51.632107Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.014383316040039062, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_bottleneck_unpivot_agg_daily", "compiled": true, "compiled_code": "\n\nwith daily_bottleneck_delay as (\n    select * from ANALYTICS_PRD.performance.int_performance__bottleneck_delay_metrics_agg_daily\n),\n\nunpivot_delay as (\n    select\n        station_id,\n        sample_date,\n        time_shift,\n        station_type,\n        district,\n        freeway,\n        direction,\n        absolute_postmile,\n        county,\n        target_speed,\n        sum(coalesce(delay, 0)) as delay\n    from (\n        \n            select\n                station_id,\n                sample_date,\n                time_shift,\n                station_type,\n                district,\n                freeway,\n                direction,\n                absolute_postmile,\n                county,\n                '35' as target_speed,\n                daily_time_shift_spatial_delay_35_mph as delay\n            from\n                daily_bottleneck_delay\n             union all \n        \n            select\n                station_id,\n                sample_date,\n                time_shift,\n                station_type,\n                district,\n                freeway,\n                direction,\n                absolute_postmile,\n                county,\n                '40' as target_speed,\n                daily_time_shift_spatial_delay_40_mph as delay\n            from\n                daily_bottleneck_delay\n             union all \n        \n            select\n                station_id,\n                sample_date,\n                time_shift,\n                station_type,\n                district,\n                freeway,\n                direction,\n                absolute_postmile,\n                county,\n                '45' as target_speed,\n                daily_time_shift_spatial_delay_45_mph as delay\n            from\n                daily_bottleneck_delay\n             union all \n        \n            select\n                station_id,\n                sample_date,\n                time_shift,\n                station_type,\n                district,\n                freeway,\n                direction,\n                absolute_postmile,\n                county,\n                '50' as target_speed,\n                daily_time_shift_spatial_delay_50_mph as delay\n            from\n                daily_bottleneck_delay\n             union all \n        \n            select\n                station_id,\n                sample_date,\n                time_shift,\n                station_type,\n                district,\n                freeway,\n                direction,\n                absolute_postmile,\n                county,\n                '55' as target_speed,\n                daily_time_shift_spatial_delay_55_mph as delay\n            from\n                daily_bottleneck_delay\n             union all \n        \n            select\n                station_id,\n                sample_date,\n                time_shift,\n                station_type,\n                district,\n                freeway,\n                direction,\n                absolute_postmile,\n                county,\n                '60' as target_speed,\n                daily_time_shift_spatial_delay_60_mph as delay\n            from\n                daily_bottleneck_delay\n            \n        \n    ) as combined_metrics\n    group by\n        station_id,\n        sample_date,\n        time_shift,\n        station_type,\n        district,\n        freeway,\n        direction,\n        absolute_postmile,\n        county,\n        target_speed\n),\n\nbottleneck_delay_with_county as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            unpivot_delay.*,\n            c.county_name,\n            c.county_abb\n        from unpivot_delay\n        inner join county as c\n        on unpivot_delay.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\ngeo as (\n    select\n        station_id,\n        latitude,\n        longitude,\n        concat(longitude, ',', latitude) as location\n    from ANALYTICS_PRD.geo.geo__current_stations\n),\n\nbottleneck_delay_county_geo as (\n    select\n        bottleneck_delay_with_county.*,\n        geo.latitude,\n        geo.longitude,\n        geo.location\n    from\n        bottleneck_delay_with_county\n    inner join\n        geo\n        on bottleneck_delay_with_county.station_id = geo.station_id\n)\n\nselect * from bottleneck_delay_county_geo", "relation_name": "ANALYTICS_PRD.performance.performance__station_bottleneck_unpivot_agg_daily", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.633405Z", "completed_at": "2025-08-19T19:33:51.648427Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.649597Z", "completed_at": "2025-08-19T19:33:51.649606Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.02118372917175293, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_agg_yearly", "compiled": true, "compiled_code": "\n\nwith yearly as (\n    select\n        station_id,\n        sample_year,\n        length,\n        station_type,\n        district,\n        city,\n        freeway,\n        direction,\n        yearly_volume,\n        yearly_occupancy,\n        yearly_speed,\n        yearly_vmt,\n        yearly_vht,\n        yearly_q_value,\n        yearly_tti,\n        county\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_yearly\n),\n\nyearlyc as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            yearly.*,\n            c.county_name,\n            c.county_abb\n        from yearly\n        inner join county as c\n        on yearly.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\nyearlycc as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from yearlyc as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n)\n\nselect * from yearlycc", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_agg_yearly", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.638526Z", "completed_at": "2025-08-19T19:33:51.650409Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.655257Z", "completed_at": "2025-08-19T19:33:51.655269Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.02491474151611328, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_agg_yearly_city", "compiled": true, "compiled_code": "\n\n-- read the volume, occupancy and speed yearly level data\nwith station_yearly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_yearly\n),\n\n-- now aggregate yearly volume, occupancy and speed to yearly\nspatial_metrics as (\n    select\n        city,\n        sample_year,\n        sum(yearly_volume) as yearly_volume_sum,\n        avg(yearly_occupancy) as yearly_occupancy_avg,\n        sum(yearly_volume * yearly_speed) / nullifzero(sum(yearly_volume)) as yearly_speed_avg,\n        sum(yearly_vmt) as yearly_vmt,\n        sum(yearly_vht) as yearly_vht,\n        sum(yearly_vmt) / nullifzero(sum(yearly_vht)) as yearly_q_value,\n        -- travel time\n        60 / nullifzero(sum(yearly_q_value)) as yearly_tti\n    from station_yearly_data\n    where\n        city is not null\n    group by\n        city, sample_year\n),\n\nyearlyc as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from spatial_metrics as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n)\n\nselect * from yearlyc", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_agg_yearly_city", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.642095Z", "completed_at": "2025-08-19T19:33:51.654091Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.656179Z", "completed_at": "2025-08-19T19:33:51.656187Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.024707317352294922, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_agg_yearly_county", "compiled": true, "compiled_code": "\n\n-- read the volume, occupancy and speed daily level data\n-- read the volume, occupancy and speed yearly level data\nwith station_yearly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_yearly\n),\n\n-- now aggregate yearly volume, occupancy and speed to yearly\nspatial_metrics as (\n    select\n        county,\n        sample_year,\n        sum(yearly_volume) as yearly_volume_sum,\n        avg(yearly_occupancy) as yearly_occupancy_avg,\n        sum(yearly_volume * yearly_speed) / nullifzero(sum(yearly_volume)) as yearly_speed_avg,\n        sum(yearly_vmt) as yearly_vmt,\n        sum(yearly_vht) as yearly_vht,\n        sum(yearly_vmt) / nullifzero(sum(yearly_vht)) as yearly_q_value,\n        -- travel time\n        60 / nullifzero(sum(yearly_q_value)) as yearly_tti\n    from station_yearly_data\n    group by\n        county, sample_year\n),\n\nspatial_metricsc as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            spatial_metrics.*,\n            c.county_name,\n            c.county_abb\n        from spatial_metrics\n        inner join county as c\n        on spatial_metrics.county = c.county_id\n    )\n\n    select * from station_with_county\n\n)\n\nselect * from spatial_metricsc", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_agg_yearly_county", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.650943Z", "completed_at": "2025-08-19T19:33:51.658085Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.660280Z", "completed_at": "2025-08-19T19:33:51.660288Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.013169527053833008, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_agg_yearly_district", "compiled": true, "compiled_code": "\n\n-- read the volume, occupancy and speed yearly level data\nwith station_yearly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_yearly\n),\n\n-- now aggregate yearly volume, occupancy and speed to yearly\nspatial_metrics as (\n    select\n        district,\n        sample_year,\n        sum(yearly_volume) as yearly_volume_sum,\n        avg(yearly_occupancy) as yearly_occupancy_avg,\n        sum(yearly_volume * yearly_speed) / nullifzero(sum(yearly_volume)) as yearly_speed_avg,\n        sum(yearly_vmt) as yearly_vmt,\n        sum(yearly_vht) as yearly_vht,\n        sum(yearly_vmt) / nullifzero(sum(yearly_vht)) as yearly_q_value,\n        -- travel time\n        60 / nullifzero(sum(yearly_q_value)) as yearly_tti\n    from station_yearly_data\n    group by\n        district, sample_year\n)\n\nselect * from spatial_metrics", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_agg_yearly_district", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.661639Z", "completed_at": "2025-08-19T19:33:51.673242Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.680996Z", "completed_at": "2025-08-19T19:33:51.681009Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.024118900299072266, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_unpivot_agg_yearly", "compiled": true, "compiled_code": "\n\nwith yearly as (\n    select * from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_yearly\n),\n\nyearlyc as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            yearly.*,\n            c.county_name,\n            c.county_abb\n        from yearly\n        inner join county as c\n        on yearly.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\nyearlycc as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from yearlyc as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n),\n\nunpivot_combined as (\n    select\n        station_id,\n        sample_year,\n        length,\n        station_type,\n        district,\n        city,\n        city_abb,\n        city_name,\n        freeway,\n        direction,\n        county,\n        county_abb,\n        county_name,\n        target_speed,\n        sum(coalesce(delay, 0)) as delay,\n        sum(coalesce(lost_productivity, 0)) as lost_productivity\n    from (\n        \n            select\n                station_id,\n                sample_year,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_abb,\n                county_name,\n                '35' as target_speed,\n                delay_35_mph as delay,\n                lost_productivity_35_mph as lost_productivity\n            from\n                yearlycc\n             union all \n        \n            select\n                station_id,\n                sample_year,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_abb,\n                county_name,\n                '40' as target_speed,\n                delay_40_mph as delay,\n                lost_productivity_40_mph as lost_productivity\n            from\n                yearlycc\n             union all \n        \n            select\n                station_id,\n                sample_year,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_abb,\n                county_name,\n                '45' as target_speed,\n                delay_45_mph as delay,\n                lost_productivity_45_mph as lost_productivity\n            from\n                yearlycc\n             union all \n        \n            select\n                station_id,\n                sample_year,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_abb,\n                county_name,\n                '50' as target_speed,\n                delay_50_mph as delay,\n                lost_productivity_50_mph as lost_productivity\n            from\n                yearlycc\n             union all \n        \n            select\n                station_id,\n                sample_year,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_abb,\n                county_name,\n                '55' as target_speed,\n                delay_55_mph as delay,\n                lost_productivity_55_mph as lost_productivity\n            from\n                yearlycc\n             union all \n        \n            select\n                station_id,\n                sample_year,\n                length,\n                station_type,\n                district,\n                city,\n                city_abb,\n                city_name,\n                freeway,\n                direction,\n                county,\n                county_abb,\n                county_name,\n                '60' as target_speed,\n                delay_60_mph as delay,\n                lost_productivity_60_mph as lost_productivity\n            from\n                yearlycc\n            \n        \n    ) as combined_metrics\n    group by\n        sample_year,\n        station_id,\n        length,\n        station_type,\n        district,\n        city,\n        city_abb,\n        city_name,\n        freeway,\n        direction,\n        county,\n        county_abb,\n        county_name,\n        target_speed\n)\n\nselect * from unpivot_combined", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_unpivot_agg_yearly", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.668243Z", "completed_at": "2025-08-19T19:33:51.680499Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.687338Z", "completed_at": "2025-08-19T19:33:51.687349Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.027695178985595703, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_unpivot_agg_yearly_city", "compiled": true, "compiled_code": "\n\n-- read the volume, occupancy and speed yearly level data\nwith station_yearly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_yearly\n),\n\nyearlyc as (\n    \n    with city as (\n        select\n            city_id,\n            city_name,\n            native_id\n        from ANALYTICS_PRD.analytics.cities\n    ),\n    station_with_city_id as (\n        select\n            st.*,\n            c.city_name,\n            c.native_id as city_abb\n        from station_yearly_data as st\n        inner join city as c\n        on st.city = c.city_id\n    )\n\n    select * from station_with_city_id\n\n),\n\nunpivot_combined as (\n    select\n        city,\n        city_abb,\n        city_name,\n        sample_year,\n        target_speed,\n        sum(coalesce(delay, 0)) as delay,\n        sum(coalesce(lost_productivity, 0)) as lost_productivity\n    from (\n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_year,\n                '35' as target_speed,\n                nullif(delay_35_mph, 0) as delay,\n                nullif(lost_productivity_35_mph, 0) as lost_productivity\n            from\n                yearlyc\n             union all \n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_year,\n                '40' as target_speed,\n                nullif(delay_40_mph, 0) as delay,\n                nullif(lost_productivity_40_mph, 0) as lost_productivity\n            from\n                yearlyc\n             union all \n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_year,\n                '45' as target_speed,\n                nullif(delay_45_mph, 0) as delay,\n                nullif(lost_productivity_45_mph, 0) as lost_productivity\n            from\n                yearlyc\n             union all \n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_year,\n                '50' as target_speed,\n                nullif(delay_50_mph, 0) as delay,\n                nullif(lost_productivity_50_mph, 0) as lost_productivity\n            from\n                yearlyc\n             union all \n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_year,\n                '55' as target_speed,\n                nullif(delay_55_mph, 0) as delay,\n                nullif(lost_productivity_55_mph, 0) as lost_productivity\n            from\n                yearlyc\n             union all \n        \n            select\n                city,\n                city_abb,\n                city_name,\n                sample_year,\n                '60' as target_speed,\n                nullif(delay_60_mph, 0) as delay,\n                nullif(lost_productivity_60_mph, 0) as lost_productivity\n            from\n                yearlyc\n            \n        \n    ) as combined_metrics\n    where\n        city is not null\n    group by\n        city, city_abb, city_name, sample_year, target_speed\n)\n\nselect * from unpivot_combined", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_unpivot_agg_yearly_city", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.673906Z", "completed_at": "2025-08-19T19:33:51.688120Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.690363Z", "completed_at": "2025-08-19T19:33:51.690374Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.0294036865234375, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_unpivot_agg_yearly_county", "compiled": true, "compiled_code": "\n\n-- read the volume, occupancy and speed yearly level data\nwith station_yearly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_yearly\n),\n\n-- now aggregate daily volume, occupancy and speed to weekly\nspatial_metrics as (\n    select\n        county,\n        sample_year,\n        \n            sum(delay_35_mph) as delay_35_mph,\n            sum(lost_productivity_35_mph) as lost_productivity_35_mph\n            \n                ,\n            \n        \n            sum(delay_40_mph) as delay_40_mph,\n            sum(lost_productivity_40_mph) as lost_productivity_40_mph\n            \n                ,\n            \n        \n            sum(delay_45_mph) as delay_45_mph,\n            sum(lost_productivity_45_mph) as lost_productivity_45_mph\n            \n                ,\n            \n        \n            sum(delay_50_mph) as delay_50_mph,\n            sum(lost_productivity_50_mph) as lost_productivity_50_mph\n            \n                ,\n            \n        \n            sum(delay_55_mph) as delay_55_mph,\n            sum(lost_productivity_55_mph) as lost_productivity_55_mph\n            \n                ,\n            \n        \n            sum(delay_60_mph) as delay_60_mph,\n            sum(lost_productivity_60_mph) as lost_productivity_60_mph\n            \n        \n    from station_yearly_data\n    group by\n        county, sample_year\n),\n\nunpivot_metrics as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            spatial_metrics.*,\n            c.county_name,\n            c.county_abb\n        from spatial_metrics\n        inner join county as c\n        on spatial_metrics.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\nunpivot_combined as (\n    select\n        county,\n        sample_year,\n        target_speed,\n        sum(coalesce(delay, 0)) as delay,\n        sum(coalesce(lost_productivity, 0)) as lost_productivity\n    from (\n        \n            select\n                county,\n                sample_year,\n                '35' as target_speed,\n                nullif(delay_35_mph, 0) as delay,\n                nullif(lost_productivity_35_mph, 0) as lost_productivity\n            from\n                unpivot_metrics\n             union all \n        \n            select\n                county,\n                sample_year,\n                '40' as target_speed,\n                nullif(delay_40_mph, 0) as delay,\n                nullif(lost_productivity_40_mph, 0) as lost_productivity\n            from\n                unpivot_metrics\n             union all \n        \n            select\n                county,\n                sample_year,\n                '45' as target_speed,\n                nullif(delay_45_mph, 0) as delay,\n                nullif(lost_productivity_45_mph, 0) as lost_productivity\n            from\n                unpivot_metrics\n             union all \n        \n            select\n                county,\n                sample_year,\n                '50' as target_speed,\n                nullif(delay_50_mph, 0) as delay,\n                nullif(lost_productivity_50_mph, 0) as lost_productivity\n            from\n                unpivot_metrics\n             union all \n        \n            select\n                county,\n                sample_year,\n                '55' as target_speed,\n                nullif(delay_55_mph, 0) as delay,\n                nullif(lost_productivity_55_mph, 0) as lost_productivity\n            from\n                unpivot_metrics\n             union all \n        \n            select\n                county,\n                sample_year,\n                '60' as target_speed,\n                nullif(delay_60_mph, 0) as delay,\n                nullif(lost_productivity_60_mph, 0) as lost_productivity\n            from\n                unpivot_metrics\n            \n        \n    ) as combined_metrics\n    group by\n        county, sample_year, target_speed\n),\n\nunpivot_combinedc as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            unpivot_combined.*,\n            c.county_name,\n            c.county_abb\n        from unpivot_combined\n        inner join county as c\n        on unpivot_combined.county = c.county_id\n    )\n\n    select * from station_with_county\n\n)\n\nselect * from unpivot_combinedc", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_unpivot_agg_yearly_county", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.681924Z", "completed_at": "2025-08-19T19:33:51.691105Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.693256Z", "completed_at": "2025-08-19T19:33:51.693264Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.02062702178955078, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_metrics_unpivot_agg_yearly_district", "compiled": true, "compiled_code": "\n\n-- read the volume, occupancy and speed yearly level data\nwith station_yearly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_yearly\n),\n\n-- aggregate delay and productivity by sample year\nspatial_metrics as (\n    select\n        district,\n        sample_year,\n        \n            sum(delay_35_mph) as delay_35_mph,\n            sum(lost_productivity_35_mph) as lost_productivity_35_mph\n            \n                ,\n            \n        \n            sum(delay_40_mph) as delay_40_mph,\n            sum(lost_productivity_40_mph) as lost_productivity_40_mph\n            \n                ,\n            \n        \n            sum(delay_45_mph) as delay_45_mph,\n            sum(lost_productivity_45_mph) as lost_productivity_45_mph\n            \n                ,\n            \n        \n            sum(delay_50_mph) as delay_50_mph,\n            sum(lost_productivity_50_mph) as lost_productivity_50_mph\n            \n                ,\n            \n        \n            sum(delay_55_mph) as delay_55_mph,\n            sum(lost_productivity_55_mph) as lost_productivity_55_mph\n            \n                ,\n            \n        \n            sum(delay_60_mph) as delay_60_mph,\n            sum(lost_productivity_60_mph) as lost_productivity_60_mph\n            \n        \n    from station_yearly_data\n    group by\n        district, sample_year\n),\n\nunpivot_combined as (\n    select\n        district,\n        sample_year,\n        target_speed,\n        sum(coalesce(delay, 0)) as delay,\n        sum(coalesce(lost_productivity, 0)) as lost_productivity\n    from (\n        \n            select\n                district,\n                sample_year,\n                '35' as target_speed,\n                nullif(delay_35_mph, 0) as delay,\n                nullif(lost_productivity_35_mph, 0) as lost_productivity\n            from\n                spatial_metrics\n             union all \n        \n            select\n                district,\n                sample_year,\n                '40' as target_speed,\n                nullif(delay_40_mph, 0) as delay,\n                nullif(lost_productivity_40_mph, 0) as lost_productivity\n            from\n                spatial_metrics\n             union all \n        \n            select\n                district,\n                sample_year,\n                '45' as target_speed,\n                nullif(delay_45_mph, 0) as delay,\n                nullif(lost_productivity_45_mph, 0) as lost_productivity\n            from\n                spatial_metrics\n             union all \n        \n            select\n                district,\n                sample_year,\n                '50' as target_speed,\n                nullif(delay_50_mph, 0) as delay,\n                nullif(lost_productivity_50_mph, 0) as lost_productivity\n            from\n                spatial_metrics\n             union all \n        \n            select\n                district,\n                sample_year,\n                '55' as target_speed,\n                nullif(delay_55_mph, 0) as delay,\n                nullif(lost_productivity_55_mph, 0) as lost_productivity\n            from\n                spatial_metrics\n             union all \n        \n            select\n                district,\n                sample_year,\n                '60' as target_speed,\n                nullif(delay_60_mph, 0) as delay,\n                nullif(lost_productivity_60_mph, 0) as lost_productivity\n            from\n                spatial_metrics\n            \n        \n    ) as combined_metrics\n    group by\n        district, sample_year, target_speed\n)\n\nselect * from unpivot_combined", "relation_name": "ANALYTICS_PRD.performance.performance__station_metrics_unpivot_agg_yearly_district", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.701269Z", "completed_at": "2025-08-19T19:33:51.707238Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.713620Z", "completed_at": "2025-08-19T19:33:51.713630Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.021546363830566406, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_bottleneck_agg_monthly", "compiled": true, "compiled_code": "\n\nwith monthly_bottleneck as (\n    select\n        station_id,\n        sample_month,\n        time_shift,\n        cast(district as int) as district,\n        station_type,\n        freeway,\n        direction,\n        absolute_postmile,\n        monthly_active_days,\n        monthly_time_shift_duration,\n        monthly_time_shift_extent,\n        county\n    from ANALYTICS_PRD.performance.int_performance__bottleneck_delay_metrics_agg_monthly\n),\n\nbottleneck_delay_with_county as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            monthly_bottleneck.*,\n            c.county_name,\n            c.county_abb\n        from monthly_bottleneck\n        inner join county as c\n        on monthly_bottleneck.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\ngeo as (\n    select\n        station_id,\n        latitude,\n        longitude,\n        concat(longitude, ',', latitude) as location\n    from ANALYTICS_PRD.geo.geo__current_stations\n),\n\nbottleneck_delay_county_geo as (\n    select\n        bottleneck_delay_with_county.*,\n        geo.latitude,\n        geo.longitude,\n        geo.location\n    from\n        bottleneck_delay_with_county\n    inner join\n        geo\n        on bottleneck_delay_with_county.station_id = geo.station_id\n)\n\nselect * from bottleneck_delay_county_geo", "relation_name": "ANALYTICS_PRD.performance.performance__station_bottleneck_agg_monthly", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.696156Z", "completed_at": "2025-08-19T19:33:51.712565Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.714536Z", "completed_at": "2025-08-19T19:33:51.714545Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.0229794979095459, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__unpivot_agg_yearly_freeway_type_direction", "compiled": true, "compiled_code": "\n\n-- read the volume, occupancy and speed daily level data\nwith station_yearly_data as (\n    select *\n    from ANALYTICS_PRD.performance.int_performance__station_metrics_agg_yearly\n),\n\n-- now aggregate daily volume, occupancy and speed to weekly\nspatial_metrics as (\n    select\n        sample_year,\n        station_type,\n        freeway,\n        direction,\n        \n            sum(delay_35_mph) as delay_35_mph,\n            sum(lost_productivity_35_mph) as lost_productivity_35_mph\n            \n                ,\n            \n        \n            sum(delay_40_mph) as delay_40_mph,\n            sum(lost_productivity_40_mph) as lost_productivity_40_mph\n            \n                ,\n            \n        \n            sum(delay_45_mph) as delay_45_mph,\n            sum(lost_productivity_45_mph) as lost_productivity_45_mph\n            \n                ,\n            \n        \n            sum(delay_50_mph) as delay_50_mph,\n            sum(lost_productivity_50_mph) as lost_productivity_50_mph\n            \n                ,\n            \n        \n            sum(delay_55_mph) as delay_55_mph,\n            sum(lost_productivity_55_mph) as lost_productivity_55_mph\n            \n                ,\n            \n        \n            sum(delay_60_mph) as delay_60_mph,\n            sum(lost_productivity_60_mph) as lost_productivity_60_mph\n            \n        \n    from station_yearly_data\n    group by\n        sample_year, freeway, station_type, direction\n),\n\nunpivot_combined as (\n    select\n        station_type,\n        freeway,\n        direction,\n        sample_year,\n        target_speed,\n        sum(coalesce(delay, 0)) as delay,\n        sum(coalesce(lost_productivity, 0)) as lost_productivity\n    from (\n        \n            select\n                station_type,\n                freeway,\n                direction,\n                sample_year,\n                '35' as target_speed,\n                nullif(delay_35_mph, 0) as delay,\n                nullif(lost_productivity_35_mph, 0) as lost_productivity\n            from\n                spatial_metrics\n             union all \n        \n            select\n                station_type,\n                freeway,\n                direction,\n                sample_year,\n                '40' as target_speed,\n                nullif(delay_40_mph, 0) as delay,\n                nullif(lost_productivity_40_mph, 0) as lost_productivity\n            from\n                spatial_metrics\n             union all \n        \n            select\n                station_type,\n                freeway,\n                direction,\n                sample_year,\n                '45' as target_speed,\n                nullif(delay_45_mph, 0) as delay,\n                nullif(lost_productivity_45_mph, 0) as lost_productivity\n            from\n                spatial_metrics\n             union all \n        \n            select\n                station_type,\n                freeway,\n                direction,\n                sample_year,\n                '50' as target_speed,\n                nullif(delay_50_mph, 0) as delay,\n                nullif(lost_productivity_50_mph, 0) as lost_productivity\n            from\n                spatial_metrics\n             union all \n        \n            select\n                station_type,\n                freeway,\n                direction,\n                sample_year,\n                '55' as target_speed,\n                nullif(delay_55_mph, 0) as delay,\n                nullif(lost_productivity_55_mph, 0) as lost_productivity\n            from\n                spatial_metrics\n             union all \n        \n            select\n                station_type,\n                freeway,\n                direction,\n                sample_year,\n                '60' as target_speed,\n                nullif(delay_60_mph, 0) as delay,\n                nullif(lost_productivity_60_mph, 0) as lost_productivity\n            from\n                spatial_metrics\n            \n        \n    ) as combined_metrics\n    group by\n        sample_year, freeway, station_type, direction, target_speed\n)\n\nselect * from unpivot_combined", "relation_name": "ANALYTICS_PRD.performance.performance__unpivot_agg_yearly_freeway_type_direction", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.707828Z", "completed_at": "2025-08-19T19:33:51.720597Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.722706Z", "completed_at": "2025-08-19T19:33:51.722715Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.02773141860961914, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_bottleneck_unpivot_agg_monthly", "compiled": true, "compiled_code": "\n\nwith monthly_bottleneck_delay as (\n    select * from ANALYTICS_PRD.performance.int_performance__bottleneck_delay_metrics_agg_monthly\n),\n\nunpivot_delay as (\n    select\n        station_id,\n        sample_month,\n        time_shift,\n        station_type,\n        cast(district as int) as district,\n        freeway,\n        direction,\n        absolute_postmile,\n        county,\n        target_speed,\n        sum(coalesce(delay, 0)) as delay\n    from (\n        \n            select\n                station_id,\n                sample_month,\n                time_shift,\n                station_type,\n                district,\n                freeway,\n                direction,\n                absolute_postmile,\n                county,\n                '35' as target_speed,\n                monthly_time_shift_spatial_delay_35_mph as delay\n            from\n                monthly_bottleneck_delay\n             union all \n        \n            select\n                station_id,\n                sample_month,\n                time_shift,\n                station_type,\n                district,\n                freeway,\n                direction,\n                absolute_postmile,\n                county,\n                '40' as target_speed,\n                monthly_time_shift_spatial_delay_40_mph as delay\n            from\n                monthly_bottleneck_delay\n             union all \n        \n            select\n                station_id,\n                sample_month,\n                time_shift,\n                station_type,\n                district,\n                freeway,\n                direction,\n                absolute_postmile,\n                county,\n                '45' as target_speed,\n                monthly_time_shift_spatial_delay_45_mph as delay\n            from\n                monthly_bottleneck_delay\n             union all \n        \n            select\n                station_id,\n                sample_month,\n                time_shift,\n                station_type,\n                district,\n                freeway,\n                direction,\n                absolute_postmile,\n                county,\n                '50' as target_speed,\n                monthly_time_shift_spatial_delay_50_mph as delay\n            from\n                monthly_bottleneck_delay\n             union all \n        \n            select\n                station_id,\n                sample_month,\n                time_shift,\n                station_type,\n                district,\n                freeway,\n                direction,\n                absolute_postmile,\n                county,\n                '55' as target_speed,\n                monthly_time_shift_spatial_delay_55_mph as delay\n            from\n                monthly_bottleneck_delay\n             union all \n        \n            select\n                station_id,\n                sample_month,\n                time_shift,\n                station_type,\n                district,\n                freeway,\n                direction,\n                absolute_postmile,\n                county,\n                '60' as target_speed,\n                monthly_time_shift_spatial_delay_60_mph as delay\n            from\n                monthly_bottleneck_delay\n            \n        \n    ) as combined_metrics\n    group by\n        station_id,\n        sample_month,\n        time_shift,\n        station_type,\n        district,\n        freeway,\n        direction,\n        absolute_postmile,\n        county,\n        target_speed\n),\n\nbottleneck_delay_with_county as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            unpivot_delay.*,\n            c.county_name,\n            c.county_abb\n        from unpivot_delay\n        inner join county as c\n        on unpivot_delay.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\ngeo as (\n    select\n        station_id,\n        latitude,\n        longitude,\n        concat(longitude, ',', latitude) as location\n    from ANALYTICS_PRD.geo.geo__current_stations\n),\n\nbottleneck_delay_county_geo as (\n    select\n        bottleneck_delay_with_county.*,\n        geo.latitude,\n        geo.longitude,\n        geo.location\n    from\n        bottleneck_delay_with_county\n    inner join\n        geo\n        on bottleneck_delay_with_county.station_id = geo.station_id\n)\n\nselect * from bottleneck_delay_county_geo", "relation_name": "ANALYTICS_PRD.performance.performance__station_bottleneck_unpivot_agg_monthly", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.715359Z", "completed_at": "2025-08-19T19:33:51.729538Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.730128Z", "completed_at": "2025-08-19T19:33:51.730136Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.023749589920043945, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_bottleneck_agg_weekly", "compiled": true, "compiled_code": "\n\nwith weekly_bottleneck_delay as (\n    select\n        station_id,\n        sample_week,\n        time_shift,\n        cast(district as int) as district,\n        station_type,\n        freeway,\n        direction,\n        absolute_postmile,\n        weekly_time_shift_duration,\n        weekly_active_days,\n        weekly_time_shift_extent,\n        county\n    from ANALYTICS_PRD.performance.int_performance__bottleneck_delay_metrics_agg_weekly\n),\n\nbottleneck_delay_with_county as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            weekly_bottleneck_delay.*,\n            c.county_name,\n            c.county_abb\n        from weekly_bottleneck_delay\n        inner join county as c\n        on weekly_bottleneck_delay.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\ngeo as (\n    select\n        station_id,\n        latitude,\n        longitude,\n        concat(longitude, ',', latitude) as location\n    from ANALYTICS_PRD.geo.geo__current_stations\n),\n\nbottleneck_delay_county_geo as (\n    select\n        bottleneck_delay_with_county.*,\n        geo.latitude,\n        geo.longitude,\n        geo.location\n    from\n        bottleneck_delay_with_county\n    inner join\n        geo\n        on bottleneck_delay_with_county.station_id = geo.station_id\n)\n\nselect * from bottleneck_delay_county_geo", "relation_name": "ANALYTICS_PRD.performance.performance__station_bottleneck_agg_weekly", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-08-19T19:33:51.724761Z", "completed_at": "2025-08-19T19:33:51.730971Z"}, {"name": "execute", "started_at": "2025-08-19T19:33:51.731541Z", "completed_at": "2025-08-19T19:33:51.731549Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.008043289184570312, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.caldata_mdsa_caltrans_pems.performance__station_bottleneck_unpivot_agg_weekly", "compiled": true, "compiled_code": "\n\nwith weekly_bottleneck_delay as (\n    select * from ANALYTICS_PRD.performance.int_performance__bottleneck_delay_metrics_agg_weekly\n),\n\nunpivot_delay as (\n    select\n        station_id,\n        sample_week,\n        time_shift,\n        station_type,\n        cast(district as int) as district,\n        freeway,\n        direction,\n        absolute_postmile,\n        county,\n        target_speed,\n        sum(coalesce(delay, 0)) as delay\n    from (\n        \n            select\n                station_id,\n                sample_week,\n                time_shift,\n                station_type,\n                district,\n                freeway,\n                direction,\n                absolute_postmile,\n                county,\n                '35' as target_speed,\n                weekly_time_shift_spatial_delay_35_mph as delay\n            from\n                weekly_bottleneck_delay\n             union all \n        \n            select\n                station_id,\n                sample_week,\n                time_shift,\n                station_type,\n                district,\n                freeway,\n                direction,\n                absolute_postmile,\n                county,\n                '40' as target_speed,\n                weekly_time_shift_spatial_delay_40_mph as delay\n            from\n                weekly_bottleneck_delay\n             union all \n        \n            select\n                station_id,\n                sample_week,\n                time_shift,\n                station_type,\n                district,\n                freeway,\n                direction,\n                absolute_postmile,\n                county,\n                '45' as target_speed,\n                weekly_time_shift_spatial_delay_45_mph as delay\n            from\n                weekly_bottleneck_delay\n             union all \n        \n            select\n                station_id,\n                sample_week,\n                time_shift,\n                station_type,\n                district,\n                freeway,\n                direction,\n                absolute_postmile,\n                county,\n                '50' as target_speed,\n                weekly_time_shift_spatial_delay_50_mph as delay\n            from\n                weekly_bottleneck_delay\n             union all \n        \n            select\n                station_id,\n                sample_week,\n                time_shift,\n                station_type,\n                district,\n                freeway,\n                direction,\n                absolute_postmile,\n                county,\n                '55' as target_speed,\n                weekly_time_shift_spatial_delay_55_mph as delay\n            from\n                weekly_bottleneck_delay\n             union all \n        \n            select\n                station_id,\n                sample_week,\n                time_shift,\n                station_type,\n                district,\n                freeway,\n                direction,\n                absolute_postmile,\n                county,\n                '60' as target_speed,\n                weekly_time_shift_spatial_delay_60_mph as delay\n            from\n                weekly_bottleneck_delay\n            \n        \n    ) as combined_metrics\n    group by\n        station_id,\n        sample_week,\n        time_shift,\n        station_type,\n        district,\n        freeway,\n        direction,\n        absolute_postmile,\n        county,\n        target_speed\n),\n\nbottleneck_delay_with_county as (\n    \n    with county as (\n        select\n            county_id,\n            lower(county_name) as county_name,\n            native_id as county_abb\n        from ANALYTICS_PRD.clearinghouse.counties\n    ),\n    station_with_county as (\n        select\n            unpivot_delay.*,\n            c.county_name,\n            c.county_abb\n        from unpivot_delay\n        inner join county as c\n        on unpivot_delay.county = c.county_id\n    )\n\n    select * from station_with_county\n\n),\n\ngeo as (\n    select\n        station_id,\n        latitude,\n        longitude,\n        concat(longitude, ',', latitude) as location\n    from ANALYTICS_PRD.geo.geo__current_stations\n),\n\nbottleneck_delay_county_geo as (\n    select\n        bottleneck_delay_with_county.*,\n        geo.latitude,\n        geo.longitude,\n        geo.location\n    from\n        bottleneck_delay_with_county\n    inner join\n        geo\n        on bottleneck_delay_with_county.station_id = geo.station_id\n)\n\nselect * from bottleneck_delay_county_geo", "relation_name": "ANALYTICS_PRD.performance.performance__station_bottleneck_unpivot_agg_weekly", "batch_results": null}], "elapsed_time": 7.2990899085998535, "args": {"profiles_dir": "transform/ci", "partial_parse_file_diff": true, "printer_width": 80, "require_nested_cumulative_type_params": false, "require_resource_names_without_spaces": true, "indirect_selection": "eager", "state_modified_compare_vars": false, "require_batched_execution_for_custom_microbatch_strategy": false, "favor_state": false, "project_dir": "transform", "strict_mode": false, "populate_cache": true, "require_explicit_package_overrides_for_builtin_materializations": true, "introspect": true, "skip_nodes_if_on_run_start_fails": true, "validate_macro_args": false, "show_resource_report": false, "write_json": true, "state_modified_compare_more_unrendered_values": true, "log_file_max_bytes": 10485760, "target": "prd", "select": [], "require_all_warnings_handled_by_warn_error": false, "exclude": [], "use_fast_test_edges": false, "upload_to_artifacts_ingest_api": false, "log_level_file": "debug", "empty_catalog": false, "compile": true, "static_parser": true, "warn_error_options": {"error": [], "warn": [], "silence": []}, "macro_debugging": false, "quiet": false, "require_generic_test_arguments_property": false, "which": "generate", "use_colors": true, "static": false, "log_format_file": "debug", "defer": false, "partial_parse": true, "vars": {}, "print": true, "log_format": "default", "log_level": "info", "send_anonymous_usage_stats": false, "use_colors_file": true, "log_path": "transform/logs", "version_check": true, "show_all_deprecations": false, "invocation_command": "dbt docs generate --project-dir=transform --target=prd", "source_freshness_run_project_hooks": false, "require_yaml_configuration_for_mf_time_spines": false, "cache_selected_only": false}}